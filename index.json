[{"categories":["DevOps"],"content":"翻译","date":"2021-01-13","objectID":"/talk_ops/","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"原文链接：What the Ops are you talking about? 水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。 ","date":"2021-01-13","objectID":"/talk_ops/:0:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"背景 两年前，我因为效率低下的领导而获得了耻辱。我的背景是数据科学和机器学习，因此，我当然从我的工程同事那边学习到了DevOps。至少我们认为是这样的。 令人费解的是，即使我们遵循了日常站立会议所有敏捷开发的良好实践，讨论我们的难点，也没有将难题扔给别人的态度。我们紧密合作并且相互友爱。但是开发效率依然缓慢，这令整个团队很沮丧。 两年过后，我终于掌握了DevOps的含义，并且理解了它在数据团队中如此的相同而又如此不同。 ","date":"2021-01-13","objectID":"/talk_ops/:1:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"什么是Ops？ 在我们谈论以数据为中心的Ops时，先让我们从软件开始说起， 自从09年DevOps普及以来，软件行业就一直痴迷于各种操作术语。十年前，从软件开发到部署的方法已经推陈出新。软件工程师开发应用，然后将其交付给运维工程师。该应用程序在部署期间经常中断，并在团队之间造成很大的摩擦。 DevOps实践的目的是简化部署过程。该想法是将自动化视为构建和部署软件应用程序的一等公民。 这种想法彻底改变了这个行业。许多组织开始建立跨职能团队来照顾整个SDLC。该团队将建立基础架构（基础工程师），开发应用程序（软件工程师），构建CI/CD管道（DevOps工程师），部署应用程序（每位工程师），然后连续监视和观察应用程序（站点可靠性工程师）。 在一个大团队里面，一个工程师可能只会有一项主要职能，但是在较小的团队中，一位工程师经常担任许多职务。理想的情况是使许多团队成员能够履行多项职能，从而消除瓶颈和关键人员的依存关系。所以实际上， DevOps并非是一项工作职能，而是更多的实践或文化。 在开始构建任何软件时都应采用它。 随着DevOps的兴起，各种各样的Ops诞生了。 SecOps以安全性为核心，GitOps致力于持续交付，NetOps确保网络可以支持数据流，而ITOps则专注于软件交付之外的操作任务。但是，这些操作的基石都源自DevOps所承诺的愿景： 在错误最小的情况下尽可能快的发布软件 ","date":"2021-01-13","objectID":"/talk_ops/:2:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DataOps 🆚 MLOps 🆚 DevOps (and AIOps?) 注意：在本文中，分析团队是指使用SQL / PowerBI来生成业务洞察力的传统BI团队。 AI团队是指使用大数据技术构建高级分析和机器学习模型的团队。 有时他们是同一个团队，但我们将它们分开，以便更容易地解释概念。 五年前，“数据是新石油”一语成为炒作对象。世界各地的领导者开始倾注资源，建立大数据团队来挖掘这些宝贵的资产。这些团队交付的压力巨大—毕竟，我们如何才能兑现新石油的承诺？随着快速扩展，分析团队也经历了同样的痛苦。 然后，我们使这一切成为现实。 数据科学家成为21世纪最吃香的职业。我们正在建立和处于数据和分析的黄金时代。每个执行者都有一个仪表板，具有来自整个组织的数据和嵌入式预测模型的仪表板，每个客户都有基于其行为的个性化推荐。 但是，现在添加一个新功能需要花费数周甚至数月的时间。数据模型是混乱的并且没有人知道我们是使用信贷团队还是营销团队的活跃客户的定义。我们变得非常警惕将模型推向生成环境，因为我们不知道我们会破坏什么？ 因此，以数据为中心的社区团结在一起，保证不会因管理不善的数据流程而造成的效率低下，从那时起，各种以数据为中心的OPS诞生了 要了解所有这些不同的Ops，让我们来看看数据如何在组织中流动的场景： 数据是由与软件应用程序交互的客户生成的 软件将数据存储在其应用程序数据库中 分析团队从组织中的团队使用这些应用程序数据库构建ETL 然后，数据工程师将原始数据，合并的数据集（来自分析团队）和其他非结构化数据集摄取到某种形式的数据湖中 然后，数据科学家根据这些庞大的数据集建立模型 然后，这些模型采用用户生成的新数据进行预测。 然后，软件工程师将预测结果呈现给用户 并且周期继续 我们知道DevOps的诞生是由于开发团队和运维团队之间的摩擦。因此，想象一下运维，开发，分析和AI团队之间的4向界面所带来的令人头疼的问题。 为了说明不同的Ops如何解决上述过程，下面的图形绘制了每个作业功能在整个时间轴上执行的一些任务 理想情况下，应在项目开始时采用X-Ops文化，并在整个过程中实施实践. 总而言之，这就是每个Ops的意义 ","date":"2021-01-13","objectID":"/talk_ops/:3:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DevOps更快地交付软件 一系列实践旨在消除开发团队和运维团队之间的障碍，以便更快地构建和部署软件。工程团队通常采用它，包括DevOps工程师，基础架构工程师，软件工程师，站点可靠性工程师和数据工程师。 ","date":"2021-01-13","objectID":"/talk_ops/:3:1","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DataOps更快地交付数据 一系列实践旨在提高数据分析的质量和减少周期时间。DataOps主要的任务包括数据打标、数据测试、数据管道编排、数据版本控制和数据监控。分析和大数据团队是DataOps主要的支撑对象，但是任何生成和使用数据的人都应该采用良好的DataOps做法，其中包括数据分析师，BI分析师，数据科学家，数据工程师，有时还包括软件工程师。 ","date":"2021-01-13","objectID":"/talk_ops/:3:2","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"MLOps更快地提供机器学习模型 一套设计，构建和管理可重现，可测试和可持续的ML支持软件的实践。对于大数据/机器学习团队，MLOps包含大多数DataOps任务和其他特定于ML的任务，例如模型版本控制，测试，验证和监视。 ","date":"2021-01-13","objectID":"/talk_ops/:3:3","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"奖励：AIOps利用AI的功能增强了DevOps工具 有时人们会错误地将MLOps称为AIOps，但它们却大不相同。从Gartner： AIOps platforms utilize big data, modern machine learning and other advanced analytics technologies to directly and indirectly enhance IT operations (monitoring, automation and service desk) functions with proactive, personal and dynamic insight. 因此，AIOps通常是使用AI驱动技术来增强服务产品的DevOps工具。 AWS CloudWatch提供的警报和异常检测是AIOps的一个很好的例子. ","date":"2021-01-13","objectID":"/talk_ops/:3:4","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"Principals not Job Roles 一个误解是，为了实现这些行动所承诺的效率，他们需要从选择正确的技术开始。事实上，技术不是最重要的东西。 DataOps，MLOps和DevOps的实践必须与语言，框架，平台和基础架构无关。 每个人都有不同的workflow，该workflow应由负责人告知——而不是你想尝试的技术或最受欢迎的技术。首先要去技术的陷阱是，如果您想使用锤子，一切对您来说就像钉子一样。 所有的Ops都有相同的7个主要原则，但每个Ops都有自己的细微差别： ","date":"2021-01-13","objectID":"/talk_ops/:4:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"1. 合规 DevOps通常担心网络和应用程序的安全性。在MLOps领域，金融和医疗保健等行业通常需要模型可解释性。DataOps需要确保数据产品符合GDPR / HIPPA等法律。 🔧 Tools: PySyft 解耦私人数据以进行模型训练， AirCloak 用于数据匿名. Awesome AI Guidelines 策划有关AI的原则，标准和法规。 ","date":"2021-01-13","objectID":"/talk_ops/:4:1","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"2. 迭代开发 该原理源于敏捷方法论，该方法论着重于以可持续的方式持续产生业务价值。该产品经过迭代设计，构建，测试和部署，以最大程度地快速排除故障并学习原理。 ","date":"2021-01-13","objectID":"/talk_ops/:4:2","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"3. 可重现性 软件系统通常是确定性的：每次代码都应以完全相同的方式运行。因此，为了确保可重现性，DevOps只需要跟踪代码即可。 但是，由于任一数据漂移，机器学习模型通常都需要重新训练。为了重现结果，MLOps需要对模型进行版本控制，而DataOps需要对数据进行版本控制。当审核员询问要使用哪些数据来训练哪种模型来产生特定结果时，数据科学家需要能够回答这一问题。 🔧 Tools: 实验跟踪工具, 例如 KubeFlow, MLFlow 或者 SageMaker 都具有将元数据链接到实验运行的功能。 Pachyderm 和 DVC 用于数据版本控制。 ","date":"2021-01-13","objectID":"/talk_ops/:4:3","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"4. 测试 软件测试在于单元测试，集成测试和回归测试。DataOps需要严格的数据测试，其中包括架构更改，数据漂移，功能设计后的数据验证等。从机器学习的角度来看，模型准确性，安全性，偏见/公平性，可解释性都需要进行测试。 🔧 Tools: 诸如 Shap \u0026 Lime 用于可解释性, fiddler 用于解释性监控, great expectation 用于数据测试. ","date":"2021-01-13","objectID":"/talk_ops/:4:4","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"5. 持续部署 这里有三个组件用于机器学习模型的持续部署： 第一个组件是触发事件，即触发是数据科学家手动触发，日历计划事件和阈值触发吗？ 第二个组件是新模型的实际再培训。导致该模型的脚本，数据和超参数是什么？它们的版本以及如何相互链接。 最后一个组件是模型的实际部署，该部署必须由具有预警功能的部署管道进行编排。 🔧 Tools: 大多数workflow管理工具都具有此功能，例如AWS SageMaker，AzureML，DataRobot等。开源工具例如Seldon, Kubeflow KFServing. ","date":"2021-01-13","objectID":"/talk_ops/:4:5","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"6. 自动化 自动化是DevOps的核心价值，实际上有很多专门针对自动化各个方面的工具。以下是机器学习项目的一些资源： Awesome Machine Learning Awesome Production Machine Learning ","date":"2021-01-13","objectID":"/talk_ops/:4:6","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"7. 监控 需要监视软件应用程序，机器学习模型和数据管道也需要监视。对于DataOps，监视新数据的分布是否有任何数据和/或概念漂移很重要。在MLOps方面，除了模型降级之外，如果您的模型具有公共API，监视对抗攻击也至关重要。 🔧 Tools: 大多数workflow管理框架都有某种形式的监控。. 其他流行的工具包括 Prometheus 用于指标监控, Orbit by Dessa 用于数据\u0026模型监控. ","date":"2021-01-13","objectID":"/talk_ops/:4:7","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"结论 采用正确的X-Ops文化，以加快数据驱动和机器学习驱动的软件产品的交付。请记住，有关技术的原则： 建立跨学科技能: 培养T型人才和团队，弥补差距并统一问责制 尽早实现自动化: 融合在技术堆栈上并实现自动化，减轻工程费用的流程 着眼于最终方案: 预先投资解决方案设计以减少从PoC到生产的摩擦 ","date":"2021-01-13","objectID":"/talk_ops/:5:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["Cloud Native"],"content":"开篇","date":"2021-01-10","objectID":"/k8s_series/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2021-01-10","objectID":"/k8s_series/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"1. 介绍 最近整体工作在往云原生和k8s上迁移，想将自己对于k8s的一些学习心得和经验写成一个系列记录下来。 ","date":"2021-01-10","objectID":"/k8s_series/:2:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["DevOps"],"content":"开篇","date":"2021-01-08","objectID":"/devops_series/","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 《DevOps系列：文化》 ","date":"2021-01-08","objectID":"/devops_series/:1:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"1. 介绍 在Ops领域工作也接近8年了，最近想把自己的一些DevOps相关的学习和经验记录下来，整理成一个系列。 ","date":"2021-01-08","objectID":"/devops_series/:2:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"2. 当我们谈论OPS，我们在谈论什么 ","date":"2021-01-08","objectID":"/devops_series/:3:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["other"],"content":"flag","date":"2021-01-02","objectID":"/2021_flag/","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["other"],"content":"2021年已经到来，在这里给自己列一个flag清单。 ","date":"2021-01-02","objectID":"/2021_flag/:0:0","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["other"],"content":"习惯成自然 每2周完成一个ARTS(Algorithm|Review|Technique|Share) 完成12篇博客(每月一篇) 完成4篇英文技术文章翻译(每季度一篇) ","date":"2021-01-02","objectID":"/2021_flag/:0:1","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["other"],"content":"读书清单 《性能之巅 洞悉系统、企业与云计算》 《Web性能权威指南》 ","date":"2021-01-02","objectID":"/2021_flag/:0:2","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["other"],"content":"极客时间清单 程序员的数学基础课 MySQL实战45讲 ","date":"2021-01-02","objectID":"/2021_flag/:0:3","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["DevOps"],"content":"监控系统","date":"2020-08-24","objectID":"/monitor/","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"为什么需要监控系统？ ","date":"2020-08-24","objectID":"/monitor/:1:0","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"两个场景 场景一 技术部门上线了一个新项目，系统宕机了，客户在访问时发现无法访问，客户 A 不知道如何处理，放弃了访问，客户 B 知道客服系统，告知了运营人员，运营人员自己访问后也发现无法访问，于是通知了测试人员，再由测试人员通知线上项目的负责人，由负责人来进行故障恢复。 整个流程中，能处理故障的人成了最后知道故障的人。 场景二 用户反馈访问某个系统很慢，通知技术人员排查问题，由于系统涉及的组件很多，技术人员没办法立即知道问题出在哪里，于是技术人员只能通过自己把整个数据流走完的方式来排查问题： 1、由入口开始排查问题，先确认网络是否丢包，延时是否过高，发现无异常。 2、于是排查服务所在机器的负载情况，以及服务相关日志 (未必有记录)，也无异常。 3、排查代码发现有做 sql 查询，于是根据 sql 手动到数据库执行，发现 sql 执行很慢。 4、于是排查数据库所在机器的负载情况，发现 cpu 一直处在 100% 状态，是数据库进程造成的。 5、通过查询相关执行 sql 发现有某个 sql 在执行复杂查询导致了 cpu 使用率一直很高，从而影响了其他 sql 查询。 极端情况下，技术人员可能需要把所有相关组件都排查一遍，才能发现问题出在哪里。 ","date":"2020-08-24","objectID":"/monitor/:1:1","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"场景解决方案 开头提到的两个场景应该是大部分技术人员都会碰到的问题，场景一是故障出现到故障处理的耗时问题，场景二是故障处理到故障恢复的耗时问题。 场景一的解决方式，可以由一个脚本或者一个系统，定时收集客户访问的 url 的返回状态码，如果出现错误的状态码达到一定次数，就发送邮件或者短信给到对应的负载人。 场景二的解决方式，可以由一个系统，定时收集所有组件的相关信息，然后通过聚合和数据展示，来提供一个全局的问题查看功能。 解决上面两种场景的系统就是监控系统。 ","date":"2020-08-24","objectID":"/monitor/:1:2","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"为什么要监控 监控一个系统有多个原因，一般包含如下几项 分析趋势 数据库多大，增长速度如何？日活用户的增长速度？ 数据对比 增加了 redis 缓存后，访问速度较没增加前如何？这周和上周的访问速度有什么差异？ 告警 有东西故障了，或者即将故障，需要有人处理它。 构建仪表盘 仪表盘应该可以回答有关服务的一些基本问题，通常会包含常见的指标 临时性回溯分析 请求延迟刚刚大幅增加，有没有其他的现象同时发生？ ","date":"2020-08-24","objectID":"/monitor/:1:3","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"建立监控系统 ","date":"2020-08-24","objectID":"/monitor/:2:0","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"监控系统基本组件 一个监控系统一般包含下面几个组件： Agent/collector Agent/collector用于定时收集各种需要的指标信息，可以是脚本、程序、埋点。 Server Server用于接收采集回来的指标信息，进行聚合、存储，供后续查询使用。 Dashboard Dashboard用于展示历史指标信息 Alert Alert用于计算告警规则，发送告警的操作 ","date":"2020-08-24","objectID":"/monitor/:2:1","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"监控系统的工作流程 一个监控系统的工作流程一般如下： 数据采集 安装客户端，可以是脚本、程序、埋点, 定时采集各种需要的数据。 数据接收、存储 Push方式 监控系统提供接口供客户端定时上报数据 Pull方式 客户端提供接口供监控系统定时拉取数据 数据处理 告警 根据一定规则计算采集回来的指标数据，设置阈值，当达到阈值后发送告警。 展示 提供一个仪表板，用来展示采集回来的数据 分析 针对采集回来的数据进行定制化的数据分析 ","date":"2020-08-24","objectID":"/monitor/:2:2","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"Metric 配置监控时，我们首要面对的是监控数据如何采集的问题。一般我们可以把监控指标分为两类：业务指标和资源指标。 业务指标 业务指标通过衡量有用的输出来指示系统的运行状况。一般包括以下几个 吞吐量 成功率 错误 性能(延迟) 一个Web server的业务指标例子 Subtype Description Value throughput requests per second 312 success 上个周期响应状态码为2xx的百分比 99.1 error 上个周期响应状态码为5xx的百分比 0.1 performance 采集周期内的平均响应时间 0.4 资源指标 资源指标一般包括以下几个： 利用率 饱和度 错误 可用性 一些通用资源的指标例子 Resource Utilization Saturation Errors Availability Disk IO % time that device was busy wait queue length # device errors % time writable Memory % of total memory capacity in use swap usage N/A (not usually observable) N/A Microservice average % time each request-servicing thread was busy # enqueued requests # internal errors such as caught exceptions % time service is reachable Database average % time each connection was busy # enqueued queries # internal errors, e.g. replication errors % time database is reachable Four Golden Signals Four Golden Signals 是 Google 针对大量分布式监控的经验总结，4 个黄金指标可以在服务级别帮助衡量终端用户体验、服务中断、业务影响等层面的问题。主要关注与以下四种类型的指标： 延迟：服务请求所需时间。 记录用户所有请求所需的时间，重点是要区分成功请求的延迟时间和失败请求的延迟时间 流量：监控当前系统的流量，用于衡量服务的容量需求。 流量对于不同类型的系统而言可能代表不同的含义。例如，在 HTTP REST API 中, 流量通常是每秒 HTTP 请求数； 错误：监控当前系统所有发生的错误请求，衡量当前系统错误发生的速率。 对于失败而言有些是显式的 (比如, HTTP 500 错误)，而有些是隐式 (比如，HTTP 响应 200，但实际业务流程依然是失败的)。 对于一些显式的错误如 HTTP 500 可以通过在负载均衡器 (如 Nginx) 上进行捕获，而对于一些系统内部的异常，则可能需要直接从服务中添加钩子统计并进行获取。 饱和度：衡量当前服务的饱和度。 主要强调最能影响服务状态的受限制的资源。 例如，如果系统主要受内存影响，那就主要关注系统的内存状态，如果系统主要受限与磁盘 I/O，那就主要观测磁盘 I/O 的状态。因为通常情况下，当这些资源达到饱和后，服务的性能会明显下降。同时还可以利用饱和度对系统做出预测，比如，“磁盘是否可能在 4 个小时候就满了”。 ","date":"2020-08-24","objectID":"/monitor/:2:3","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"Alert 报警可以让一个系统发生故障或即将发生故障时主动通知相应的人员，一个紧急报警的处理会占用对应人员的宝贵时间，如果无效信息过多，分析和修复问题课鞥呢会变慢，故障时间也会相应的延长，因此一个高效的报警系统应该能提供足够的信息，并且误报率非常低。 在管理大规模集群的情况下，究竟有多少报警量才是合理的呢？ Google SRE每周只有十条报警，如果超过十条，说明没有把无效报警过滤掉（Google SRE仅负责SLA要求为99.99%的服务）。 那么怎么减少报警量呢？ 这就需要对报警进行优化了。 报警优化 1. 报警值班和报警升级 基于值班表，每天安排两人进行值班处理报警，将值班压力从全团队压缩在两人范围内，从而让团队能够有足够的时间和人力进行优化工作。 同时，为了避免两个值班人员都没有响应报警，可以使用报警升级功能，如果一个报警在5min内值班人员均未响应，或者15min内未处理完毕，或者有严重故障发生，都可以将报警进行升级，通告团队其他成员协助处理。 2. 建立报警等级 Google SRE的实践则是将监控系统的输出分为三类，报警、工单和记录。 SRE的要求是所有的故障级别的报警，都必须是接到报警，有明确的非机械重复的事情要做，且必须马上就得做，才能叫做故障级别的报警。其他要么是工单，要么是记录。 3. 故障自愈 重启作为单机预案，在很多业务线，可以解决至少50%的报警。没有响应，重启试试，请求异常，重启试试，资源占用异常，重启试试，各种问题，重启都屡试不爽。 换言之，针对简单场景具有明确处置方案的报警，自动化是一个比较好的解决方案，能够将人力从大量重复的工作中解放出来。 自动化处理报警的过程中，需要注意以下问题： 自动化处理比例不能超过服务的冗余度（默认串行处理最为稳妥）； 不能对同一个问题在短时间内重复多次地自动化处理（不断重启某个机器上的特定进程）； 在特定情况下可以在全局范围内快速终止自动化处理机制； 尽量避免高危操作（如删除操作、重启服务器等操作）； 每次执行操作都需要确保上一个操作的结果和效果收集分析完毕（如果一个服务重启需要10min）。 4. 持续优化TOP3的报警 2/8定律，80%的报警可能来自20%的指标，对报警数过多的报警进行持续优化，可以减少大量的报警。 5. 基于时间段分而治之 从冗余度角度来分析，如果在流量峰值有20%的冗余度，那么在流量低谷，冗余度至少为50%。 基于冗余度的变换，相应的监控策略的阈值，随机也应该发生一系列的变化。 举例来说，在高峰期，可能一个服务故障20%的实例，就必须介入处理的话，那么在低谷期，可能故障50%的实例，也不需要立即处理，依赖于报警自动化处理功能，逐步修复即可。 6. 报警周期优化，避免瞬报 在监控趋势图中，会看到偶发的一些毛刺或者抖动，这些毛刺和抖动，就是造成瞬报的主要原因。 这些毛刺和抖动，至多定义为异常，而非服务故障，因此应该以非紧急的通知方式进行。 7. 提前预警，防患于未然 对于很多有趋势规律的场景，可以通过提前预警的方式，降低问题的紧迫程度和严重性。 8. 日常巡检 提前预警面向的是有规律的场景，而日常巡检，还可以发现那些没有规律的隐患。 9. 比例为主，绝对值为辅 线上机器的规格不同，如果从绝对值角度进行监控，则无法适配所有的机器规格，势必会产生大量无意义的报警。 10. Code Review 前人埋坑，后人挖坑。在解决存量问题的情况下，不对增量问题进行控制，那报警优化，势必会进入螺旋式缓慢上升的过程，这对于报警优化这类项目来说，无疑是致命的。 通过对新增监控的Code Review，可以让团队成员快速达成一致认知，从而避免监控配置出现千人千面的情况出现。 11. 沉淀标准和最佳实践 仅仅做Code Review还远远不够，一堆人开会，面对一行监控配置，大眼瞪小眼，对不对，为什么不对，怎么做更好？大家没有一个标准，进而会浪费很多时间来进行不断的讨论。 这时候，如果有一个标准，告诉大家什么是好，那么就有了评价标准，很多事情就比较容易做了。 标准本身也是需要迭代和进步的，因此大家并不需要担心说我的标准不够完美。 基于标准，再给出一些最佳的监控时间，那执行起来，就更加容易了。 12. 彻底解决问题不等于自动处理问题 自动化处理问题不等于解决问题，掩耳盗铃也不等于解决问题，什么叫做解决问题，只有是找到问题的根本原因，并消灭之，才能确保彻底解决问题，轻易不会再次发生。 ","date":"2020-08-24","objectID":"/monitor/:2:4","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"参考 Google SRE 运维解密 datadog monitoring 101 摆脱无效报警？十年运维监控报警优化经验总结 ","date":"2020-08-24","objectID":"/monitor/:3:0","tags":["devops"],"title":"监控系统","uri":"/monitor/"},{"categories":["DevOps"],"content":"SRE介绍","date":"2020-08-23","objectID":"/sre/","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"困局 计算机软件系统离开人通常是无法自主运行的，那要如何去运维一个日趋复杂的大型分布式计算机系统呢？ ","date":"2020-08-23","objectID":"/sre/:1:0","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"Dev/Ops分离团队模型 雇佣系统管理员(sysadmin)运维复杂的计算机系统是行业内一直以来的普遍做法，系统管理员的工作主要在于应对系统中产生的各种需要人工干预的事件，以及来自业务部门的变更需求。但随着系统变得复杂，组件越来越多，流量不断上升，相关的事件和变更需求也会越来越多，就需要招聘更多的系统管理员。系统管理员的日常工作和研发工程师的相差甚远，通常归属于两个不同的部门，开发部(Dev)和运维部(Ops)。也就是Dev/Ops分离团队模型。 但是这个模型存在两个无法避免的问题。 直接成本。随着系统复杂度的增加，部署规模的扩大，团队的大小基本与系统负载成线性相关，共同成长。 间接成本。即研发团队和运维团队之间的沟通成本。研发团队想要\"随时随地发布新功能，没有任何阻拦”，运维团队想要”一旦一个东西在生产环境中正常工作了，就不要再进行任何改动“。本质来说，两个团队的目标是互相矛盾的。 ","date":"2020-08-23","objectID":"/sre/:1:1","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"解决之道 ","date":"2020-08-23","objectID":"/sre/:2:0","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"DevOps DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。 ","date":"2020-08-23","objectID":"/sre/:2:1","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"SRE SRE可以理解为DevOps的一种实践，SRE基本是在进行由运维团队完成的工作，但是雇佣具有软件专业知识的工程师，通过创造软件系统的方式来维护系统运行并替代传统模型中的人工操作。本质上，SRE是在用软件工程的思维和方法论，通过设计、构建自动化工具来完成以前由系统管理员人工操作完成的任务。 SRE方法论 1. 确保长期关注研发工作 SRE团队应将运维工作限制在50%以内，并将剩余时间投入到研发项目上 2. 在保障SLO的前提下最大化迭代速度 错误预算，任何产品都不是，也不应该做到100%可靠，部门建立起一个合理的可靠性目标，错误预算等于”1-可靠性目标“，通过错误预算来最大化新功能上线的速度，同时保障服务质量。 3. 监控系统 监控系统是SRE团队监控服务质量和可用性的一个主要手段。一个监控系统应该只有三类输出： 紧急警报(alert)，意味着收到警报的用户需要立即执行某种操作 工单(ticket)，意味着接受工单的用户应该执行某种操作，但是并发立即执行。 日志(logging)，平时没有人需要关注日志信息，但是日志信息依然被收集起来以备调试和事后分析时使用 4. 应急事件处理 可靠性是MTTF(平均失败时间)和MTTR(平均恢复时间)的函数。评价一个团队将系统恢复到正常情况的最有效的指标，就是MTTR。 任何需要人工操作的事情都只会延长恢复时间。但有时候人工介入不可避免时，可以通过事先预案并且将最佳方法记录到”运维手册“上来降低MTTR。 5. 变更管理 变更管理的最佳实践是使用自动化来完成以下几个项目： 采用渐进式发布机制 迅速而准确地检测到问题的发生 当问题发生时，安全迅速的回滚 6. 需要预测和容量规划 需要预测和容量规划是保障一个业务有足够的容量和冗余度去服务预测中的未来需要。 容量规划有几个必需步骤： 必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间 规划中必须有准确的非自然增长的需求来源的统计 必须有周期性压力测试，以便准确地将系统原始资源信息与业务容量对应起来。 7. 效率与性能 高效地利用各种资源是任何赢利性服务都要关心的，一个服务的利用率指标通常依赖于这个服务的工作方式以及对容量的配置与部署上。如果能通过密切关注一个服务的容量配置策略，进而改进其资源利用率，可以有效地降低系统的总成本。 ","date":"2020-08-23","objectID":"/sre/:2:2","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"成为SRE ","date":"2020-08-23","objectID":"/sre/:3:0","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"技能要求 – TCP/IP网络模型 (OSI模型) – Unix/Linux 系统 – Unix/Linux 系统管理 – 数据结构与算法 – 编程语言 – SQL和数据库管理 – 人员管理 – 项目管理 ","date":"2020-08-23","objectID":"/sre/:3:1","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"能力等级 0 – 对于相关的技术领域还不熟悉。 1 – 可以读懂这个领域的基础知识。 2 – 可以实现一些小的改动，清楚基本的原理，并能够在简单的指导下自己找到更多的细节。 3 – 基本精通这个技术领域，完全不需要别人的帮助。 4 – 对这个技术领域非常的熟悉和舒适，可以应对和完成所有的日常工作。 ​ 4 – 1 对于软件领域 – 有能力开发中等规模的程序，能够熟练和掌握并使用所有的语言特性，而不是需要翻书，并且能够找到所有的冷知识。 ​ 4 – 2 对于系统领域 – 掌握网络和系统管理的很多基础知识，并能够掌握一些内核知识以运维一个小型的网络系统，包括恢复、调试和能解决一些不常见的故障。 5 – 对于该技术领域有非常底层的了解和深入的技能。 6 – 能够从零开发大规模的程序和系统，掌握底层和内在原理，能够设计和部署大规模的分布式系统架构。 7 – 理解并能利用高级技术，以及相关的内在原理，并可以从根本上自动化大量的系统管理和运维工作。 8 – 对于一些边角和晦涩的技术、协议和系统工作原理有很深入的理解和经验。能够设计，部署并负责非常关键以及规模很大的基础设施，并能够构建相应的自动化设施。 9 – 能够在该技术领域出一本经典的书。并和标准委员会的人一起工作制定相关的技术标准和方法。 10 – 在该领域写过一本书，被业内尊为专家，并是该技术的发明人。 ","date":"2020-08-23","objectID":"/sre/:3:2","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"Roadmap ","date":"2020-08-23","objectID":"/sre/:3:3","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["DevOps"],"content":"参考 Google SRE 运维解密 Google SRE Workbook Roadmap ","date":"2020-08-23","objectID":"/sre/:4:0","tags":["devops"],"title":"运维进阶之SRE","uri":"/sre/"},{"categories":["Linux"],"content":"Nginx匹配机制总结","date":"2020-06-06","objectID":"/nginx_match/","tags":["linux","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"写在前面 Nginx是一个当前主流的HTTP服务器和反向代理服务器，很多做WEB相关的同学基本都会用到，很多云厂商的七层负载均衡器也基本都是基于nginx实现的，个人在工作过程也算是经常接触，这篇文章主要想总结一下nginx的匹配机制，主要分为两块，一块是server的匹配，一块是location的匹配。 ","date":"2020-06-06","objectID":"/nginx_match/:0:1","tags":["linux","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"Server匹配机制 配置过nginx的都知道，在一个http模块中是可以配置多个server模块的，并且多个server模块是可以配置相同的监听端口的，下面是一个简单的server配置例子： server { listen 80; server_name example.org www.example.org; ... } server { listen 80; server_name example.net www.example.net; ... } server { listen 80; server_name example.com www.example.com; ... } 当我们对nginx发起http请求后，nginx会拿到http请求中对应的 \"Host\" 头部跟server模块中的server_name进行匹配，根据匹配的server结果进入具体的server模块处理http请求。那么，它具体的匹配机制是怎样的呢？ 首先，我们先简单了解下nginx内部server的相关结构， 其中listen和server_name在配置文件中的写法有： listen(可带default_server标识) ip:port ip(监听80端口) port(监听所有地址) server_name www.example.com(完整域名) *.example.com(带通配符开头的域名) www.example.*(带通配符结尾的域名) ~^(www.)?(.+)$(正则写法的域名) 代码中的具体结构： /************************************************************************************* 伪结构体示例 (port) --\u003e address(ip:port) --\u003e server(example.com) --\u003e server(example.net) 一个server模块的唯一标识是由address(listen配置)和server(server_name配置)组成 *************************************************************************************/ /* address 结构体，具有相同的ip:port */ struct ngx_http_addr_conf_s { /* default_server 存储的是listen配置里带default_server标识的server， 若没有就为顺序中的第一个server */ ngx_http_core_srv_conf_t *default_server; ngx_http_virtual_names_t *virtual_names; unsigned ssl:1; unsigned http2:1; unsigned proxy_protocol:1; }; /* virtual_name结构体，存储hash_combined和正则写法的server_name */ typedef struct { ngx_hash_combined_t names; ngx_uint_t nregex; ngx_http_server_name_t *regex; } ngx_http_virtual_names_t; /* hash_combined结构体，存储完成域名、通配符开头、通配符结尾的server_name */ typedef struct { ngx_hash_t hash; ngx_hash_wildcard_t *wc_head; ngx_hash_wildcard_t *wc_tail; } ngx_hash_combined_t; 通过结构体，我们来说明下server的匹配规则： host是否匹配virtual_names中的names中的完整域名(hash)，若是则返回 host是否匹配virtual_name中的names中的通配符开头的域名(wc_head)，若是则返回 host是否匹配virtual_name中的names中的通配符结尾的域名(wc_tail)，若是则返回 host是否匹配virtual_name中的正则写法的域名(regex)，若是则返回 返回default_server 具体示例如下： #精确匹配，第一优先级 server { listen 80; server_name www.test.com; } #通配符开头匹配，第二优先级， server { listen 80; server_name *.test.com; } #通配符结尾匹配，第三优先级 server { listen 80; server_name www.test.*; } #正则匹配，第三优先级 server { listen 80; server_name ~^(www.)?(.+)$; } #default，没找到对应host，则以此优先 server { listen 80 defalut_server; server_name _; } #若没有加defalut_server，则第一个server为defalut_server server { listen 80; server_name _; } ","date":"2020-06-06","objectID":"/nginx_match/:0:2","tags":["linux","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"Location匹配机制 一个server模块可以配置多个location，nginx根据URI来进行匹配， lication的写法有以下几种： = /uri 精确匹配 ^~ /uri 非正则前缀匹配 ~ 或者 ~* /uri 正则匹配 /uri 前缀匹配 整个location匹配机制如下： 针对所有前缀字符串测试URI(包括精确匹配、非正则前缀匹配、前缀匹配中的字符串) uri等于精确匹配中的字符串，停止搜索 最长(最相似)前缀字符串如果为非正则前缀匹配(带^~)，则停止正则搜索 保存最长(最相似)的前缀字符串 按顺序进行uri和正则匹配测试，有一个匹配成功后就停止搜索 如果都没有，就使用最长(最相似)的前缀匹配 额外说明： 最长(最相似)前缀字符串的测试阶段，非正则前缀匹配匹配、前缀匹配的优先级是一致的，谁的长度长，谁优先。优先前缀匹配的前提必须是前缀字符串非正则前缀匹配的长度大于前缀匹配的长度，这个很多网站都是直接写成了非正则前缀匹配是第二优先级，没有说明前提条件。 具体示例如下： #精确匹配，第一优先级 location = /test { } #前缀匹配，最低优先级，长度优先 location /test/aa { } #非正则前缀匹配，最长前缀下为第二优先级(特殊条件下) location ^~ /test { } #正则匹配，第三优先级,顺序优先 # ~ : 区分大小写 # ~* : 不区分大小写 location ~* ^/test { } ","date":"2020-06-06","objectID":"/nginx_match/:0:3","tags":["linux","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"参考 https://nginx.org/en/docs/http/request_processing.html https://nginx.org/en/docs/http/ngx_http_core_module.html#location https://docs.nginx.com/nginx/admin-guide/web-server/web-server/ https://www.codedump.info/post/20190212-nginx-http-config/ ","date":"2020-06-06","objectID":"/nginx_match/:0:4","tags":["linux","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"Linux PAM模块","date":"2020-04-05","objectID":"/linux_pam/","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"概念 Linux-PAM（Pluggable Authentication Modules for Linux）是一套共享库,使本地系统管理员可以随意选择程序的认证方式。换句话说，不用(重新编写)重新编译一个包含PAM功能的应用程序，就可以改变它使用的认证机制，这种方式下，就算升级本地认证机制,也不用修改程序。 ","date":"2020-04-05","objectID":"/linux_pam/:0:1","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"工作机制 当应用程序希望与PAM交互以处理事件时，他们必须包括libpam，该libpam允许通过库提供的API进行通信。 当PAM看到必须处理的新事件时，它将查看/etc/pam.d中的相关配置文件，并确定在某些阶段必须使用哪些模块。 ","date":"2020-04-05","objectID":"/linux_pam/:0:2","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"/etc/pam.d配置文件介绍 配置文件语法 type control module-path module-arguments 配置文件分为四列 第一列代表模块类型 第二列代表控制标记 第三列代表模块路径 第四列代表模块参数 类型 类型 是规则对应的管理组。它用于指定后续模块要与哪个管理组关联。 目前有四种类型: account 此模块类型执行基于非身份验证的帐户管理。 通常用于限制/允许对服务的访问，例如是否允许登录,是否达到最大用户数,或是root用户是否允许在这个终端登录等。 auth 此模块为用户验证提供两方面服务。让应用程序提示用户输入密码或者其他标记，确认用户合法性；通过他的凭证许可权限，设定组成员关系或者其他优先权。 password 此模块用于控制用户更改密码的全过程。 session 此模块处理为用户提供服务之前/后需要做的些事情。包括：开启/关闭交换数据的信息，监视目录等，设置用户会话环境等。也就是说这是在系统正式进行服务提供之前的最后一道关口。 如果在类型前加一个短横线 -，就表示如果找不到这个模块，导致无法被加载时，这一事件不会被记录在日志中。这个功能适用于那些认证时非必需的、安装时可能没被安装进系统的模块。 控制标记 流程栈（stack） 它是认证时执行步骤和规则的堆叠。在某个服务的配置文件中，它体现在了配置文件中的自上而下的执行顺序中。栈是可以被引用的，即在一个栈（或者流程）中嵌入另一个栈。 控制标记 规定如何处理PAM模块鉴别认证的结果，简而言之就是鉴别认证成功或者失败之后会发生什么事，如何进行控制。一般有两种形式，一种是比较常见的“关键字”方式，另一种则是用方括号（[]）包含的“value =action”方式。 关键字方式: required 如果本条目没有被满足，那最终本次认证一定失败，但认证过程不因此打断。整个栈运行完毕之后才会返回“认证失败”信号。 requisite 如果本条目没有被满足，那本次认证一定失败，而且整个栈立即中止并返回错误信号。 sufficient 如果本条目的条件被满足，且本条目之前没有任何required条目失败，则立即返回“认证成功”信号；如果对本条目的验证失败，不对结果造成影响。 optional 该条目仅在整个栈中只有这一个条目时才有决定性作用，否则无论该条验证成功与否都和最终结果无关。 include 将其他配置文件中的流程栈包含在当前的位置，就好像将其他配置文件中的内容复制粘贴到这里一样。 substack 运行其他配置文件中的流程，并将整个运行结果作为该行的结果进行输出。该模式和 include 的不同点在于认证结果的作用域：如果某个流程栈 include 了一个带 requisite 的栈，这个 requisite 失败将直接导致认证失败，同时退出栈；而某个流程栈 substack 了同样的栈时，requisite 的失败只会导致这个子栈返回失败信号，母栈并不会在此退出。 value = action方式: 另外还有一种比较复杂的格式为value = action的语法来设置控制标志，标志之间会以空格分开。格式如下： [value1 = action1 value2 = action2 ……] 其中value可以是下列Linux PAM库的返回值： success、open_err、symbol_err、service_err、 system_err、buf_err、perm_denied、auth_err、cred_insufficient、authinfo_unavail、user_unknown、maxtries、new_authtok_reqd、acct_expired、 session_err、cred_unavail、cred_expired、cred_err、no_module_data、conv_err、 authtok_err、authtok_recover_err、authtok_lock_busy、authtok_disable_aging、 try_again、ignore、abort、authtok_expired、module_unknown、bad_item和default。其中，default代表其他所有没有明确说明的返回值。 流程栈中很可能有多个验证规则，每条验证的返回值可能不尽相同，那么到底哪一个验证规则能作为最终的结果呢？这就需要 actionN 的值来决定了。actionN 的值有以下几种： ignore 在一个栈中有多个认证条目的情况下，如果标记 ignore 的返回值被命中，那么这条返回值不会对最终的认证结果产生影响。 bad 标记 bad 的返回值被命中时，最终的认证结果注定会失败。此外，如果这条 bad 的返回值是整个栈的第一个失败项，那么整个栈的返回值一定是这个返回值，后面的认证无论结果怎样都改变不了现状了。 die 标记 die 的返回值被命中时，马上退出栈并宣告失败。整个返回值为这个 die 的返回值。 ok 在一个栈的运行过程中，如果 ok 前面没有返回值，或者前面的返回值为 PAM_SUCCESS，那么这个标记了 ok 的返回值将覆盖前面的返回值。但如果前面执行过的验证中有最终将导致失败的返回值，那 ok 标记的值将不会起作用。 done 在前面没有 bad 值被命中的情况下，done 值被命中之后将马上被返回，并退出整个栈。 N（无符号整数） 功效和 ok 类似，并且会跳过接下来的 N 个验证步骤。如果 N = 0 则和 ok 完全相同。 reset 清空之前生效的返回值，并且从下面的验证起重新开始。 关键字的控制方式也可以用value = action方式来表示 #required [success=ok new_authtok_reqd=ok ignore=ignore default=bad] #requisite [success=ok new_authtok_reqd=ok ignore=ignore default=die] #sufficient [success=done new_authtok_reqd=done default=ignore] #optional [success=ok new_authtok_reqd=ok default=ignore] 模块路径 模块路径 是应用程序要使用的PAM的绝对路径，或者是默认模块位置的相对路径名，一般为/lib/security /或/lib64/security/，取决于系统架构。 模块参数 模块参数 将只和特定模块相关，因此某个模块的文档中一定包含其参数的信息。如果需要在单个参数中使用空格，可以将整个参数用方括号（[]）包裹起来。 ","date":"2020-04-05","objectID":"/linux_pam/:0:3","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"一个例子 以/etc/pam.d/sshd为例 加载/etc/pam.d/password-auth配置文件 大部分模块的配置文件可在/etc/security中找到，并进行配置 我们比较常进行配置的最大文件数和最大进程数就是在limit.conf中配置，在sshd中会加载到 ","date":"2020-04-05","objectID":"/linux_pam/:0:4","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"谈谈文件描述符","date":"2020-03-29","objectID":"/file_descriptor/","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"概念 wiki解释，文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。 一个文件描述符是一个数字，唯一标识一个在计算机的操作系统打开的文件。它描述了数据资源，以及如何访问该资源。 当程序要求打开文件（或其他数据资源，例如网络套接字）时，内核： 授予访问权限。 在全局文件表中创建一个条目。 向软件提供该条目的位置。 该描述符是唯一的非负整数。系统上每个打开的文件至少存在一个文件描述符。 ","date":"2020-03-29","objectID":"/file_descriptor/:0:1","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"细节 对于内核，所有打开的文件均由文件描述符引用。文件描述符是一个非负数。当我们打开现有文件或创建新文件时，内核将文件描述符返回到进程。当我们想读取或写入文件时，我们用文件描述符标识文件。 每个Linux进程（也许是守护程序除外）都应该具有三个标准的POSIX文件描述符： POSIX常数名称 文件描述符 描述 STDIN_FILENO 0 标准输入 STDOUT_FILENO 1 标准输出 STDERR_FILENO 2 标准误差 有三个“系统文件表”：有一个文件描述符表，它将文件描述符（小整数）映射到打开的文件表中的条目。打开文件表中的每个条目（除其他事项外）还包含文件偏移量和指向内存中inode表的指针。在打开的文件表中，每个open（）调用都有一个文件表条目，如果文件描述符是dup（）ed或fork（）ed，则共享该条目。 我们使用来自维基百科的示例来显示这些表的工作方式。这是一张照片： 单个进程的文件描述符，文件表和索引节点表。请注意，多个文件描述符可以引用相同的文件表条目（例如，由于dup系统调用），并且多个文件表条目可以依次引用同一个索引节点（如果已多次打开；则该表之所以仍然简化，是因为它通过文件名来表示索引节点，即使索引节点可以具有多个名称也是如此。文件描述符3没有引用文件表中的任何内容，表明它已关闭。 理解具体情况，需要了解由内核维护的 3 个数据结构： 进程级 文件描述符表 ( file descriptor table ) 系统级 打开文件表 ( open file table ) 文件系统 i-node表 ( i-node table ) 这 3 个数据结构之间的关系如 图-1 所示： 图-1：文件描述符、打开文件及 inode 关系 ","date":"2020-03-29","objectID":"/file_descriptor/:0:2","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"文件描述符表 内核为每个进程维护一个 文件描述符表 ，该表每一条目都记录了单个文件描述符的相关信息，包括： 控制标志 ( flags )，目前内核仅定义了一个，即 close-on-exec 打开文件描述体指针 ","date":"2020-03-29","objectID":"/file_descriptor/:0:3","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"打开文件表 内核对所有打开的文件维护一个系统级别的 打开文件描述表 ( open file description table )，简称 打开文件表 。 表中条目称为 打开文件描述体 ( open file description )，存储了与一个打开文件相关的全部信息，包括： 文件偏移量 ( file offset )，调用 read() 和 write() 更新，调用 lseek() 直接修改 访问模式 ，由 open() 调用设置，例如：只读、只写或读写等 i-node 对象指针 ","date":"2020-03-29","objectID":"/file_descriptor/:0:4","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"i-node 表 每个文件系统会为存储于其上的所有文件(包括目录)维护一个 i-node 表，单个 i-node 包含以下信息： 文件类型 ( file type )，可以是常规文件、目录、套接字或 FIFO 访问权限 文件锁列表 ( file locks ) 文件大小 等等 i-node 存储在磁盘设备上，内核在内存中维护了一个副本，这里的 i-node 表为后者。 副本除了原有信息，还包括： 引用计数 (从打开文件描述体)、所在 设备号 以及一些临时属性，例如文件锁。 ","date":"2020-03-29","objectID":"/file_descriptor/:0:5","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"参数优化 1. 系统最大的文件描述符数量 系统文件最大值取决于内存大小，在kernel初始化时定义 代码: /* * One file with associated inode and dcache is very roughly 1K. Per default * do not use more than 10% of our memory for files. */ void __init files_maxfiles_init(void) { unsigned long n; unsigned long nr_pages = totalram_pages(); unsigned long memreserve = (nr_pages - nr_free_pages()) * 3/2; memreserve = min(memreserve, nr_pages - 1); n = ((nr_pages - memreserve) * (PAGE_SIZE / 1024)) / 10; files_stat.max_files = max_t(unsigned long, n, NR_FILE); } 由代码可知，file-max的值不超过内存的10% #获取total ram pages 和 PAGE_SIZE大小 $ getconf -a | grep \"PAGE\" PAGESIZE 4096 PAGE_SIZE 4096 _AVPHYS_PAGES 565489 _PHYS_PAGES 1011579 #查看系统最大打开文件描述符数 $ cat /proc/sys/fs/file-max 399894 #查看当前系统使用的打开文件描述符数 $ cat /proc/sys/fs/file-nr 928 0 399894 | | |_ Max no. of file descriptors allowed on the system | | | |__ Total free allocated file descriptors | |__ Total allocated file descriptors #设置系统最大文件描述符 #临时性 $ echo 1000000 \u003e /proc/sys/fs/file-max #永久性 #在/etc/sysctl.conf中设置 fs.file-max = 1000000 $ sysctl -p 2. 进程最大描述符 # 查看某个进程的使用 $ ls -l /proc/2374/fd | wc -l # 进程最大打开文件描述符数 #soft limit $ ulimit -n 65535 #hard limit $ ulimit -Hn 65535 #soft limit不能大于hard limit #设置 #临时性 $ ulimit -Sn 1600000 #永久性 $ vim /etc/security/limits.conf root soft nofile 65535 root hard nofile 65535 #设置nofile的hard limit还有一点要注意的就是hard limit不能大于/proc/sys/fs/nr_open 3. 总结 1. 所有进程打开的文件描述符数不能超过/proc/sys/fs/file-max 2. 单个进程打开的文件描述符数不能超过user limit中nofile的soft limit 3. nofile的soft limit不能超过其hard limit 4. nofile的hard limit不能超过/proc/sys/fs/nr_open ","date":"2020-03-29","objectID":"/file_descriptor/:0:6","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Security"],"content":"理解SSL/TLS协议","date":"2017-01-08","objectID":"/tls/","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"背景 早期我们在访问web时使用HTTP协议，该协议在传输数据时使用明文传输，明文传输带来了以下风险： 信息窃听风险，第三方可以获取通信内容 信息篡改风险，第三方可以篡改通信内容 身份冒充风险，第三方可以冒充他人身份参与通信 为了解决明文传输所带来的风险，网景公司在1994年设计了SSL用于Web的安全传输协议，这是SSL的起源。IETF将SSL进行标准化，1999年公布了第一版TLS标准文件。随后又公布了 RFC 5246（2008年8月）与 RFC 6176 （2011年3月）。该协议在web中被广泛应用。 ","date":"2017-01-08","objectID":"/tls/:1:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"SSL/TLS协议 TLS（Transport Layer Security，传输层安全协议），及其前身SSL（Secure Sockets Layer，安全套接层）是一种安全协议，目的是为互联网通信，提供安全及数据完整性保障。 TLS协议使用以下三种机制为信息通信提供安全传输： 隐秘性，所有通信都通过加密后进行传播 身份认证，通过证书进行认证 可靠性，通过校验数据完整性维护一个可靠的安全连接 ","date":"2017-01-08","objectID":"/tls/:2:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"以TLS1.2为例说明TLS协议 TLS协议由TLS Record Protocol和TLS Handshake Protocol两层协议组成 ","date":"2017-01-08","objectID":"/tls/:3:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"TLS Record Protocol 该协议提供了连接安全的两个基本特性： 连接私有 对称密码用于数据加密，这种对称加密是为每条连接唯一生成的并基于另一个人协商的秘密协议 连接可靠 消息传输包括一条消息 使用密钥MAC进行完整性检查，安全哈希函数（例如， SHA-1等）用于MAC计算。 ","date":"2017-01-08","objectID":"/tls/:3:1","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"TLS Handshake Protocol 该协议提供了连接安全的三个基本特性： 可以使用非对称身份验证对等方的身份，或者 公钥，密码学等 共享密钥的协商是安全的 谈判可靠 一个TLS握手协议一般涉及以下步骤： 交换hello信息用于算法协商，交换随机值，并检查会话是否恢复 交换必要的密码信息以允许客户端和服务端同意使用premaster secret 交换证书和密码信息以允许客户端和服务端进行身份验证 通过随机值和premaster secret生成master secret 向record layer提供安全参数 允许客户端和服务器验证其对等方具有计算出的相同安全参数，并且握手发生在没有被攻击者篡改的情况下 TLS握手的完整消息流 ClientHello 客户端提供了以下内容: 支持的协议版本 客户端随机数据(后续用于握手) 可选的session id 加密套件列表 压缩方法列表 扩展列表 ServerHello 服务端提供了以下内容： 选择后的协议版本 选择后的加密套件 选择后的压缩方法 服务端随机数据(后续用于握手) session id 扩展列表 ServerCertificate 服务端提供了证书，证书包含以下内容： 服务端的hostname 服务端所使用的公钥 来自受信任的第三方的证明，证明此hostname的所有者拥有此公钥的私钥 ServerKeyExchange(可选) 服务端仅在证书包含的信息不足以使客户端进行premaster secret交换时发送该消息 CertificateRequest(可选) 当服务端需要客户端证书时发送，需要加密套件支持 ServerHelloDone 服务端表明已经完成了一半的handshake ClientCertificate(可选) 当服务端有需要验证客户端证书时发送，如果加密套件不支持，则消息不包含证书 ClientKeyExchange 生成一个48byte的premaster secret，并通过服务端证书包含的公钥进行加密发送给服务端 CertificateVerify(可选) 该消息只在客户端证书具有签名能力时发送 ClientChangeCipherSpec(message) 一种协议，数据只有一字节，用于告知Server端已经切换到之前协商好的加密套件的状态，准备使用之前协商好的加密套件加密数据并进行传输了。 ClientFinished 客户端和服务端现在都拥有3个数值 ClientHello.random ServerHello.random premaster secret master secret由上面三个数值计算而成 master_secret = PRF(pre_master_secret,\"master secret\",ClientHello.random + ServerHello.random)[0..47]; 使用master secret加密finished消息发送给服务端 ServerChangeCipherSpec(message) 同上 ServerFinished 同上 根据之前的握手信息，如果客户端和服务端都能对Finish信息进行正常加解密且消息正确的被验证，则说明握手通道已经建立成功。 接下来，双方所有的通信数据都通过Master Secret进行加密后传输。　 ","date":"2017-01-08","objectID":"/tls/:3:2","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"参考： WIKI/Transport_Layer_Security RFC 5246 图示TLS连接 ","date":"2017-01-08","objectID":"/tls/:3:3","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Network"],"content":"谈谈HTTP","date":"2016-05-29","objectID":"/http/","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"写在前面 如今网络已经无处不在，人们通过网络获取浏览各种信息，其中，大部分都是通过浏览器访问各种网页来获取我们想要的信息，那么浏览器与网页(服务端)究竟是如何通信的呢？这就得从HTTP协议说起了，浏览器获取网页信息都是基于HTTP协议来处理的。 ","date":"2016-05-29","objectID":"/http/:0:1","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"概念 HTTP（HyperText Transfer Protocol，超文本传输协议）是互联网上应用最为广泛的一种网络协议。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。通过HTTP或者HTTPS协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。其具有如下特点： 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快 PS：尽管TCP/IP协议是互联网上最流行的应用，HTTP协议中，并没有规定必须使用它或它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP假定其下层协议提供可靠的传输。因此，任何能够提供这种保证的协议都可以被其使用。因此也就是其在TCP/IP协议族使用TCP作为其传输层。 ","date":"2016-05-29","objectID":"/http/:0:2","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"工作流程 HTTP协议的通信过程永远是客户端发起请求(request)，服务器回送响应(respone)，如下图所示： 一个完整的HTTP操作称为一个事务，其流程可分为四步： 建立连接(TCP三次握手) 客户端发送一个请求报文给服务器 服务器响应对应信息 客户端接收信息，然后断开连接 ","date":"2016-05-29","objectID":"/http/:0:3","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"请求和响应详解 请求报文 请求行：由请求方法、URL和HTTP版本组成 eg：GET /index.html HTTP/1.1 请求方法 GET：请求获取URI所标识的资源 HEAD：请求获取URI所标识的资源，但不传回资源的文本部分 POST：向指定URI资源提交数据，请求服务器进行处理 PUT：向指定URI资源上传其最新内容 DELETE：请求服务器删除URI所标识的资源 TRACE：回显服务器收到的请求，主要用于测试或诊断 OPTIONS：请求URI资源所支持的HTTP请求方法 CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接 URL 请求的资源路径 协议版本 现在大部分为HTTP/1.0 和 HTTP/1.1 请求头部 eg：host:www.google.com host为必选，其他都为可选参数 空行 消息体 请求所带的文本 响应报文 状态行：由协议版本、状态码和描述信息组成 eg：HTTP/1.1 200 OK 协议版本 状态码：用于告诉客户端，服务器是否产生预期的响应 1XX：提示信息，表示请求已被成功接收，继续处理 2XX：成功，表示请求已被成功接收，理解 3XX：重定向，要完成请求必须进行更进一步的处理 4XX：客户端错误，请求有语法错误或请求无法实现 5XX：服务器端错误，服务器未能实现合法的请求 描述信息 响应头部 空行 消息体 一个例子 访问codecc.xyz首页 Request，首行为请求行，其余为请求头部 Respone，首行为响应状态行，空行前为响应头部，其余为响应数据 ","date":"2016-05-29","objectID":"/http/:0:4","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol ","date":"2016-05-29","objectID":"/http/:0:5","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Linux"],"content":"理解系统启动过程","date":"2016-05-21","objectID":"/system_start/","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"前言 Linux是一种自由和开放源代码的类UNIX操作系统。该操作系统的内核由林纳斯·托瓦兹在1991年10月5日首次发布。在加上用户空间的应用程序之后，成为Linux操作系统。Linux是自由软件和开放源代码软件发展中最著名的例子。 接触Linux的时间也不算短了，一直都是直接使用Linux操作系统进行一些工作，很少去了解系统从开机到能使用的整个过程，感觉有需要好好理解下整个系统的启动过程，故写这篇博客加深一下理解。 ","date":"2016-05-21","objectID":"/system_start/:0:1","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"启动过程 先通过一张图来简单了解下整个系统启动的流程，整个过程基本可以分为POST–\u003eBIOS–\u003eMBR(GRUB)–\u003eKernel–\u003eInit–\u003eRunlevel。下面会详细说明每个过程的作用。 BIOS BIOS(Basic Input/Output System)，基本输入输出系统，该系统存储于主板的ROM芯片上，计算机在开机时，会最先读取该系统，然后会有一个加电自检过程，这个过程其实就是检查CPU和内存，计算机最基本的组成单元(控制器、运算器和存储器)，还会检查其他硬件，若没有异常就开始加载BIOS程序到内存当中。详细的BIOS功能，这边就不说了，BIOS主要的一个功能就是存储了磁盘的启动顺序，BIOS会按照启动顺序去查找第一个磁盘头的MBR信息，并加载和执行MBR中的Bootloader程序，若第一个磁盘不存在MBR，则会继续查找第二个磁盘(PS：启动顺序可以在BIOS的界面中进行设置)，一旦BootLoader程序被检测并加载内存中，BIOS就将控制权交接给了BootLoader程序。 MBR MBR(Master Boot Record)，主引导记录，MBR存储于磁盘的头部，大小为512bytes，其中，446bytes用于存储BootLoader程序，64bytes用于存储分区表信息，最后2bytes用于MBR的有效性检查。 GRUB GRUB(Grand Unified Bootloader)，多系统启动程序，其执行过程可分为三个步骤： Stage1：这个其实就是MBR，它的主要工作就是查找并加载第二段Bootloader程序(stage2)，但系统在没启动时，MBR根本找不到文件系统，也就找不到stage2所存放的位置，因此，就有了stage1_5 Stage1_5：该步骤就是为了识别文件系统 Stage2：GRUB程序会根据/boot/grub/grub.conf文件查找Kernel的信息，然后开始加载Kernel程序，当Kernel程序被检测并在加载到内存中，GRUB就将控制权交接给了Kernel程序。 PS：实际上这个步骤/boot还没被挂载，GRUB直接识别grub所在磁盘的文件系统，所以实际上应该是/grub/grub.conf文件，该配置文件的信息如下： grub.conf: #boot=/dev/sda default=0 #设定默认启动的title的编号，从0开始 timeout=5 #等待用户选择的超时时间 splashimage=(hd0,0)/boot/grub/splash.xpm.gz #GRUB的背景图片 hiddenmenu #隐藏菜单 title CentOS (2.6.18-194.el5PAE) #内核标题 root (hd0,0) #内核文件所在的设备 kernel /vmlinuz-2.6.18-194.el5PAE ro root=LABEL=/ #内核文件路径以及传递给内核的参数 initrd /initrd-2.6.18-194.el5PAE.img #ramdisk文件路径 ``` Kernel Kernel，内核，Kernel是Linux系统最主要的程序，实际上，Kernel的文件很小，只保留了最基本的模块，并以压缩的文件形式存储在硬盘中，当GRUB将Kernel读进内存，内存开始解压缩内核文件。讲内核启动，应该先讲下initrd这个文件， initrd(Initial RAM Disk)，它在stage2这个步骤就被拷贝到了内存中，这个文件是在安装系统时产生的，是一个临时的根文件系统(rootfs)。因为Kernel为了精简，只保留了最基本的模块，因此，Kernel上并没有各种硬件的驱动程序，也就无法识rootfs所在的设备，故产生了initrd这个文件，该文件装载了必要的驱动模块，当Kernel启动时，可以从initrd文件中装载驱动模块，直到挂载真正的rootfs，然后将initrd从内存中移除。 Kernel会以只读方式挂载根文件系统，当根文件系统被挂载后，开始装载第一个进程(用户空间的进程)，执行/sbin/init，之后就将控制权交接给了init程序。 Init init，初始化，顾名思义，该程序就是进行OS初始化操作，实际上是根据/etc/inittab(定义了系统默认运行级别)设定的动作进行脚本的执行，第一个被执行的脚本为/etc/rc.d/rc.sysinit，这个是真正的OS初始化脚本，简单讲下这个脚本的任务(可以去看看实际脚本，看看都做了什么)： 激活udev和selinux; 根据/etc/sysctl.conf文件，来设定内核参数; 设定系统时钟; 装载硬盘映射; 启用交换分区; 设置主机名; 根文件系统检测，并以读写方式重新挂载根文件系统; 激活RAID和LVM设备; 启用磁盘配额; 根据/etc/fstab，检查并挂载其他文件系统; 清理过期的锁和PID文件 执行完后，根据配置的启动级别，执行对应目录底下的脚本，最后执行/etc/rc.d/rc.local这个脚本，至此，系统启动完成。 Runlevel runlevel，运行级别，不同的级别会启动的服务不一样，init会根据定义的级别去执行相应目录下的脚本，Linux的启动级别分为以下几种： 0：关机模式 1：单一用户模式(直接以管理员身份进入) 2：多用户模式（无网络） 3：多用户模式（命令行） 4：保留 5：多用户模式（图形界面） 6：重启 在不同的运行级别下，/etc/rc.d/rc这个脚本会分别执行不同目录下的脚本： Runlevel 0 – /etc/rc.d/rc0.d/ Runlevel 1 – /etc/rc.d/rc1.d/ Runlevel 2 – /etc/rc.d/rc2.d/ Runlevel 3 – /etc/rc.d/rc3.d/ Runlevel 4 – /etc/rc.d/rc4.d/ Runlevel 5 – /etc/rc.d/rc5.d/ Runlevel 6 – /etc/rc.d/rc6.d/ 这些目录下的脚本只有K*和S*开头的文件，K开头的文件为开机需要执行关闭的服务，S开头的文件为开机需要执行开启的服务。 ","date":"2016-05-21","objectID":"/system_start/:0:2","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"参考 http://www.thegeekstuff.com/2011/02/linux-boot-process/ [http://www.ibm.com/developerworks/library/l-linuxboot/]( ","date":"2016-05-21","objectID":"/system_start/:0:3","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Network"],"content":"谈谈DNS","date":"2016-05-21","objectID":"/dns/","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"写在前面 目前，我们大部分的网络通信都是基于TCP/IP协议的，而TCP/IP又基于IP地址作为唯一标识进行通信，随着需要记忆的IP地址数量的增多，肯定会超出我们的记忆能力范围，但如果使用一种利于人们的记忆的方式，如域名，例如\"www.google.com”，我们便可以轻松的记忆这种方式的标识，而不是繁杂的数字。而DNS(域名系统)就是为了可以使用这种方式提供服务的。 ","date":"2016-05-21","objectID":"/dns/:0:1","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"概念 DNS(Domain Name System)，域名系统，它是因特网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。 DNS Domain Namespace，DNS域命名空间，是一种分层树状结构，其格式如下:“www.google.com”,以点”.“为分隔。结构如图所示： 根域：绝对域名(FQDN)，以点”.“结尾的域名 顶级域：用来指示某个国家/地区或组织使用的名称的类型名称，例如.com 二级域：个人或组织在因特网上使用的注册名称，例如google.com 子域：已注册的二级域名派生的域名，一般就是网站名，例如www.google.com 主机名：标识网络上的特定计算机，例如h1.www.google.com DNS资源记录：(即映射关系，通常由域名管理员进行配置)，常见类型如下： SOA：起始授权机构 NS：名称服务器 MX：邮件服务器 A：IP地址(最常用，映射IP地址) CNAME：别名(较常用，映射到其他域名) ","date":"2016-05-21","objectID":"/dns/:0:2","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"DNS工作原理 当我们请求一个域名时，会通过DNS服务器将域名解析成IP访问最终的主机，那么，DNS是如何查询到域名所对应的IP并返回给我们的呢？请工作机制如图所示： 当我们请求一个域名时，直到获取到IP地址，整个过程是如何工作的？以请求www.codecc.xyz为例： 首先，我们的主机会去查找本地的hosts文件和本地DNS解析器缓存，如果hosts文件和本地DNS缓存存在www.codecc.xyz和IP的映射关系，则完成域名解析，请求该IP地址，否则进入第二步。 当hosts和本地DNS解析器缓存都没有对应的网址映射关系，则会根据机器(/etc/reslove.conf)配置的本地DNS服务器进行查询，此服务器收到查询时，如果要查询的域名在本地配置区域资源或者缓存中存在映射关系，则跳到步骤9，将解析结果直接返回给客户机。 PS：一二步骤为递归查询，其余步骤为迭代查询 若本地DNS服务器不存在该域名的映射关系，就把请求发送至13台根DNS服务器。 根DNS服务器会判断这个域名(.xyz)由谁来授权管理，并返回一个负责该顶级域的DNS服务器的一个IP给本地DNS服务器。 本地DNS服务器收到该IP后，会再将查询请求发送至(.xyz)所在的DNS服务器。 如果(.xyz)的DNS服务器无法解析该域名，就会去判断这个二级域名(codecc.xyz)的管理者，返回一个负责该二级域的DNS服务器的IP给本地DNS服务器。 本地DNS服务器收到该IP后，会再次将查询请求发送至(codecc.xyz)所在的DNS服务器。 (codecc.xyz)的DNS服务器会存有www.codecc.xzy的映射关系，将解析后的IP返回给本地DNS服务器 本地DNS服务器根据查询到的解析IP发送给客户机，至此，DNS解析完成。 ","date":"2016-05-21","objectID":"/dns/:0:3","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"常用DNS查询命令 windows： nslookup 域名 Linux： nslookup 域名 dig 域名 ","date":"2016-05-21","objectID":"/dns/:0:4","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Domain_Name_System https://technet.microsoft.com/en-us/library/cc772774(v=ws.10).aspx 《TCP/IP详解卷1：协议》 ","date":"2016-05-21","objectID":"/dns/:0:5","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Security"],"content":"WEB安全之CSP","date":"2016-05-20","objectID":"/webcsp/","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"概念 内容安全策略(Content-Security-Policy，CSP)：是一种web应用技术用于帮助缓解大部分类型的内容注入攻击，包括XSS攻击和数据注入等，这些攻击可实现数据窃取、网站破坏和作为恶意软件分发版本等行为。该策略可让网站管理员指定客户端允许加载的各类可信任资源。 ","date":"2016-05-20","objectID":"/webcsp/:0:1","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"浏览器支持 统计来源：caniuse.com/contentsecuritypolicy \u0026 Mozilla ","date":"2016-05-20","objectID":"/webcsp/:0:2","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"指令参考 Content-Security-Policy 响应头的值可配置一个或多个，多个指令以分号;隔开。 指令 示例 描述 default-src ‘self’ cdn.example.com 默认配置，若其他指令没有配置，都以此配置的规则为准 script-src ‘self’ js.example.com 定义允许加载的JavaScript来源 style-src ‘self’ css.example.com 定义允许加载的样式表来源 img-src ‘self’ img.example.com 定义允许加载的图片来源 connect-src ‘self’ 适用于XMLHttpRequest(AJAX),WebSocket或EventSource，当为不允许的来源，浏览器返回一个400的状态码。 font-src font.example.com 定义允许加载的字体来源 object-src ‘self’ 定义允许加载的插件来源.eg,\u003cobject\u003e,\u003cembed\u003e或\u003capplet\u003e media-src media.example.com 定义允许加载的audio和video.eg,HTML5,\u003caudio\u003e,\u003cvideo\u003e元素 frame-src ‘self’ 定义允许加载的框架来源 sandbox allow-forms allow-scripts 授权一个沙箱用来请求具有iframe sanbox等类似属性的资源,该沙箱默认为同源策略,禁止弹出窗口,执行插件和脚本.若要允许其他,可增加配置:allow-forms,allow-same-origin,allow-scripts,allow-top-navigation report-uri /some-report-uri 该配置让浏览器发送一个失败报告到指定的路径，也可以增加-Report-only到HTTP头,让浏览器只发送报告(不做阻止动作) ","date":"2016-05-20","objectID":"/webcsp/:0:3","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"来源配置参考 所有的指令都要在配置后面添加来源列表，多个来源列表可用空格隔开，*和none只能存在一个。 指令 示例 描述 * img-src * 无限制，允许所有 ‘none’ object-src ‘none’ 禁止加载任何路径的资源 ‘self’ script-src ‘self’ 允许加载同源的资源 data: img-src ‘self’ data: 允许通过数据模式加载资源 domain.ccc.com img-src img.ccc.com 允许加载匹配域名的资源 *.ccc.com img-src *.ccc.com 允许加载匹配域名的资源 https://img.ccc.com img-src https://img.ccc.com 允许加载匹配https方式的域名资源 https: img-src https: 允许加载所有匹配https方式的资源 ‘unsafe-inline’ script-src ‘unsafe-inline’ 允许使用内联元素,类似,Style attribute,onclick,scripttag bodies ‘unsafe-eval’ script-src ‘unsafe-eval’ 允许不安全的动态编码，例如eval() ","date":"2016-05-20","objectID":"/webcsp/:0:4","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"例子 只允许加载同源的所有资源 default-src 'self'; 支持*号匹配 default-src 'self' https://*.ccc.com:*; 只允许加载同源的脚本 script-src 'self'; 只允许加载同源的和www.ccc.com的脚本 script-src 'self' www.ccc.com; ","date":"2016-05-20","objectID":"/webcsp/:0:5","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"常见配置 该策略允许加载同源的图片、脚本、AJAX和CSS资源，并阻止加载其他任何资源，对于大多数网站是一个不错的配置。 default-src 'none'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; 被禁止时的报错信息： 谷歌浏览器可通过谷歌开发工具查看该报错，通常是按F12 Refused to load the script ‘script-uri’ because it violates the following Content Security Policy directive: “your CSP directive”. Firefox 可通过 Web Developer Tools 查看报错 Content Security Policy: A violation occurred for a report-only CSP policy (“An attempt to execute inline scripts has been blocked”). The behavior was allowed, and a CSP report was sent. ","date":"2016-05-20","objectID":"/webcsp/:0:6","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"参考 http://content-security-policy.com/ https://developer.mozilla.org/en-US/docs/Web/Security/CSP http://www.w3.org/TR/CSP2/ ","date":"2016-05-20","objectID":"/webcsp/:0:7","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Network"],"content":"初识网络通信","date":"2016-05-18","objectID":"/network_comm/","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"写在前面 在计算机刚出现的时候，只能在本机进行一些运算处理，想将一台计算机中的数据转移到另一台计算机中，需要通过外部存储介质来传输，例如磁带、软盘。而网络技术的出现，使得计算机间可以通过一些传输介质(网线、光纤等)，实现快速的数据传输和信息交互。如今，网络已无处不在，那么，计算机之间究竟是如何通信的呢？下面会通过一些基础的网络知识来简单理解计算机之间的通信过程。 ","date":"2016-05-18","objectID":"/network_comm/:0:1","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"网络通信模型 网络通信模型是一种概念模型和框架，旨在使各种计算机在世界范围内互连为网络。其中有OSI七层模型和TCP/IP四层模型，现在大部分网络通信都是以TCP/IP四层模型为基础的。 它们的对应层次如下图： OSI有七层：从上到下依次为应用层、表示层、会话层、传输层、网络层、数据链路层、物理层 TCP/IP有四层：从上到下依次为应用层、传输层、互连层(网络层)、网络接口层(链路层)。 因为目前大部分TCP/IP模型，所以就以TCP/IP为例，我们来理解下数据间的通信，下图是两台计算机通信的数据的传输过程： ","date":"2016-05-18","objectID":"/network_comm/:0:2","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"数据封装 在详细了解TCP/IP每一层各自的作用前，先要理解数据封装的概念，数据在通过网络接口传送出去前，会经过层层封装，每层都会在前面的基础上添加自己的信息，在传输到对方计算机后，又会被层层进行解封装后得到最后的数据。其过程如下图所示： ","date":"2016-05-18","objectID":"/network_comm/:0:3","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"TCP/IP参考模型 TCP/IP参考模型是一个抽象的分层模型，这个模型中，所有的TCP/IP系列网络协议都被归类到4个抽象的\"层\"中。每一抽象层创建在低一层提供的服务上，并且为高一层提供服务。 完成一些特定的任务需要众多的协议协同工作，这些协议分布在参考模型的不同层中的，因此有时称它们为一个协议栈。 应用层(Application Layer) 该层包括所有和应用程序协同工作，利用基础网络交换应用程序专用的数据的协议。 应用层是大多数普通与网络相关的程序为了通过网络与其他程序通信所使用的层。这个层的处理过程是应用特有的；数据从网络相关的程序以这种应用内部使用的格式进行传送，然后被编码成标准协议的格式。 常见的应用层协议有HTTP、FTP、DNS、SNMP(基于UDP) 传输层(Transport Layer) 主要为两台主机上的应用程序提供端到端的通信，包括TCP协议（传输控制协议）和UDP（用户数据报协议）。 端口号由此层提供，且在一台计算机中具有唯一性。 UDP为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。 TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等,由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。 因为TCP是一种面向连接的协议，所以两个在使用TCP的应用在彼此交换数据前必须先建立一个TCP连接，也就是有名的TCP三次握手，如下图所示： 建立连接协议过程：（TCP三次握手协议） 客户端发送一个SYN段指明客户打算连接的服务器的端口，以及初始序号（ISN）。 服务器发回包含服务器的初始序号的SYN报文段作为应答。同时，将确认序号设置为客户的ISN加1以对客户的SYN报文段进行确认。一个SYN占用一个序号。 客户将确认序号设置为服务器的ISN加1以对服务器的SYN报文段进行确认。 网络层(Internet Layer) 处理分组在网络中的活动。网络层协议包括IP协议（网际协议），ICPM协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议），其中的IP协议身是TCP/IP协议簇中最为核心的协议。IP提供的是不可靠、无连接的数据包传送服务。 IP地址 讲到IP协议就应该讲讲IP地址，IP地址是分配给网络上使用IP协议的设备的数字标签，有IPv4和IPv6两大类，我们目前使用的大部分还是IPv4的地址，以下简称IP地址，IP地址由32位二进制数组成，为便于使用，常以XXX.XXX.XXX.XXX形式表示。 IP地址由两个字段组成：网络号(net-id)和主机号(host-id)，为方便IP地址管理，IP地址被分为五类，如下图： 其中A、B、C类地址为单播（unicast）地址；D类地址为组播（multicast）地址；E类地址为保留地址，以备将来的特殊用途。目前大量使用中的IP地址属于A、B、C三类地址。 A类地址范围：0.0.0.0～127.255.255.255 B类地址范围：128.0.0.0～191.255.255.255 C类地址范围：192.0.0.0～223.255.255.255 私网地址范围：10.0.0.0～10.255.255.255 ，172.16.0.0～172.31.255.255 ，192.168.0.0～192.168.255.255，私网地址只能在本地局域网中使用，不在公网中使用。 子网和掩码 传统的IP地址分配方式，对IP地址的浪费非常严重。为了充分利用已有的IP地址，人们提出了掩码（mask）和子网（subnet）的概念。 掩码是一个与IP地址对应的32位数字，这些数字中一些为1，另外一些为0。原则上这些1和0可以任意组合，不过一般在设计掩码时，网络号码和子网号码的比特值为1，主机号码的比特值为0。掩码可以把IP地址分为两个部分：子网地址和主机地址。IP地址与掩码中为1的位对应的部分为子网地址，其他的位对应的部分则是主机地址。当不进行子网划分时，子网掩码即为默认值，此时子网掩码中“1”的长度就是网络号码的长度。即A类地址对应的掩码默认值为255.0.0.0；B类地址的掩码默认值为255.255.0.0；C类地址掩码的默认值为255.255.255.0。 路由 概念：若目的主机与源主机在同一共享网络内，IP数据报直接送达目的主机，否则，主机把数据报发往默认的路由器上，由路由器进行数据报转发。 链路层(Link Layer) 通常包括设备驱动程序和网络接口卡。处理与传输媒介的物理接口细节。 主要协议有：ARP协议和RARP协议 MAC地址 ：数据链路层具有自己的寻址机制(48bit地址)，当一台主机把以太网数据帧发送到位于同一局域网上得另一台主机时，是根据48bit的以太网地址来确定目的接口的。 而ARP和RARP协议是为IP地址和MAC地址提供映射的： ","date":"2016-05-18","objectID":"/network_comm/:0:4","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"使用 我们在判断两台主机应用之间的网络是否正常，通常是判断到对方IP和端口是否能通。 常用网络判断命令： Windows ping $IP：最常用的判断网络是否可达的命令。 tracert $IP：跟踪路由，即打印出本机到到目的IP，所经过路由。 telnet $IP $port：可以测试某个IP和应用端口是否能通。 netstat：查看本机监听和建立连接的端口。 Linux ping $IP：最常用的判断网络是否可达的命令 traceroute $IP：跟踪路由，即打印出本机到到目的IP，所经过路由。 或者使用mtr -ni 0.1 $IP，可以实现以上两个共同的效果 nc -vz $IP $PORT：测试到目的IP的应用端口是否能通。 netstat -tupln：可以查看本机目前监听的端口 ","date":"2016-05-18","objectID":"/network_comm/:0:5","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Internet_protocol_suite 《TCP/IP详解卷1:协议》 ","date":"2016-05-18","objectID":"/network_comm/:0:6","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":null,"content":"About CC Software Developer Networking Engineer ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"About Mess","uri":"/about/"},{"categories":null,"content":"Working Experience CF (2019-current) DevOps Engineer CNC (2015-2018) Operations Engineer(SA) ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"About Mess","uri":"/about/"},{"categories":null,"content":"Focus \u0026 Interests Linux Networking Cloud Native Golang, Shell DevOps ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"About Mess","uri":"/about/"}]