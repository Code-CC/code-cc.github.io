[{"categories":["Nginx"],"content":"执行阶段","date":"2021-01-30","objectID":"/openresty_phases/","tags":["nginx"],"title":"Openresty执行阶段","uri":"/openresty_phases/"},{"categories":["Nginx"],"content":"Nginx执行阶段 NGX_HTTP_POST_READ_PHASE — 第一阶段， ngx_http_realip_module 在此阶段注册其处理程序，以允许在调用任何其他模块之前替换客户端地址。 NGX_HTTP_SERVER_REWRITE_PHASE — 该阶段处理server块(location块除外)定义的rewrite指令。 ngx_http_rewrite_module 在此阶段安装其处理程序。 NGX_HTTP_FIND_CONFIG_PHASE — 根据请求URI选择位置的特殊阶段。在此阶段之前，将相关虚拟服务器的默认位置分配给请求，并且任何请求位置配置的模块都将接收默认服务器位置的配置。该阶段为请求分配一个新位置。该阶段无法注册其他处理程序。 NGX_HTTP_REWRITE_PHASE — 同 NGX_HTTP_SERVER_REWRITE_PHASE, 但处理的是上一个阶段选择的location块内的定义的rewrite规则指令。 NGX_HTTP_POST_REWRITE_PHASE — 特殊阶段，如果请求的URI在rewirte期间更改，则将请求重定向到新的location块。这是通过再次请求 NGX_HTTP_FIND_CONFIG_PHASE 来完成的。此阶段无法注册其他处理程序。 NGX_HTTP_PREACCESS_PHASE — 与访问控制无关的用于不同类型的处理程序的公共阶段。标准nginx模块 ngx_http_limit_conn_module 和 ngx_http_limit_req_module 在此阶段注册其处理程序。 NGX_HTTP_ACCESS_PHASE — 验证客户端请求是否合法的阶段。例如ngx_http_access_module 和 ngx_http_auth_basic_module 等标准nginx模块在此阶段注册其处理程序。默认情况下，客户端必须通过该阶段所有处理程序的合法验证才能继续请求下一个阶段。 通过satisfy 指令，则可以允许客户端在通过该阶段任何一个处理程序的合法验证后直接进入下一个阶段。 NGX_HTTP_POST_ACCESS_PHASE — 特殊阶段，处理满足 satisfy any 指令的阶段。如果某些访问阶段处理程序拒绝了访问并且没有显式允许访问，则该请求完成。此阶段无法注册其他处理程序。 NGX_HTTP_PRECONTENT_PHASE — 在生成内容之前调用处理程序的阶段。一些标准nginx模块如 ngx_http_try_files_module 和 ngx_http_mirror_module 在此阶段注册其处理程序。 NGX_HTTP_CONTENT_PHASE — 正常生成响应的阶段. 多个Nginx标准模块在此阶段注册其处理程序, 包括 ngx_http_index_module 和 ngx_http_static_module。它们按顺序被调用直到某一个模块产生输出。也可以按location设置内容处理程序，如果 ngx_http_core_module的location配置已设置处理程序，则将其称为内容处理程序，并且在此阶段安装的处理程序将被忽略。 NGX_HTTP_LOG_PHASE — 执行请求日志记录的阶段。当前，只有 ngx_http_log_module 在此阶段注册其处理程序以进行访问日志记录。在释放请求之前，在请求处理的最后阶段调用日志阶段处理程序。 ","date":"2021-01-30","objectID":"/openresty_phases/:0:1","tags":["nginx"],"title":"Openresty执行阶段","uri":"/openresty_phases/"},{"categories":["Nginx"],"content":"Lua执行阶段 init_by_lua* — 在Nginx master 进程加载配置时候时，在全局LuaVM 级别上运行指定的lua代码。通常在该阶段注册全局变量或者预加载lua模块。 init_worker_by_lua* — 启用master进程后，在每次Nginx worker进程启动时运行指定的Lua代码。当禁用master进程时，此hook将仅在init_by_lua *之后运行。通常用于创建每个worker的重复计时器（通过Lua API的ngx.timer.at），也用于后端运行状况检查或其他定时例行工作。 ssl_certificate_by_lua* — 当Nginx即将启动下游https连接的SSL握手时，此指令运行用户Lua代码。 set_by_lua* — 该指令旨在执行简短，快速运行的代码块，因为在代码执行期间会阻止Nginx事件循环。因此，应该避免耗时的代码队列。 rewrite_by_lua* — 充当rewrite阶段处理程序，并针对每个请求执行指定的Lua代码字符串。 Lua代码可以进行API调用，并在独立的全局环境（即沙箱）中作为新生成的协程执行。请注意，此处理程序始终在标准ngx_http_rewrite_module之后运行。 access_by_lua* — 充当access阶段处理程序。请注意，此处理程序始终在标准ngx_http_access_module 之后运行。 content_by_lua* — 充当content阶段处理程序。 balancer_by_lua* — 该指令将Lua代码作为upstream{}配置块定义的任何upstream实体的upsteam balancer 运行 header_filter_by_lua* — 执行lua代码用于定义输出header过滤器 body_filter_by_lua* — 执行lua代码用于定义输出body过滤器 log_by_lua* — 在日志请求处理阶段执行lua代码，此操作不会替代当前的access日志，而是在它之前执行。 参考 nginx-http-phases openresty-reference ","date":"2021-01-30","objectID":"/openresty_phases/:0:2","tags":["nginx"],"title":"Openresty执行阶段","uri":"/openresty_phases/"},{"categories":["Cloud Native"],"content":"Kubernetes成熟度模型","date":"2021-01-28","objectID":"/k8s_model/","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"原文链接：kubernetes maturity model 水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。 ","date":"2021-01-28","objectID":"/k8s_model/:0:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"前言 Kubernetes有很多好处。 同时，当组织采用云原生技术时，它可能变得复杂。 Kubernetes成熟度模型的存在可帮助您确定自己在迁移到原生云的过程中所处的位置，无论您是Kubernetes的新手还是有部署经验的人。 这是一个重要的工具，可帮助您自我确定您所处的阶段，了解环境中的差距并获得有关增强和改善Kubernetes技术栈的见解。 ","date":"2021-01-28","objectID":"/k8s_model/:1:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"如何使用Kubernetes成熟度模型 Kubernetes和您的工作负载在不断变化。 使用此成熟度模型时，请知道，如果确实达到某个阶段，则可能仍需要重新访问以前的阶段。 另外，请注意，Kubernetes的成熟并非一朝一夕就能完成，而是需要时间。 Kubernetes成熟度模型应用作工具，以帮助您了解在迁移到云原生过程中需要集中精力或需要帮助的地方。 ","date":"2021-01-28","objectID":"/k8s_model/:1:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"1. 准备阶段 从哪里开始？如何证明k8s的价值？谁可以信任？ 在该阶段，你将学习/精通以下内容： 云原生和k8s将如何帮助推动业务和技术目标。它将耗费什么？并就整个组织的目标达成共识。 明白云原生、容器、以及k8s的价值 能够向企业领导者描述该价值 得到团队，领导和整个组织的支持 ","date":"2021-01-28","objectID":"/k8s_model/:2:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 明白你的问题 为什么要使用kubernetes？想要通过kubernetes解决什么问题？ 同意使用OSS 转换到kubernetes需要你明白开源软件(OSS)在云原生生态中的角色和能量 接受投资未来 kubernetes的旅程将会耗费大量的时间和金钱。你需要面向未来投资。 ","date":"2021-01-28","objectID":"/k8s_model/:2:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 在采用Kubernetes时，第一步是准备工作。在这里，理解并能够阐明云原生和Kubernetes为什么对组织很重要至关重要。一些核心概念包括理解云原生计算，容器和Kubernetes的价值和影响。在较高的层次上，我们在这里每个定义。 Cloud Native 云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。 云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。我们通过将最前沿的模式民主化，让这些创新为大众所用。 Source: CNCF definition. 云原生计算的好处包括更快的发布速度，易于管理，通过容器化和云标准降低了成本，能够构建更可靠的系统，避免了供应商锁定以及改善了客户应用体验。 Container 一个打包代码及其所有依赖项的标准软件单元，使得应用程序可以从一个计算环境快速可靠地运行到另一个计算环境 Source: Docker 在k8s中，你运行的每个容器都是可重复的；通过包含依赖项实现标准化意味着无论您在哪里运行它，都可以得到相同的行为。容器将应用程序与基础主机基础结构分离。这使得在不同的云或OS环境中的部署更加容易 Source: CNCF concepts. Kubernetes Kubernetes是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 它拥有一个庞大且快速增长的生态系统。 Kubernetes的服务，支持和工具广泛可用。Kubernetes为您提供了一个可弹性运行分布式系统的框架。 它负责应用程序的扩展和故障转移，提供部署模式等。 Source: CNCF What is Kubernetes. Infrastructure as code (IAC) 使用配置语言配置和管理基础结构的能力。 IAC为网络，负载平衡器，虚拟机，Kubernetes集群和监视等基础架构的管理带来了现代软件开发的可重复性，透明性和测试。 IAC的主要目标是减少错误和配置漂移，同时允许工程师将时间花在更高价值的任务上。 IAC定义了基础架构的最终状态，而不是定义要执行的一系列步骤-像Terraform这样的IAC工具可以针对您的基础架构多次运行，从而产生相同的预期结果。 使用云用户界面创建托管的Kubernetes集群是一个相对简单的过程，但是使用基础结构作为代码有助于标准化集群配置并管理集群节点的附件，例如网络策略，维护窗口以及身份和访问管理（IAM） 和工作量。 ","date":"2021-01-28","objectID":"/k8s_model/:2:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"公司和文化的改变 云原生实践，容器和Kubernetes的采用可以有助于实现战略业务目标，包括通过适当的功能来帮助最大程度地节省成本，适应需求，降低和分散风险。 它还代表了整个组织的文化变化。在准备进行转型时，您需要团队，领导层和整个组织的支持，因为这将需要不同的技能，新的团队结构和改变的意愿。 ","date":"2021-01-28","objectID":"/k8s_model/:2:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 在准备阶段，可能面临的挑战： 从何处开始或谁信任和倾听的不确定性。 不确定您的用例是否可行或可转换到云原生/ Kubernetes世界 需要证明业务价值/领导成本 ","date":"2021-01-28","objectID":"/k8s_model/:2:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 您的技术计划与业务/领导力支持相辅相成，以取得成功。 您接受并交流文化和跨职能工作流程的变化。 您接受这一旅程将需要大量的投资和对新技术的信任。 您了解开源软件（OSS）在云原生生态系统中的作用和功能。 您已经考虑并确认了希望获得的价值 你知道你的业务重点。 您了解有关安全性，效率和可靠性的要求。 ","date":"2021-01-28","objectID":"/k8s_model/:2:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Deep Dive into Core Concepts Kubernetes Basic Training Why Infrastructure as Code and Kubernetes How to Create, View and Destroy a Pod in Kubernetes ","date":"2021-01-28","objectID":"/k8s_model/:2:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"2. 改造阶段 如何设置Kubernetes基础架构并转移工作负载？ 在该阶段，你将学习/精通以下内容： Kubernetes的基础知识以及采用和转换现有思维方式，工作流程和实践到平台的能力。 你将精通kubernetes术语，并能够将现有技术映射到云原生环境 你将容器化你的应用并把工作负载转移到kubernetes上 你将清理你的技术债务并避免把它带到kubernetes上 ","date":"2021-01-28","objectID":"/k8s_model/:3:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 理解核心概念 你将为采用kubernetes做花费时间理解核心概念的准备。 全组织范围接受 您可以在整个组织中进行购买，以投资Kubernetes概念证明或将Kubernetes用于所有新应用程序。 优先级工作负载 您了解使用分阶段方法计划迁移到Kubernetes的工作负载 ","date":"2021-01-28","objectID":"/k8s_model/:3:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 转变是您迁移到Kubernetes的阶段。在该阶段，你将通过部署你的第一个集群和负载来验证您的基础知识和理解。在改造阶段，您应该对基础知识有所准备，但同时可能缺乏完成该阶段所需的专业知识。 你将花费大量的时间在该阶段。进行一些关键活动时，它涵盖了您的初始实施，迁移和学习曲线。当您采用Kubernetes时，不要被“启动并运行”的文章所迷惑。在设置集群和准备生产之间存在功能差距。您可能会发现在此阶段进行Kubernetes概念验证或与Kubernetes专家合作以确保您正在设置第一个集群以满足工作负载的需求很有帮助。 ","date":"2021-01-28","objectID":"/k8s_model/:3:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"采用新的语言和架构体系 当你要采用kubernetes时，你不只是做简单的准备，你将开始练习和理解新的语言、架构和负载需求。 术语学习 在准备阶段，你可能已经明白了一些术语，但在改造阶段期间，你将需要使用所有的kubernetes术语。一些必要的概念将包含在内，包括node、pod、namespace、ReplicaSet、控制器等等。尽管事先进行培训很重要，但是在实践中您会接触到每个功能时，您会更好地理解它们。 应用架构和理解需求 你需要将应用架构映射到新的云原生环境中。这样做将帮助您发现需求并发现应用程序的依赖关系，以便您可以成功拥抱容器。它还将使您能够重新查看以前的历史假设和决策。例如： Old World New World SSH to server Deploy by code and immutable infrastructure Dedicated workloads Self-healing and ephemeral workloads Add server to scale Add a pod or nod to scale Configuration management for deployment Containerization for deployment 工作负载理解 你将理解运行在集群中内不同类型的工作负载：Deployments、Jobs、CronJobs、ReplicaSet、DaemonSets和Pods ","date":"2021-01-28","objectID":"/k8s_model/:3:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"技术改造 在第二阶段，你将开始在kubernetes上运行工作负载。为了成功应对技术改造，有10个主要的步骤需要执行。这是您将要执行的每个步骤的简要概述。准备在此过程的每个步骤上花费大量时间。 深入理解和项目计划 - 无论您是在本地，在数据中心还是已经迁移到云，您的第一步是深入研究现有技术栈。您需要调查技术栈的各个方面，从基础网络，基础结构，配置，密钥管理到如何部署应用程序及其依赖项。迁移到Kubernetes时，您需要确定对技术的要求。该步骤帮助你避免遗漏重要的依赖。在这次深入研究的基础上，您可以制定一个项目计划，这是您进行迁移的路线图。 应用容器化 - 您的应用程序可能已经被容器化了，在这种情况下，您可以继续执行第三步了。如果不是，则需要根据 twelve-factor app 方法细分应用程序。这非常重要，因为您将需要使应用程序能够生存下去（您的容器随时可能被杀死）。您需要能够干净地站立您的应用程序和容器。在此步骤中，我们建议您从构建工件中提取密钥和配置。 Kubernetes是短暂的，因此，您可以维护标准和安全性，并在容器运行时简单地注入密钥和配置。 建立云基础设施 - 你需要确认你的云服务提供商：AWS、GCP、Azure或者像EKS、GKS和AKS的kubernetes管理服务。如果你选择了kubernetes管理服务，你就不需要额外的工作用于构建你自己的kubernetes基础设施。此步骤的一部分，您需要设置基础云配置，VPC，安全组，身份验证和授权等。 构建Kubernets基础设施 - 在该步骤，需要考虑一些设计注意事项，以避免做出可能需要耗时的集群重建或网络和成本影响的选择。类似的注意事项有：您应该在哪些区域拥有多少个群集，并具有多少个可用区（AZ）？需要多少个单独的环境，集群和命名空间？服务之间应如何相互通信和发现？安全性是在VPC，集群还是Pod级别上？您的重点应该放在可重复性上。您将需要利用基础架构作为代码（IaC），以便可以以一种重复的方式构建集群。在此步骤中，请谨慎使用第一步中的深度研究/项目计划中的配置选项，以确保您不会错过应用程序要求。 编写YAML或者Helm charts - 在Fairwinds，我们将此步骤称为Kubernating。在这里定义Kubernetes资源以将其放入集群中。可以在此处编写Kubernetes资源YAML文件，但是现在大多数都使用Helm charts将应用程序部署到Kubernetes中。您将专门为您的容器镜像，配置映射模板，密钥或任何特殊应用程序要求编写YAML或Helm charts。 深入了解外部云依赖性 - 你的应用可能会有外部的依赖，例如key store，库、数据库或者其他资产。Kubernetes不是这些依赖生存的好地方。您将需要在Kubernetes之外管理您的有状态依赖关系。例如，您可以使用Amazon RDS之类的工具中的独立数据库，然后将其放入Kubernetes中。然后，您的应用程序可以在Kubernetes的pod中运行，并与这些依赖项对话。 定义Git工作流程 - Kubernetes的一个主要优点是能够以可重复的方式部署代码而无需人工干预。您通常会通过Git将代码提交到代码仓库，这将启动事件并与将这些更改移动到非生产集群的分支合并。然后，您将对代码进行测试和质量检查，然后合并到master中。这会将您的代码部署到登台或生产中。在此阶段，您只需定义Git工作流的外观即可，即当开发人员推送代码时，Kubernetes会发生什么？ 构建CI/CD管道 - 定义Git工作流程后，您将使用Jenkins或CircleCI等自动化工具来设置CI / CD平台。这会将您定义的工作流程转变为实际的构建管道。 非生产测试 - 完成单片式应用程序或微服务架构的步骤1-8之后，您将部署到非生产环境。在这里，您将使用该应用程序以确保其运行，具有足够的资源和限制，测试您的机密信息是否正确以及人们可以访问该应用程序。您将测试杀死pod会发生什么情况。从本质上讲，您将在开始生产之前踢一下轮胎。如果您运行的是整体应用程序，则可以更快地完成此阶段。如果要部署微服务应用程序体系结构，则将为每个服务完成步骤1-8，然后将其部署到非生产环境。一旦所有服务都存在，您就可以看到它们如何协同工作以确保您的应用程序一旦投入生产，应用是正常工作的。 生产推广 - 最后，一旦您在非生产环境中对应用程序进行了全面测试并对此感到满意，只要您构建的生产环境与登台相同，就可以部署流量并将其发送到您的应用程序。在这里，您只需更改负载平衡器或DNS。使用DNS，您可以根据需要进行故障回复。 ","date":"2021-01-28","objectID":"/k8s_model/:3:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"债务清理 在实施Kubernetes时，您将有机会清理现有系统中产生的技术债务。 技术债务可以概括为持续吸引人们注意力以完成任务的任何工作流，流程，代码或硬件。 这可能包括已推迟的升级或更新，已解决的代码错误，旧版本依赖性或错误的配置。 自然地，当您迁移到Kubernetes时，您可以评估该技术债务的存在位置，从而避免在新环境中复制它。 ","date":"2021-01-28","objectID":"/k8s_model/:3:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"生产力增加与损失 Kubernetes提供了机会来更改和改进团队协作以及交付应用程序或服务的方式。随着您的转变，您的团队也会发生变化。 Kubernetes是一个巨大的变化。您将采用一种新的工作方式，团队中的每个人都会以不同的方式学习该技术。开始时，随着您和您的团队对技术的适应，生产率将会受到影响。在此阶段要有耐心，因为长期的生产率收益将超过短期的损失。 ","date":"2021-01-28","objectID":"/k8s_model/:3:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"工具 您需要决定如何做出有关工具的决定，包括： 您如何确定哪些问题需要工具解决方案 谁负责做出该决定？ 您如何审核工具？ 对于开源工具，您需要评估每个工具是否定期更新，以及是否有足够的社区支持来避免工具过时。在此阶段花时间与使用Kubernetes的开发人员合作回答这些问题。 ","date":"2021-01-28","objectID":"/k8s_model/:3:7","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"在控制与最终灵活性之间取得平衡 Kubernetes的一个好处是开发人员无需操作团队即可提交代码的能力。 所需要的是好的政策，以确保安全性，可靠性和效率。 挑战在于，在设置第一个集群时，需要在为开发人员提供最终灵活性或控制基础架构之间取得平衡。 您是否会在一开始就向开发人员开放Kubernetes，以免影响生产力？ 还是会锁定系统？ 您将使用哪些配置来限制更改？ 您必须考虑如何平衡开发人员需求和公司政策。 ","date":"2021-01-28","objectID":"/k8s_model/:3:8","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 在转换期间，您可能会面临以下挑战： 被复杂性淹没 庞大的Kubernetes生态系统导致决策瘫痪 缺乏内部专业知识或人才流失 Kubernetes最佳实践/执行的不确定性 这些挑战是任何IT环境的常见疑问。使用Kubernetes时也是如此，但是在这一领域的人才或专业知识甚至更少。如果出现这些挑战，您可以从托管的Kubernetes服务寻求帮助。 另外，您的团队中存在现有的行为。花时间了解哪些行为至关重要，哪些行为可以更改，哪些历史不再需要，何处存在可以简化的复杂性。 ","date":"2021-01-28","objectID":"/k8s_model/:3:9","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 您将在转换阶段投入大量时间并建立您的知识库 您将确定在Kubernetes中使用哪些应用程序 您将考虑整体解决方案与开放源代码和专有技术的拼凑而成 您将了解Kubernetes的基础知识，优点和缺点 您将成功进行Kubernetes的概念验证，因此您将能够决定是否继续 ","date":"2021-01-28","objectID":"/k8s_model/:3:10","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Why Managed Services with EKS, GKE or AKS Strengths and Weaknesses of AKS, EKS and GKE Intro to Kubernetes + How to Deploy a Multi-tiered Web Application ","date":"2021-01-28","objectID":"/k8s_model/:3:11","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"3. 部署阶段 实施流程，CI / CD，赋予开发人员权力并引入一些监控和可观察性。 在该阶段，你将学习/精通以下内容： Kubernetes实现了基线理解。您正在通过进行基本的开发，部署，管理和故障排除来练习技能。你将： 为您的Kubernetes工作负载奠定坚实的基础 准备在您的组织中部署Kubernetes 通过CI / CD实施构建和部署过程，并引入了一些有限的监控和可观察性。 使开发人员能够自助 ","date":"2021-01-28","objectID":"/k8s_model/:4:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 应用容器化/kubernetes设置 您将采用容器并成功运行Kubernetes POC或建立基础架构。 在预发环境运行工作负载 您将在预生产中拥有工作负载，或者可能具有某些生产级部署。 建立的过程 您将建立初始的Git工作流程，建立CI / CD管道并建立适当的测试流程。 ","date":"2021-01-28","objectID":"/k8s_model/:4:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 当您达到此阶段时，您和您的团队将掌握基本知识。现在，一个应用程序或服务正在生产中运行，可以正确地了解外部依赖关系，通过负载平衡器将流量路由到Kubernetes，并且可以访问日志记录和指标。您还将拥有自动缩放功能。 Kubernetes成熟度模型的这一阶段让您承担所有工作，包括实施构建和部署过程，设置CI / CD，赋予开发人员权力以及引入一些有限的监视和可观察性。 您将在此阶段熟悉所有Kubernetes基础知识。这很重要，因此您可以建立坚实的基础。您几乎已经超过了学习曲线的驼峰。 ","date":"2021-01-28","objectID":"/k8s_model/:4:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"CI/CD 您将开始建立结构化的构建和部署过程，以展示云和容器本机CI / CD系统的质量。 CI / CD将成为用于构建和部署的经过功能验证的工作流程。 您和您的团队可以半可靠地将代码交付给工作和生产环境，可以通过Git分支和标签管理部署，并可以判断构建和部署是否成功。 范围更广的团队了解部署的结果，包括应更改的内容以及在何处可以到达端点。最后，随着部署过程的成熟，CI / CD将有助于在部署过程的早期发现问题。 ","date":"2021-01-28","objectID":"/k8s_model/:4:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"赋予开发人员和运维人员权力 您的开发人员应有权部署到Kubernetes。为了使之成为可能，您的团队将对从源代码管理（scm）到部署的工作流程有基本的了解，并有权访问scm中的合并/标记提交以触发部署。开发人员需要能够执行CI / CD流程的基本调试，并具有对Kubernetes资源定义或Helm图表的kubectl访问。 同时，您将希望操作员以及开发人员可以访问Kubernetes API，以确保他们了解工作负载在何处以及如何查看其状态。 这是确保他们能够调试在Kubernetes中遇到的简单错误或阻止程序的重要部分。 为确保Kubernetes取得成功，请在此阶段花费时间进行培训，并授权所有开发人员和操作团队进行这些活动。 ","date":"2021-01-28","objectID":"/k8s_model/:4:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"用户基础 在此阶段，您的团队将能够操作Kubernetes的基础知识。这包括学习和执行Kubernetes操作基础知识，包括： 将操作员连接到Kubernetes API 了解如何列出和查看资源 执行基本动作（对动作如何理解有限的机械动作） ","date":"2021-01-28","objectID":"/k8s_model/:4:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"有限的监控和可视化 您需要运营商和开发人员将监视和可观察性纳入他们的工作负载中。有流行的开源工具，例如Prometheus，还有来自Datadog等供应商的工具。在基础阶段，您将开始使用这些工具，对群集的监视和可观察性有限。您将开始了解工作量和基础结构的哪些方面需要深入了解或保持关注。 ","date":"2021-01-28","objectID":"/k8s_model/:4:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"策略\u0026审核工具 在基础阶段结束时，您和您的团队将寻求工具来帮助您成熟的Kubernetes环境。这将包括探索开源工具open source tooling ，以帮助解决安全性，策略管理，工作负载配置错误，资源请求和限制等问题。您还可以探索来自软件供应商的工具，这些工具为Kubernetes提供策略驱动的解决方案。policy-driven solutions for Kubernetes. ","date":"2021-01-28","objectID":"/k8s_model/:4:7","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 在基础阶段，您可能会面临以下挑战： 新的概念和技能可能会使团队进度缓慢或陷入困境 曾经工作的东西不太一样 尚未深入了解，一些问题似乎无法解决或令人沮丧 你有很多问题，没人可以解答 您可能会花费时间询问Kubernetes的问题是否可以解决，从生态系统寻求帮助或寻求Kubernetes专家的帮助。 ","date":"2021-01-28","objectID":"/k8s_model/:4:8","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 你已经为Kubernetes工作负载奠定了坚实的基础 您有信心并准备在整个组织中部署Kubernetes 企业看到了Kubernetes的价值 ","date":"2021-01-28","objectID":"/k8s_model/:4:9","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Kube 101 Training Best Practices for Implementing CI/CD Pipelines in Kubernetes Kubernetes: What Needs Monitoring and Why Most Helpful Kubernetes Open Source Projects We Use ","date":"2021-01-28","objectID":"/k8s_model/:4:10","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"4. 建立自信阶段 建立对自己的核心能力的信心，以成功地定期部署和发布功能。 在该阶段，你将学习/精通以下内容： 建立核心能力，以成功地定期部署和发布功能。您正在建立更深刻的理解，从而导致更多的自定义，实验和更广泛的组织使用。您将： 通过经验建立信心 围绕基础设施即代码和配置建立核心标准 选择可以紧密协作的Kubernetes附加组件 开始使用监控工具来帮助您了解服务挑战 ","date":"2021-01-28","objectID":"/k8s_model/:5:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 在生产环境运行工作负载 现在，你已经运行部分或者全部的工作负载在生产环境 实施CI/CD 您已经建立了CI / CD管道，它是经过功能验证的工作流程，用于构建和部署 初始化监控和可视化 您已经开始使用监视和可观察性工具来确定Kubernetes基础架构中的差距。 ","date":"2021-01-28","objectID":"/k8s_model/:5:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 随着Kubernetes环境的成熟，您将奠定坚实的基础。现在，当您进入成熟度模型的第四阶段时，就该建立信心了。在第三阶段，您已经建立并运行了Kubernetes基础架构。在第四阶段，您将开始了解Kubernetes的细微差别。 重要的是要记住，建立信心将需要时间，因为您重复执行任务并经历类似的情况。 ","date":"2021-01-28","objectID":"/k8s_model/:5:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"每天都有新的理解 想象你是刚刚学习骑自行车的时候，您可能可以直线骑行。建立信心时，您将开始转弯，越过颠簸，甚至在没有握住把手的情况下骑行。在第三阶段中，您学习了如何骑自行车，现在在第四阶段中，当您通过经验了解细微差别时，每天都在学习新的提示和技巧。 您会在某些方面感到很自在，但对其他方面则缺乏信心。例如，随着您对活动性和就绪性探针的熟悉，您将了解微小的配置更改如何改变工作负载的行为。您将更有能力进行更改以产生积极的影响。另一个示例是您可能已经制定了安全策略，但是不能确保所有群集都具有符合要求的配置。 在此阶段，您将了解这些细微差别，然后开始在团队中培训其他人。这将帮助您进一步建立信心。 当您建立信心时，您的好奇心将围绕您迄今为止所经历的事情以及如何进行改进而增加。如果您的Kubernetes集群出现故障，您将进行试验而不是惊慌。 ","date":"2021-01-28","objectID":"/k8s_model/:5:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"胜任力 您在选择和实施第三方工具以增强Kubernetes体验方面的核心能力将会增强。您将研究有助于提高安全性的工具(Trivy, Polaris, Kubesec)，设置正确的资源利用率(Goldilocks)或帮助进行升级 (Nova)等等。 您还可以胜任正在执行的非标准活动，以及已更改和自定义的默认活动。 ","date":"2021-01-28","objectID":"/k8s_model/:5:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"排查故障 您还将对故障排除更有信心。也许您的应用程序在每次部署时都会崩溃，而您却不知道为什么。您将开始研究配置并研究资源。以前您知道这个概念，但是您不了解它对应用程序的影响。现在，您发现没有为应用程序提供足够的资源来启动它。 您现在有一个可重复进行的故障排除周期，因此更改可以快速完成并反复进行，直到它们起作用为止。 ","date":"2021-01-28","objectID":"/k8s_model/:5:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 在基础阶段，您可能会面临以下挑战： 担心单点故障和故障排除 团队实践不统一 对所做的决定感到遗憾 功能缺失 令人失望的表现 对您的Kubernetes集群充满信心与经验有关。但是，许多团队缺乏学习工作所需的时间。培训，专业和托管服务，审计和配置验证可在此提供帮助。 ","date":"2021-01-28","objectID":"/k8s_model/:5:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 通过经验以及Kubernetes专家培训，专业和托管服务，审计和配置验证的帮助，您已经对Kubernetes集群建立了信心。 您正在尝试使用Kubernetes，因为您已经实现了有关基础架构的代码（IaC）和配置标准 您开始监视和了解您的服务挑战 您可以放心地选择加载项，但是在部署和管理所有工具时会遇到挑战 ","date":"2021-01-28","objectID":"/k8s_model/:5:7","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Kubernetes Audit and Improve 5 Kubernetes Security Tools You Should Use Managing Kubernetes Configuration for Security, Reliability and Efficiency ","date":"2021-01-28","objectID":"/k8s_model/:5:8","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"5. 改进操作阶段 提升集群的安全性、可靠性和效率 在该阶段，你将学习/精通以下内容： 在整个企业中成功部署Kubernetes 通过花费时间配置集群来提高安全性，效率和可靠性 你的团队可以聚焦于业务，而不是维护kubernetes 您的挑战现在很复杂，需要您的内部团队以外的Kubernetes专业知识。 ","date":"2021-01-28","objectID":"/k8s_model/:6:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 kubernetes自信 你以前通过经验建立了在kubernets上的自信 标准实施 你已经建立了CI/CD，IaC和配置的标准 开始监控 您开始监视和了解您的服务挑战。 ","date":"2021-01-28","objectID":"/k8s_model/:6:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 到达kubernetes成熟度模型的该阶段是一个标志性的里程碑。您将定期成功地将功能部署和交付到Kubernetes中。您的开发人员将会满意： 预计它们会影响Kubernetes的术语，例如Deployment，Daemon Set，Service或Namespace 修改Kubernetes资源的某些配置，例如ConfigMap或Helm图表 对CI / CD过程进行故障排除 对Kubernetes中的应用程序/服务进行故障排除，包括访问日志和事件以及检索指标/监控 您不仅拥有基础知识，而且现在可以专注于改善运营。 ","date":"2021-01-28","objectID":"/k8s_model/:6:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"安全、效率和可靠 为了使组织成功采用Kubernetes，您将需要花费时间来提高安全性，效率和可靠性。重要的是要了解有关这些主题的配置。 安全 您需要确定谁负责Kubernetes集群安全以及如何对其进行管理。您是否可以快速识别配置错误，从而在容器和Kubernetes实施中留下安全漏洞？ 效率 Kubernetes是否有效运行？谁负责监视资源利用率，以确保您不会过度配置资源或配置资源不足。您的应用程序或服务的范围是什么？ 可靠 Kubernetes是否会带来任何停机挑战？系统可靠吗？您是否实现了所有的自我修复，自动缩放功能，并且没有引入配置问题？ 这些领域中的每一个都需要您和您的团队制定策略并建立方法，以轻松确保在整个集群中实施这些策略。策略驱动的配置验证可以帮助： 在CI / CD阶段通过开放策略代理（OPA）集成或作为准入控制器来实施自定义策略 通过在应用程序开发期间检测问题来防止错误，从而防止错误首先进入生产环境 通过自动扫描容器中的漏洞并审核群集中的漏洞来节省时间 通过确定如何提高Kubernetes计算资源的效率来降低成本 ","date":"2021-01-28","objectID":"/k8s_model/:6:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 与每个成熟阶段一样，您会遇到新的痛点。您可能会遇到以下挑战： 复杂性现在不在您的舒适范围内 维护和运营工作量很大，并花费了团队时间和精力 团队担心人员不足，无聊，分心或技能不足以应对更深的Kubernetes挑战 达到这一成熟水平时，克服这些挑战可能会很复杂。它可能需要内部雇用专家，但是预算可能不存在。这是培训，专业和托管服务，审计和配置验证可以提供帮助的另一个领域。 ","date":"2021-01-28","objectID":"/k8s_model/:6:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 您在Kubernetes成熟度上取得了重要的里程碑 通过花费时间配置群集来提高安全性，效率和可靠性 您的团队将能够专注于您的业务，而不是维护Kubernetes 第五阶段不是终点线。如果不进行第6阶段和第7阶段，您将永远不会意识到Kubernetes的全部好处和价值。 ","date":"2021-01-28","objectID":"/k8s_model/:6:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Kubernetes Audit and Improve Kubernetes Best Practices for Security Closing the Kubernetes Services Gap Kubernetes Best Practices for Reliability Kubernetes Best Practice for Efficient Resource Utilization ","date":"2021-01-28","objectID":"/k8s_model/:6:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"6. 测量\u0026控制 通过复杂的监控来推动策略和控制，从而对工作负载有更深入的了解。 在该阶段，你将学习/精通以下内容： 复杂的监视和警报功能可让您对工作负载有更深入的功能了解。您将： 围绕允许的行为，安全性，配置和标准，提出更强的见解和更严格的控制 将基础结构作为代码和CI / CD驱动的流程加倍 探索网络策略，工作负载标识和服务网格以锁定工作负载能力 ","date":"2021-01-28","objectID":"/k8s_model/:7:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 部署和发布 您定期成功部署和发布功能 集群配置 您正在花费时间通过评估群集来提高安全性，效率和可靠性 团队聚焦于业务 您的Kubernetes基础架构是生产级的（技术部门有限），使您的团队可以专注于您的应用程序或服务 ","date":"2021-01-28","objectID":"/k8s_model/:7:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 Kubernetes成熟度的下一阶段是引入更多的环境测量和控制。 您和您的团队在Kubernetes中运作良好，具有全面的了解，并在整个组织范围内得到采用。 您正在对Kubernetes进行更深入的功能理解，并就如何在集群和整个环境中完成工作提出了意见。 此外，团队已准备好解决先前阶段的技术债务。 先前的阶段已经引入了一些监视和可观察性。在此阶段，您将收集并处理更多数据，见解和工具，以开始了解要测量和跟踪的内容以及如何控制Kubernetes。 ","date":"2021-01-28","objectID":"/k8s_model/:7:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"更复杂的监视和警报 现在，使用更复杂的监视和警报是帮助了解常见问题，Kubernetes错误以及如何解决它们的重点。 您将更熟悉如何构建监视仪表板以在需要帮助之前发现问题和常见的错误配置。 当问题发生时，您也将知道它们的大致位置，以便更轻松地进行故障排除。 ","date":"2021-01-28","objectID":"/k8s_model/:7:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"测量和跟踪 在此阶段，您将开始改进衡量Kubernetes环境并跟踪成功的方式。测量将围绕五个关键领域： 安全 - 您将测量容器或群集中存在多少个漏洞以及哪些漏洞，以及修补工作负载，群集或附加组件的频率/时间。 审计 - 您将创建一个审计跟踪，以了解谁最近执行了操作以及集群中工作负载正在执行哪些操作。您将能够确定是否发生了未经授权的访问或操作。 漂移 - 您将能够确定哪些工作负载不符合您的标准，正在运行哪些版本的依赖项/集群附加组件以及工作负载是否与Kubernetes的未来版本兼容。 效率 - 您将进行测量以跟踪工作负载的典型或标准资源使用情况以及集群中节点的典型容量/使用情况。您还将知道群集扩展的频率。 速度 - 您将采取措施提高开发速度。这将包括了解部署的发布频率，多少用户访问您的集群以及在集群内执行的最常见操作。 ","date":"2021-01-28","objectID":"/k8s_model/:7:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"控制 您将在工作负载和其他Kubernetes资源方面遇到痛苦，主要是在一致性方面。 工作负载可能不一致，也可能手动部署，然后进行修改。 跨容器和群集的配置中可能存在差异，这对于识别，更正和保持一致可能是一个挑战。 工作负载可能会杂乱无章，影响其他工作负载。 工作负载可能访问过多，从而导致安全问题。 可能存在可靠性或可伸缩性问题（无法充分扩展或扩展得太频繁）。 由于使用过多的资源或未清理工作负载，成本可能会攀升至很高。 随着您和您的团队的成熟，所有这些要点都是很自然的。在此阶段中，您要围绕安全性，配置和工作流来制定控制策略。以下是您需要考虑的一些示例。 ","date":"2021-01-28","objectID":"/k8s_model/:7:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"安全 Kubernetes工作负载安全性至关重要。您需要控制群集权限，并且应该能够回答： 谁有权访问集群 用户可以在集群中执行哪些操作？ 工作负载在集群中可以采取什么行动？ 集群中具有什么级别的权限工作负载？ 集群中工作负载之间的网络策略是什么？ ","date":"2021-01-28","objectID":"/k8s_model/:7:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"配置 坚固的Kubernetes环境将具有用于一致性的配置标准。您应该在以下位置设置控件： Kubernetes资源的住处和定义位置？ 什么变化会在何时发生？ 您的资源代码审查流程是什么？ 集群中可以部署什么类型的资源？ 哪些名称空间可供哪些用户使用？ 哪些名称空间工作负载部署到？ 如何设置可用于工作负载或名称空间的资源量？ 您在工作负载/部署中常见的标准/默认设置是什么？ ","date":"2021-01-28","objectID":"/k8s_model/:7:7","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"工作流 同样，您将建立工作流，以了解如何部署工作负载和服务，升级路径和职责： 谁可以将工作负载和服务部署到您的集群？ 如何将工作负载和服务部署到您的集群？ 环境之间的提升路径是什么？ 谁负责您的环境的哪些方面？ 通过回答这些问题，您现在将拥有一组策略来开始在集群中实施配置更改。 您还具有Kubernetes经验，可以循环回到这些更高级的主题。 您将重新访问可能只是选择了默认选项的配置，检查发生了什么并进行更改。 ","date":"2021-01-28","objectID":"/k8s_model/:7:8","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 跨工作负载，集群，团队的配置和流程不一致 用户和工作负载具有过多的访问权限，并且可能以不安全的方式运行/操作。 常见的可靠性问题很麻烦，并且由于缺乏有效的监视/警报而无法很好地理解。 ","date":"2021-01-28","objectID":"/k8s_model/:7:9","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 第六阶段将使您能够改善和完善Kubernetes环境，以确保其能够满足您的业务需求。 它还可以帮助您重新访问以前的阶段，以便在迁移新应用或设置新环境时避免引入不必要的问题。 您可能在成熟的这个阶段需要帮助，以确定可以在哪里进行改进。 在这里，对Kubernetes环境进行审核是一个很好的工具。 您也可以使用配置验证工具。 退出第六阶段时，您将建立协议和程序，以便团队与系统保持一致的交互并了解优先级。 您还将对基础架构（如代码和CI）有深入的了解 ","date":"2021-01-28","objectID":"/k8s_model/:7:10","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Kubernetes: What Needs Monitoring and Why Kubernetes Audit and Improve Managing Kubernetes Configuration for Security, Reliability and Efficiency Why Infrastructure as Code and Kubernetes ","date":"2021-01-28","objectID":"/k8s_model/:7:11","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"7. 优化\u0026自动化 消除人为错误和辛劳，提高可靠性并最大化效率。 在该阶段，你将学习/精通以下内容： 使用更复杂的工具来消除人为错误和辛劳，提高可靠性并最大程度地提高效率。 ","date":"2021-01-28","objectID":"/k8s_model/:8:0","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"必要条件 改进和完善 您正在衡量和跟踪Kubernetes部署，以确保其交付符合业务需求。 建立协议 您已经制定了协议，策略和过程，因此团队可以与系统和优先级保持一致的交互。 IaC和CI/CD 您对作为代码和CI / CD的基础架构有深刻的理解，有助于一次性更改。 ","date":"2021-01-28","objectID":"/k8s_model/:8:1","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"介绍 随着Kubernetes完全成熟，您现在将专注于优化和自动化环境。这包括优化Kubernetes的成本和效率，尽可能自动化以及定期运行配置验证以检查错误。 ","date":"2021-01-28","objectID":"/k8s_model/:8:2","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"优化 现在，您正在跟踪和测量，您将在仪表板中拥有数据。这将帮助您优化Kubernetes使其更加高效或可靠。您将进行一些细微的改变，从而产生很大的变化。如，您可以通过以下方式优化群集： 根据您的工作负载需求使用正确的实例类型 扩展自定义指标与通用CPU使用率 转向多地区以更有效地为全球交通服务 跟踪和管理云支出成本 通过增加工作负载弹性来降低升级风险 您将永远不会停止优化集群。随着新数据的出现以及您的应用程序可与更多用户一起运行，您将需要不断查看仪表板并进行调整。这是成熟的最后阶段，很难做到。您需要一次解决一个问题以进行优化。 ","date":"2021-01-28","objectID":"/k8s_model/:8:3","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"自动化 这是成熟的顶峰。到目前为止，您一直在手工做所有事情。在这里，您要自动化在前六个阶段中手动完成的所有操作。例如，您将： 查看您的基础架构即代码（IaC）以确保其牢固 使用监视失败来重新启动或管理有问题和失败的资源 自动审核并标记配置错误或安全问题 从生产中删除人员访问权限，转而使用服务帐户 通过软件和工具构建，升级和备份系统和基础架构 ","date":"2021-01-28","objectID":"/k8s_model/:8:4","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"配置验证 最后，您将使用CI / CD流程中内置的配置验证工具，以确保不会将安全性，可靠性和效率问题部署到生产中。使用按政策编码，您将能够： 通过在CI / CD阶段或作为准入控制器的Open Policy Agent（OPA）集成，自动化部署护栏和最佳安全实践。 在应用程序开发过程中自动进行问题检测，以防止错误从一开始就进入生产。 通过扫描容器中的漏洞并审核群集中的弱点，可以持续了解Kubernetes的安全状况。 ","date":"2021-01-28","objectID":"/k8s_model/:8:5","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"挑战 您可能会面临以下挑战： 从CI / CD到生产的政策管理 工作负载和其他Kubernetes资源使用资源效率低下，扩展不正确或性能不佳 成本攀升或不为人知 可靠性问题仍然需要大量的人为干预和辛劳 ","date":"2021-01-28","objectID":"/k8s_model/:8:6","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"输出 您将通过策略驱动的容器和Kubernetes配置验证来简化从开发到操作的交接，从而加强法规遵从性。 在CI / CD流程到生产过程中都包含策略执行，可防止错误引起安全性或可靠性挑战。 您正在使用OPA创建自定义策略。 您可以深入研究Kubernetes的可靠性，效率和安全性实践。 ","date":"2021-01-28","objectID":"/k8s_model/:8:7","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["Cloud Native"],"content":"学习资源 Managing Kubernetes Configuration for Security, Reliability and Efficiency Kubernetes Security, Reliability, Efficiency: It’s all about Configuration Fairwinds Insights: CI Pipeline to Protect Your Kubernetes Clusters Managing OPA Policies with Fairwinds Insights Addressing Kubernetes Security Vulnerabilities with Policy Enforcement ","date":"2021-01-28","objectID":"/k8s_model/:8:8","tags":["kubernetes","translate"],"title":"[译]Kubernetes成熟度模型","uri":"/k8s_model/"},{"categories":["DevOps"],"content":"翻译","date":"2021-01-13","objectID":"/talk_ops/","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"原文链接：What the Ops are you talking about? 水平有限，本文不免存在遗漏或错误之处。如有疑问，请查阅原文。 ","date":"2021-01-13","objectID":"/talk_ops/:0:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"背景 两年前，我因为效率低下的领导而获得了耻辱。我的背景是数据科学和机器学习，因此，我当然从我的工程同事那边学习到了DevOps。至少我们认为是这样的。 令人费解的是，即使我们遵循了日常站立会议所有敏捷开发的良好实践，讨论我们的难点，也没有将难题扔给别人的态度。我们紧密合作并且相互友爱。但是开发效率依然缓慢，这令整个团队很沮丧。 两年过后，我终于掌握了DevOps的含义，并且理解了它在数据团队中如此的相同而又如此不同。 ","date":"2021-01-13","objectID":"/talk_ops/:1:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"什么是Ops？ 在我们谈论以数据为中心的Ops时，先让我们从软件开始说起， 自从09年DevOps普及以来，软件行业就一直痴迷于各种Ops术语。十年前，从软件开发到部署的方法已经推陈出新。软件工程师开发应用，然后将其交付给运维工程师。该应用程序在部署期间经常中断，并在团队之间造成很大的摩擦。 DevOps实践的目的是简化部署过程。该想法是将自动化视为构建和部署软件应用程序的一等公民。 这种想法彻底改变了这个行业。许多组织开始建立跨职能团队来照顾整个SDLC。该团队将建立基础架构（基础工程师），开发应用程序（软件工程师），构建CI/CD管道（DevOps工程师），部署应用程序（每位工程师），然后连续监视和观察应用程序（站点可靠性工程师）。 在一个大团队里面，一个工程师可能只会有一项主要职能，但是在较小的团队中，一位工程师经常担任许多职务。理想的情况是使许多团队成员能够履行多项职能，从而消除瓶颈和关键人员的依存关系。所以实际上， DevOps并非是一项工作职能，而是更多的实践或文化。 在开始构建任何软件时都应采用它。 随着DevOps的兴起，各种各样的Ops诞生了。 SecOps以安全性为核心，GitOps致力于持续交付，NetOps确保网络可以支持数据流，而ITOps则专注于软件交付之外的操作任务。但是，这些操作的基石都源自DevOps所承诺的愿景： 在错误最小的情况下尽可能快的发布软件 ","date":"2021-01-13","objectID":"/talk_ops/:2:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DataOps 🆚 MLOps 🆚 DevOps (and AIOps?) 注意：在本文中，分析团队是指使用SQL / PowerBI来生成业务洞察力的传统BI团队。 AI团队是指使用大数据技术构建高级分析和机器学习模型的团队。 有时他们是同一个团队，但我们将它们分开，以便更容易地解释概念。 五年前，“数据是新石油”一语成为炒作对象。世界各地的领导者开始倾注资源，建立大数据团队来挖掘这些宝贵的资产。这些团队交付的压力巨大—毕竟，我们如何才能兑现新石油的承诺？随着快速扩展，分析团队也经历了同样的痛苦。 然后，我们使这一切成为现实。 数据科学家成为21世纪最吃香的职业。我们正在建立和处于数据和分析的黄金时代。每个执行者都有一个仪表板，具有来自整个组织的数据和嵌入式预测模型的仪表板，每个客户都有基于其行为的个性化推荐。 但是，现在添加一个新功能需要花费数周甚至数月的时间。数据模型是混乱的并且没有人知道我们是使用信贷团队还是营销团队的活跃客户的定义。我们变得非常警惕将模型推向生成环境，因为我们不知道我们会破坏什么？ 因此，以数据为中心的社区团结在一起，保证不会因管理不善的数据流程而造成的效率低下，从那时起，各种以数据为中心的OPS诞生了 要了解所有这些不同的Ops，让我们来看看数据如何在组织中流动的场景： 数据是由与软件应用程序交互的客户生成的 软件将数据存储在其应用程序数据库中 分析团队从组织中的团队使用这些应用程序数据库构建ETL 然后，数据工程师将原始数据，合并的数据集（来自分析团队）和其他非结构化数据集摄取到某种形式的数据湖中 然后，数据科学家根据这些庞大的数据集建立模型 然后，这些模型采用用户生成的新数据进行预测。 然后，软件工程师将预测结果呈现给用户 并且周期继续 我们知道DevOps的诞生是由于开发团队和运维团队之间的摩擦。因此，想象一下运维，开发，分析和AI团队之间的4向界面所带来的令人头疼的问题。 为了说明不同的Ops如何解决上述过程，下面的图形绘制了每个作业功能在整个时间轴上执行的一些任务 理想情况下，应在项目开始时采用X-Ops文化，并在整个过程中实施实践. 总而言之，这就是每个Ops的意义 ","date":"2021-01-13","objectID":"/talk_ops/:3:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DevOps更快地交付软件 一系列实践旨在消除开发团队和运维团队之间的障碍，以便更快地构建和部署软件。工程团队通常采用它，包括DevOps工程师，基础架构工程师，软件工程师，站点可靠性工程师和数据工程师。 ","date":"2021-01-13","objectID":"/talk_ops/:3:1","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"DataOps更快地交付数据 一系列实践旨在提高数据分析的质量和减少周期时间。DataOps主要的任务包括数据打标、数据测试、数据管道编排、数据版本控制和数据监控。分析和大数据团队是DataOps主要的支撑对象，但是任何生成和使用数据的人都应该采用良好的DataOps做法，其中包括数据分析师，BI分析师，数据科学家，数据工程师，有时还包括软件工程师。 ","date":"2021-01-13","objectID":"/talk_ops/:3:2","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"MLOps更快地提供机器学习模型 一套设计，构建和管理可重现，可测试和可持续的ML支持软件的实践。对于大数据/机器学习团队，MLOps包含大多数DataOps任务和其他特定于ML的任务，例如模型版本控制，测试，验证和监视。 ","date":"2021-01-13","objectID":"/talk_ops/:3:3","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"奖励：AIOps利用AI的功能增强了DevOps工具 有时人们会错误地将MLOps称为AIOps，但它们却大不相同。从Gartner： AIOps platforms utilize big data, modern machine learning and other advanced analytics technologies to directly and indirectly enhance IT operations (monitoring, automation and service desk) functions with proactive, personal and dynamic insight. 因此，AIOps通常是使用AI驱动技术来增强服务产品的DevOps工具。 AWS CloudWatch提供的警报和异常检测是AIOps的一个很好的例子. ","date":"2021-01-13","objectID":"/talk_ops/:3:4","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"Principals not Job Roles 一个误解是，为了实现这些行动所承诺的效率，他们需要从选择正确的技术开始。事实上，技术不是最重要的东西。 DataOps，MLOps和DevOps的实践必须与语言，框架，平台和基础架构无关。 每个人都有不同的workflow，该workflow应由负责人告知——而不是你想尝试的技术或最受欢迎的技术。首先要去技术的陷阱是，如果您想使用锤子，一切对您来说就像钉子一样。 所有的Ops都有相同的7个主要原则，但每个Ops都有自己的细微差别： ","date":"2021-01-13","objectID":"/talk_ops/:4:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"1. 合规 DevOps通常担心网络和应用程序的安全性。在MLOps领域，金融和医疗保健等行业通常需要模型可解释性。DataOps需要确保数据产品符合GDPR / HIPPA等法律。 🔧 Tools: PySyft 解耦私人数据以进行模型训练， AirCloak 用于数据匿名. Awesome AI Guidelines 策划有关AI的原则，标准和法规。 ","date":"2021-01-13","objectID":"/talk_ops/:4:1","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"2. 迭代开发 该原理源于敏捷方法论，该方法论着重于以可持续的方式持续产生业务价值。该产品经过迭代设计，构建，测试和部署，以最大程度地快速排除故障并学习原理。 ","date":"2021-01-13","objectID":"/talk_ops/:4:2","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"3. 可重现性 软件系统通常是确定性的：每次代码都应以完全相同的方式运行。因此，为了确保可重现性，DevOps只需要跟踪代码即可。 但是，由于任一数据漂移，机器学习模型通常都需要重新训练。为了重现结果，MLOps需要对模型进行版本控制，而DataOps需要对数据进行版本控制。当审核员询问要使用哪些数据来训练哪种模型来产生特定结果时，数据科学家需要能够回答这一问题。 🔧 Tools: 实验跟踪工具, 例如 KubeFlow, MLFlow 或者 SageMaker 都具有将元数据链接到实验运行的功能。 Pachyderm 和 DVC 用于数据版本控制。 ","date":"2021-01-13","objectID":"/talk_ops/:4:3","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"4. 测试 软件测试在于单元测试，集成测试和回归测试。DataOps需要严格的数据测试，其中包括架构更改，数据漂移，功能设计后的数据验证等。从机器学习的角度来看，模型准确性，安全性，偏见/公平性，可解释性都需要进行测试。 🔧 Tools: 诸如 Shap \u0026 Lime 用于可解释性, fiddler 用于解释性监控, great expectation 用于数据测试. ","date":"2021-01-13","objectID":"/talk_ops/:4:4","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"5. 持续部署 这里有三个组件用于机器学习模型的持续部署： 第一个组件是触发事件，即触发是数据科学家手动触发，日历计划事件和阈值触发吗？ 第二个组件是新模型的实际再培训。导致该模型的脚本，数据和超参数是什么？它们的版本以及如何相互链接。 最后一个组件是模型的实际部署，该部署必须由具有预警功能的部署管道进行编排。 🔧 Tools: 大多数workflow管理工具都具有此功能，例如AWS SageMaker，AzureML，DataRobot等。开源工具例如Seldon, Kubeflow KFServing. ","date":"2021-01-13","objectID":"/talk_ops/:4:5","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"6. 自动化 自动化是DevOps的核心价值，实际上有很多专门针对自动化各个方面的工具。以下是机器学习项目的一些资源： Awesome Machine Learning Awesome Production Machine Learning ","date":"2021-01-13","objectID":"/talk_ops/:4:6","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"7. 监控 需要监视软件应用程序，机器学习模型和数据管道也需要监视。对于DataOps，监视新数据的分布是否有任何数据和/或概念漂移很重要。在MLOps方面，除了模型降级之外，如果您的模型具有公共API，监视对抗攻击也至关重要。 🔧 Tools: 大多数workflow管理框架都有某种形式的监控。. 其他流行的工具包括 Prometheus 用于指标监控, Orbit by Dessa 用于数据\u0026模型监控. ","date":"2021-01-13","objectID":"/talk_ops/:4:7","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["DevOps"],"content":"结论 采用正确的X-Ops文化，以加快数据驱动和机器学习驱动的软件产品的交付。请记住，有关技术的原则： 建立跨学科技能: 培养T型人才和团队，弥补差距并统一问责制 尽早实现自动化: 融合在技术堆栈上并实现自动化，减轻工程费用的流程 着眼于最终方案: 预先投资解决方案设计以减少从PoC到生产的摩擦 ","date":"2021-01-13","objectID":"/talk_ops/:5:0","tags":["devops","translation"],"title":"[译]当我们谈论Ops，我们在谈论什么","uri":"/talk_ops/"},{"categories":["Other"],"content":"flag","date":"2021-01-02","objectID":"/2021_flag/","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["Other"],"content":"2021年已经到来，在这里给自己列一个flag清单。 ","date":"2021-01-02","objectID":"/2021_flag/:0:0","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["Other"],"content":"习惯成自然 每2周完成一个ARTS(Algorithm|Review|Technique|Share) 完成12篇博客(每月一篇) 完成4篇英文技术文章翻译(每季度一篇) ","date":"2021-01-02","objectID":"/2021_flag/:0:1","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["Other"],"content":"读书清单 《性能之巅 洞悉系统、企业与云计算》 《Web性能权威指南》 ","date":"2021-01-02","objectID":"/2021_flag/:0:2","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["Other"],"content":"极客时间清单 程序员的数学基础课 MySQL实战45讲 ","date":"2021-01-02","objectID":"/2021_flag/:0:3","tags":["life"],"title":"2021年flag","uri":"/2021_flag/"},{"categories":["Cloud Native"],"content":"Ingress","date":"2020-10-10","objectID":"/k8s_series_ingress/","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_ingress/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"1. 介绍 ","date":"2020-10-10","objectID":"/k8s_series_ingress/:2:0","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"1.1 Ingress Ingress 公开了从集群外部到集群内service的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。 可以将 Ingress 配置为服务提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及提供基于名称的虚拟主机等能力。 Ingress Controller 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。 ","date":"2020-10-10","objectID":"/k8s_series_ingress/:2:1","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"1.2 Ingress Controller 为了让 Ingress 资源工作，集群必须有一个正在运行的 Ingress Controller。 ","date":"2020-10-10","objectID":"/k8s_series_ingress/:2:2","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"2. Ingress Contoller 选择 ","date":"2020-10-10","objectID":"/k8s_series_ingress/:3:0","tags":["kubernetes"],"title":"Kubernetes系列：Ingress","uri":"/k8s_series_ingress/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"1. 介绍 最近整体工作在往云原生和k8s上迁移，想将自己对于k8s的一些学习心得和经验写成一个系列记录下来。 ","date":"2020-10-10","objectID":"/k8s_series/:2:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"2. 云计算 云计算是一种按使用量付费的模式，这种模式提供可用的、便捷的、按需的网络访问， 进入可配置的计算资源共享池（资源包括网络，服务器，存储，应用软件，服务），这些资源能够被快速提供，只需投入很少的管理工作，或与服务供应商进行很少的交互。 云计算最基本的特性是：“按使用量付费”、“资源共享池”和多租户隔离。 1.2 云计算的特点 超大规模 云具有相当的规模，Google 云计算已经拥有 100 多万台服务器， Amazon、IBM、微软、Yahoo 等的云均拥有几十万台服务器。企业私有云一般拥有数百上千台服务器。云能赋予用户前所未有的计算能力。 虚拟化 云计算支持用户在任意位置、使用各种终端获取应用服务。所请求的资源来自云，而不是固定的有形的实体。应用在云中某处运行，但实际上用户无需了解、也不用担心应用运行的具体位置。只需要一台笔记本或者一个手机，就可以通过网络服务来实现我们需要的一切，甚至包括超级计算这样的任务。 高可靠性 云使用了数据多副本容错、计算节点同构可互换等措施来保障服务的高可靠性，使用云计算比使用本地计算机可靠。 通用性 云计算不针对特定的应用，在云的支撑下可以构造出千变万化的应用，同一个云可以同时支撑不同的应用运行。 高可扩展性 云的规模可以动态伸缩，满足应用和用户规模增长的需要。 按需服务 云是一个庞大的资源池，你按需购买;云可以像自来水，电，煤气那样计费。 极其廉价 由于云的特殊容错措施可以采用极其廉价的节点来构成云，云的自动化集中式管理使大量企业无需负担日益高昂的数据中心管理成本，云的通用性使资源的利用率较之传统系统大幅提升，因此用户可以充分享受云的低成本优势，经常只要花费几百美元、几天时间就能完成以前需要数万美元、数月时间才能完成的任务。 潜在的危险性 云计算服务除了提供计算服务外，还必然提供了存储服务。但是云计算服务当前垄断在私人机构(企业)手中，而他们仅仅能够提供商业信用。对于政府机构、商业机构(特别像银行这样持有敏感数据的商业机构)对于选择云计算服务应保持足够的警惕。一旦商业用户大规模使用私人机构提供的云计算服务，无论其技术优势有多强，都不可避免地让这些私人机构以数据(信息)的重要性挟制整个社会。 对于信息社会而言，信息是至关重要的。另一方面，云计算中的数据对于数据所有者以外的其他用户云计算用户是保密的，但是对于提供云计算的商业机构而言确实毫无秘密可言。所有这些潜在的危险，是商业机构和政府机构选择云计算服务、特别是国外机构提供的云计算服务时，不得不考虑的一个重要的前提。 1.3 云计算的分类 公有云：只有使用权，使用的时候进行按需付费。但数据放在别人家。数据安全没有保障。而且银行不会使用公有云，金融行业不要使用公有云。公有云的核心属性是共享资源服务。 私有云：自己的机房搭建的云，私有云有局限性，资源固定；数据比较安全。私有云的核心属性是专有资源。 混合云：主要任务放到私有云，临时需要时利用混合云，它将公有云和私有云进行混合匹配，以获得最佳的效果，这种个性的解决方案，达到二既省钱又安全的目的。 1.4 云计算分层 云计算也是层的，大概有以下几种： 传统 IT 基本所有的都需要自行管理，比如：网络、存储、服务器、虚拟化，操作系统、中间件、运行环境、数据、应用等。 IaaS: Infrastructure-as-a-Service（基础设施即服务） IaaS 主要作用是提供虚拟机或者其他资源作为服务提供给用户。 PaaS: Platform-as-a-Service（平台即服务） PaaS, 中文名为平台即服务。如果以传统计算机架构中 “硬件+操作系统/开发工具+应用软件” 的观点来看待，那么云计算的平台层应该提供类似操作系统和开发工具的功能。实际上也的确如此，PaaS 定位于通过互联网为用户提供一整套开发、运行和运行应用软件的支撑平台。就像在个人计算机软件开发模式下，程序员可能会在一台装有 Windows 或 Linux 操作系统的计算机上使用开发工具开发并部署应用软件一样。PaaS 某些时候也叫做中间件，主要作用是提供一个开发和运行平台给用户。 SaaS: Software-as-a-Service（软件即服务） SaaS，软件即服务。简单地说，就是一种通过互联网提供软件服务的软件应用模式。在这种模式下，用户不需要再花费大量投资用于硬件、软件和开发团队的建设，只需要支付一定的租赁费用，就可以通过互联网享受到相应的服务，而且整个系统的维护也由厂商负责。 如果要用一句话来概括 IaaS、PaaS 和 SaaS 的话，那就是：如果把云计算比喻成一部手机，那么 IaaS 就是硬件，你要自己写代码研发系统才能用；PaaS 是手机系统，你要实现什么功能还是要装各种软件；SaaS 就是硬件+系统+软件，你要干什么一句话就能解决。 ","date":"2020-10-10","objectID":"/k8s_series/:3:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"3. 虚拟化 2.1 虚拟化概念 虚拟化是通过软件手段对计算机硬件资源镜像整合管理和再分配的一种技术，常用的手段有基于虚拟机的虚拟化和基于容器的虚拟化。 2.2 虚拟化技术分类 2.2.1 按应用场景分类 操作系统虚拟化 应用程序虚拟化 桌面应用虚拟化 存储虚拟化 网络虚拟化 2.2.2 按照应用模式分类 一对多：其中将一个物理服务器划分为多个虚拟服务器，这是典型的服务器整合模式。 多对一：其中整合了多个虚拟服务器，并将它们作为一个资源池，这是典型的网格计算模式。 多对多：将前两种模式结合在一起。 2.2.3 按硬件资源调用模式分类 全虚拟化 全虚拟化，虚拟化操作系统与底层硬件完全隔离。由中间的 Hypervisor 层转化虚拟化客户操作系统对底层硬件的调用代码，全虚拟化无需更改客户端操作系统，并兼容性好。典型代表有：Vmware Workstation、KVM。 半虚拟化 半虚拟化，在虚拟客户操作系统中加入特定的虚拟化指令，通过这些指令可以直接通过 Hypervisor 层调用硬件资源，免除有 Hypervisor 层转换指令的性能开销。半虚拟化的典型代表 Microsoft Hyper-V、Vmware 的 vSphere。 注：针对 IO 层面半虚拟化要比全虚拟化要好，因为磁盘 IO 多一层必定会慢。一般说 IO 就是网络 IO 和磁盘 IO，因为这两个相对而言是比较慢的。 2.3 基于虚拟机（Hypervisor-based）的虚拟化 它通过一个软件层的封装，提供和物理硬件相同的输入输出表现。实现了操作系统和计算机硬件的解耦，将 OS 和计算机间从 1 对 1 变成了多对多（实际上是 1 对多）的关系。该软件层称为虚拟机管理器（VMM / Hypervisor），它可以直接运行在裸机上（Xen、VMware EXSi），也可以运行在操作系统上（KVM、VMware Workstation）。这项技术已经很成熟了,（发展了40 多年），但仍然存在以下几个问题： 在虚拟机上运行了一个完整的操作系统（GuestOS），在其下执行的还有虚拟化层和宿主机操作系统，一定比直接在物理机上运行相同的服务性能差； 有 GuestOS 的存在，虚拟机镜像往往有几个 G 到几十个 G，占用的存储空间大，便携性差； 想要使用更多硬件资源，需要启动一台新的虚拟机。要等待 GuesOS 启动，可能需要几十秒到几分钟不等。 实际使用场景中，我们使用虚拟化技术其实是为了按需分配资源来完成服务的部署和使用，同时对服务所依赖的环境进行隔离，不被其它服务感知或干扰。为此启动一个 GuestOS 并不是必需的，为什么不考虑让多个虚拟机公用一个操作系统内核，只隔离开服务运行环境同时控制服务使用的系统资源呢？基于容器的虚拟化就是这样一种技术。 2.4 基于容器的虚拟化 容器是没有 GuestOS 的轻量级虚拟机，多个容器共享一个 OS 内核，容器中包含需要部署的应用和它依赖的系统环境，容器大小通常只有几十到几百 MB。由于共享操作系统内核，所以容器依赖于底层的操作系统，各个操作系统大都有自己的容器技术和容器工具。 Docker 是一个 Linux 容器管理工具，随着 Docker 的兴起，Linux 容器技术也是当下最时兴的容器虚拟化技术。Linux 容器工具有很多，OpenVZ、LXC、Docker、Rocket、Lmctfy 等等，大都是基于 Linux 内核提供的两个机制：Cgroups（实现资源按需分配）和 Namespace（实现任务隔离）。 2.5 二种虚拟化技术的区别 虚拟机技术已经发展了很多年，虚拟机和虚拟化层间的接口、虚拟机镜像格式等都已经标准化了。相应的管理工具、分布式集群管理工具都有比较完善的解决方案，而容器最近几年才兴起，配套技术和标准还在完善中； 虚拟机由于有 GuestOS 存在，可以和宿主机运行不同 OS，而容器只能支持和宿主机内核相同的操作系统； 虚拟机由于有 VMM 的存在，虚拟机之间、虚拟机和宿主机之间隔离性很好。而容器之间公用宿主机的内核，共享系统调用和一些底层的库，隔离性相对较差； 容器比虚拟机明显更轻量级，对宿主机操作系统而言，容器就跟一个进程差不多。因此容器有着更快的启动速度（秒级甚至更快），更高密度的存储和使用（镜像小）、更方便的集群管理等优点。同时由于没有 GuestOS 存在，在容器中运行应用和直接在宿主机上几乎没有性能损失，比虚拟机明显性能上有优势。 ","date":"2020-10-10","objectID":"/k8s_series/:4:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"4. 容器 实际使用场景中，我们使用虚拟化技术其实是为了按需分配资源来完成服务的部署和使用，同时对服务所依赖的环境进行隔离，不被其它服务感知或干扰。为此启动一个GuestOS并不是必需的，为什么不考虑让多个虚拟机公用一个操作系统内核，只隔离开服务运行环境同时控制服务使用的系统资源呢？基于容器的虚拟化就是这样一种技术。其中最著名的就是Docker了 Docker是以Docker容器为资源分割和调度的基本单位，封装整个运行时环境，为开发者和系统管理员设计的，用于构建、发布、和运行分布式应用的平台。它是一个跨平台，可移植并且简单易用的容器解决方案。 容器技术的好处 持续部署与测试 容器消除了线上线下的环境差异，保证了应用生命周期的环境一致性和标准化。开发人员使用镜像实现标准开发环境的构建，开发完成后通过封装着完整环境和应用的镜像进行迁移。由此，测试和运维人员可以直接部署软件镜像来进行测试和发布，大大简化了持续集成、测试和发布的过程。 跨平台支持 容器带来的最大好处之一就是其适配性，越来越多的云平台都支持容器，用户再也无需担心应平台的捆绑，同时也能让应用多平台混合部署成为可能。目前支持容器的IaaS平台包括但不限于亚马逊平台（AWS)、Google云平台（GCP）、微软云平台（Azure）、OpenStack等，还包括如Chef、Puppet、Ansible等配置管理工具。 环境标准化和版本控制 基于容器提供的环境一致性和标准化，你可以使用Git等工具对容器镜像进行版本控制，相比于代码的版本控制来说，你还能够对整个应用运行环境实现版本控制，一旦出现故障可以快速回滚。相比以前的虚拟机镜像，容器压缩和备份速度更快，镜像启动也像启动一个普通进行一样快速。 高资源利用率与隔离 容器没有管理程序的额外开销，与底层共享操作系统，性能更加优良，系统负载更低，在同等条件下可以更充分地利用系统资源。同时，容器拥有不错的资源隔离与限制能力，可以精确地对应用分配CPU和内存等资源，保证了应用间不会相互影响。 容器跨平台与镜像 linux容器虽然早在Linux 2.6版本内核已经存在，但是缺少容器的跨平台性，难以推广。容器在原有Linux容器的基础上大胆革新，为容器设定了一整套标准化的配置方法，将应用依赖的运行环境打包成镜像，真正实现了“构建一次，到处运行”的理念，大大提高了容器的跨平台性。 易于理解且易用 Docker的英文原意是集装箱码头工人，标志是鲸鱼运送一大堆集装箱，集装箱就是容器，生动好记，易于理解。一个开发者可以在15分钟内入门Docker并进行安装和部署，这是容器史上的一次飞跃。因为它的易用性，有更多的人开始关注容器技术，加速了容器标准化的步伐。 应用镜像仓库 Docker官方构建了一个镜像仓库，组织和管理形式类似于GitHub,其上已累积了成千上万的镜像，因为Docker的跨平台适配性，相当于用户提供了一个非常有用的应用商店，所有人都可以自由地下载为服务组件，这为开发者提供了巨大便利。 ","date":"2020-10-10","objectID":"/k8s_series/:5:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"5. Kubernetes 真正的生产型应用会涉及多个容器。这些容器必须跨多个服务器主机进行部署。容器安全性需要多层部署，因此可能会比较复杂。因此出现了kubernetes、swarm、mesos等编排软件，最终kubernetes实现了大一统。 Kubernetes 可以提供所需的编排和管理功能，以便您针对这些工作负载大规模部署容器。借助 Kubernetes 编排功能，您可以构建跨多个容器的应用服务、跨集群调度、扩展这些容器，并长期持续管理这些容器的健康状况。有了 Kubernetes，您便可切实采取一些措施来提高 IT 安全性。 Kubernetes 还需要与联网、存储、安全性、遥测和其他服务整合，以提供全面的容器基础架构。 当然，这取决于您如何在您的环境中使用容器。Linux 容器中的基本应用将它们视作高效、快速的虚拟机。一旦把它部署到生产环境或扩展为多个应用，您显然需要许多托管在相同位置的容器来协同提供各种服务。随着这些容器的累积，您运行环境中容器的数量会急剧增加，复杂度也随之增长。 Kubernetes 通过将容器分类组成 “容器集” （pod），解决了容器增殖带来的许多常见问题容器集为分组容器增加了一个抽象层，可帮助您调用工作负载，并为这些容器提供所需的联网和存储等服务。Kubernetes 的其它部分可帮助您在这些容器集之间达成负载平衡，同时确保运行正确数量的容器，充分支持您的工作负载。 如果能正确实施 Kubernetes，再辅以其它开源项目（例如 Atomic 注册表、Open vSwitch、heapster、OAuth 以及 SELinux），您就能够轻松编排容器基础架构的各个部分。 ","date":"2020-10-10","objectID":"/k8s_series/:6:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"6. 结论 ","date":"2020-10-10","objectID":"/k8s_series/:7:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_arch/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 一个 Kubernetes 集群由一组被称作节点的机器组成。这些节点上运行 Kubernetes 所管理的容器化应用。集群具有至少一个工作节点。 工作节点托管作为应用负载的组件的 Pod 。控制平面管理集群中的工作节点和 Pod 。 为集群提供故障转移和高可用性，这些控制平面一般跨多主机运行，集群跨多个节点运行。 本文档概述了交付正常运行的 Kubernetes 集群所需的各种组件。 这张图表展示了包含所有相互关联组件的 Kubernetes 集群。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。 请参阅构建高可用性集群 中对于多主机 VM 的设置示例。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"kube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 Kubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:1","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"etcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。 要了解 etcd 更深层次的信息，请参考 etcd 文档。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:2","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"kube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:3","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"kube-controller-manager 在主节点上运行 控制器 的组件。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。 副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)。 服务帐户和令牌控制器（Service Account \u0026 Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌. ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:4","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"cloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器允许您链接聚合到云提供商的应用编程接口中， 并分离出相互作用的组件与您的集群交互的组件。 cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。 下面的控制器都包含对云平台驱动的依赖： 节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 ","date":"2020-10-10","objectID":"/k8s_series_arch/:2:5","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"Node 组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:3:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"kubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:3:1","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"kube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:3:2","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"容器运行时（Container Runtime） 容器运行环境是负责运行容器的软件。 Kubernetes 支持多个容器运行环境: Docker、 containerd、CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:3:3","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"插件（Addons） 插件使用 Kubernetes 资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 kube-system 命名空间。 下面描述众多插件中的几种。有关可用插件的完整列表，请参见 插件（Addons）。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:4:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"DNS 尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该 有集群 DNS， 因为很多示例都需要 DNS 服务。 集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。 Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:4:1","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"Web 界面（仪表盘） Dashboard 是Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:4:2","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"容器资源监控 容器资源监控 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:4:3","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"集群层面日志 集群层面日志 机制负责将容器的日志数据 保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。 ","date":"2020-10-10","objectID":"/k8s_series_arch/:4:4","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_arch/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_cni/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_cni/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_cni/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_cni/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_cri/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_cri/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_cri/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_cri/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_csi/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_csi/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_csi/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_csi/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_intro/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_intro/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"1. 介绍 Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。 名称 Kubernetes 源于希腊语，意为“舵手”或“飞行员”。Google 在 2014 年开源了 Kubernetes 项目。 Kubernetes 建立在 Google 在大规模运行生产工作负载方面拥有十几年的经验 的基础上，结合了社区中最好的想法和实践。 ","date":"2020-10-10","objectID":"/k8s_series_intro/:2:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"2. 部署模式的发展史 让我们回顾一下为什么 Kubernetes 如此有用。 传统部署时代： 早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况， 结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。 虚拟化部署时代： 作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。 虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。 每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。 容器部署时代： 容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。 容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处： 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。 可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 ","date":"2020-10-10","objectID":"/k8s_series_intro/:3:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"3. 好处 容器是打包和运行应用程序的好方式。在生产环境中，你需要管理运行应用程序的容器，并确保不会停机。 例如，如果一个容器发生故障，则需要启动另一个容器。如果系统处理此行为，会不会更容易？ 这就是 Kubernetes 来解决这些问题的方法！ Kubernetes 为你提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足你的扩展要求、故障转移、部署模式等。 例如，Kubernetes 可以轻松管理系统的 Canary 部署。 Kubernetes 为你提供： 服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。 存储编排 Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。 自动部署和回滚 你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。 自动完成装箱计算 Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。 当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。 自我修复 Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的 运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。 密钥与配置管理 Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。 ","date":"2020-10-10","objectID":"/k8s_series_intro/:4:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"4. k8s不是什么？ Kubernetes 不是传统的、包罗万象的 PaaS（平台即服务）系统。 由于 Kubernetes 在容器级别而不是在硬件级别运行，它提供了 PaaS 产品共有的一些普遍适用的功能， 例如部署、扩展、负载均衡、日志记录和监视。 但是，Kubernetes 不是单体系统，默认解决方案都是可选和可插拔的。 Kubernetes 提供了构建开发人员平台的基础，但是在重要的地方保留了用户的选择和灵活性。 Kubernetes： 不限制支持的应用程序类型。 Kubernetes 旨在支持极其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。 如果应用程序可以在容器中运行，那么它应该可以在 Kubernetes 上很好地运行。 不部署源代码，也不构建你的应用程序。 持续集成(CI)、交付和部署（CI/CD）工作流取决于组织的文化和偏好以及技术要求。 不提供应用程序级别的服务作为内置服务，例如中间件（例如，消息中间件）、 数据处理框架（例如，Spark）、数据库（例如，mysql）、缓存、集群存储系统 （例如，Ceph）。这样的组件可以在 Kubernetes 上运行，并且/或者可以由运行在 Kubernetes 上的应用程序通过可移植机制（例如， 开放服务代理）来访问。 不要求日志记录、监视或警报解决方案。 它提供了一些集成作为概念证明，并提供了收集和导出指标的机制。 不提供或不要求配置语言/系统（例如 jsonnet），它提供了声明性 API， 该声明性 API 可以由任意形式的声明性规范所构成。 不提供也不采用任何全面的机器配置、维护、管理或自我修复系统。 此外，Kubernetes 不仅仅是一个编排系统，实际上它消除了编排的需要。 编排的技术定义是执行已定义的工作流程：首先执行 A，然后执行 B，再执行 C。 相比之下，Kubernetes 包含一组独立的、可组合的控制过程， 这些过程连续地将当前状态驱动到所提供的所需状态。 如何从 A 到 C 的方式无关紧要，也不需要集中控制，这使得系统更易于使用 且功能更强大、系统更健壮、更为弹性和可扩展。 ","date":"2020-10-10","objectID":"/k8s_series_intro/:5:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"5. 结论 ","date":"2020-10-10","objectID":"/k8s_series_intro/:6:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_intro/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_oam/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_oam/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_oam/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_oam/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_scheduler/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_scheduler/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_scheduler/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_scheduler/"},{"categories":["Cloud Native"],"content":"开篇","date":"2020-10-10","objectID":"/k8s_series_service/","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_service/"},{"categories":["Cloud Native"],"content":"系列目录 《Kubernetes系列：开篇》 《Kubernetes系列：概述》 《Kubernetes系列：架构》 《Kubernetes系列：CRI》 《Kubernetes系列：CNI》 《Kubernetes系列：CSI》 《Kubernetes系列：Service》 《Kubernetes系列：Ingress》 《Kubernetes系列：OAM》 《Kubernetes系列：调度》 ","date":"2020-10-10","objectID":"/k8s_series_service/:1:0","tags":["kubernetes"],"title":"Kubernetes系列：开篇","uri":"/k8s_series_service/"},{"categories":["DevOps"],"content":"SRE介绍","date":"2020-07-29","objectID":"/devops_series_sre/","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-29","objectID":"/devops_series_sre/:1:0","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"困局 计算机软件系统离开人通常是无法自主运行的，那要如何去运维一个日趋复杂的大型分布式计算机系统呢？ ","date":"2020-07-29","objectID":"/devops_series_sre/:2:0","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"Dev/Ops分离团队模型 雇佣系统管理员(sysadmin)运维复杂的计算机系统是行业内一直以来的普遍做法，系统管理员的工作主要在于应对系统中产生的各种需要人工干预的事件，以及来自业务部门的变更需求。但随着系统变得复杂，组件越来越多，流量不断上升，相关的事件和变更需求也会越来越多，就需要招聘更多的系统管理员。系统管理员的日常工作和研发工程师的相差甚远，通常归属于两个不同的部门，开发部(Dev)和运维部(Ops)。也就是Dev/Ops分离团队模型。 但是这个模型存在两个无法避免的问题。 直接成本。随着系统复杂度的增加，部署规模的扩大，团队的大小基本与系统负载成线性相关，共同成长。 间接成本。即研发团队和运维团队之间的沟通成本。研发团队想要\"随时随地发布新功能，没有任何阻拦”，运维团队想要”一旦一个东西在生产环境中正常工作了，就不要再进行任何改动“。本质来说，两个团队的目标是互相矛盾的。 ","date":"2020-07-29","objectID":"/devops_series_sre/:2:1","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"解决之道 ","date":"2020-07-29","objectID":"/devops_series_sre/:3:0","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"DevOps DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。 ","date":"2020-07-29","objectID":"/devops_series_sre/:3:1","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"SRE SRE可以理解为DevOps的一种实践，SRE基本是在进行由运维团队完成的工作，但是雇佣具有软件专业知识的工程师，通过创造软件系统的方式来维护系统运行并替代传统模型中的人工操作。本质上，SRE是在用软件工程的思维和方法论，通过设计、构建自动化工具来完成以前由系统管理员人工操作完成的任务。 SRE方法论 1. 确保长期关注研发工作 SRE团队应将运维工作限制在50%以内，并将剩余时间投入到研发项目上 2. 在保障SLO的前提下最大化迭代速度 错误预算，任何产品都不是，也不应该做到100%可靠，部门建立起一个合理的可靠性目标，错误预算等于”1-可靠性目标“，通过错误预算来最大化新功能上线的速度，同时保障服务质量。 3. 监控系统 监控系统是SRE团队监控服务质量和可用性的一个主要手段。一个监控系统应该只有三类输出： 紧急警报(alert)，意味着收到警报的用户需要立即执行某种操作 工单(ticket)，意味着接受工单的用户应该执行某种操作，但是并发立即执行。 日志(logging)，平时没有人需要关注日志信息，但是日志信息依然被收集起来以备调试和事后分析时使用 4. 应急事件处理 可靠性是MTTF(平均失败时间)和MTTR(平均恢复时间)的函数。评价一个团队将系统恢复到正常情况的最有效的指标，就是MTTR。 任何需要人工操作的事情都只会延长恢复时间。但有时候人工介入不可避免时，可以通过事先预案并且将最佳方法记录到”运维手册“上来降低MTTR。 5. 变更管理 变更管理的最佳实践是使用自动化来完成以下几个项目： 采用渐进式发布机制 迅速而准确地检测到问题的发生 当问题发生时，安全迅速的回滚 6. 需要预测和容量规划 需要预测和容量规划是保障一个业务有足够的容量和冗余度去服务预测中的未来需要。 容量规划有几个必需步骤： 必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间 规划中必须有准确的非自然增长的需求来源的统计 必须有周期性压力测试，以便准确地将系统原始资源信息与业务容量对应起来。 7. 效率与性能 高效地利用各种资源是任何赢利性服务都要关心的，一个服务的利用率指标通常依赖于这个服务的工作方式以及对容量的配置与部署上。如果能通过密切关注一个服务的容量配置策略，进而改进其资源利用率，可以有效地降低系统的总成本。 ","date":"2020-07-29","objectID":"/devops_series_sre/:3:2","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"成为SRE ","date":"2020-07-29","objectID":"/devops_series_sre/:4:0","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"技能要求 – TCP/IP网络模型 (OSI模型) – Unix/Linux 系统 – Unix/Linux 系统管理 – 数据结构与算法 – 编程语言 – SQL和数据库管理 – 人员管理 – 项目管理 ","date":"2020-07-29","objectID":"/devops_series_sre/:4:1","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"能力等级 0 – 对于相关的技术领域还不熟悉。 1 – 可以读懂这个领域的基础知识。 2 – 可以实现一些小的改动，清楚基本的原理，并能够在简单的指导下自己找到更多的细节。 3 – 基本精通这个技术领域，完全不需要别人的帮助。 4 – 对这个技术领域非常的熟悉和舒适，可以应对和完成所有的日常工作。 ​ 4 – 1 对于软件领域 – 有能力开发中等规模的程序，能够熟练和掌握并使用所有的语言特性，而不是需要翻书，并且能够找到所有的冷知识。 ​ 4 – 2 对于系统领域 – 掌握网络和系统管理的很多基础知识，并能够掌握一些内核知识以运维一个小型的网络系统，包括恢复、调试和能解决一些不常见的故障。 5 – 对于该技术领域有非常底层的了解和深入的技能。 6 – 能够从零开发大规模的程序和系统，掌握底层和内在原理，能够设计和部署大规模的分布式系统架构。 7 – 理解并能利用高级技术，以及相关的内在原理，并可以从根本上自动化大量的系统管理和运维工作。 8 – 对于一些边角和晦涩的技术、协议和系统工作原理有很深入的理解和经验。能够设计，部署并负责非常关键以及规模很大的基础设施，并能够构建相应的自动化设施。 9 – 能够在该技术领域出一本经典的书。并和标准委员会的人一起工作制定相关的技术标准和方法。 10 – 在该领域写过一本书，被业内尊为专家，并是该技术的发明人。 ","date":"2020-07-29","objectID":"/devops_series_sre/:4:2","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"Roadmap 参考 Google SRE 运维解密 Google SRE Workbook Roadmap ","date":"2020-07-29","objectID":"/devops_series_sre/:4:3","tags":["devops"],"title":"DevOps系列：SRE","uri":"/devops_series_sre/"},{"categories":["DevOps"],"content":"监控系统","date":"2020-07-20","objectID":"/devops_series_mon/","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-20","objectID":"/devops_series_mon/:1:0","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"为什么需要监控系统？ ","date":"2020-07-20","objectID":"/devops_series_mon/:2:0","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"两个场景 场景一 技术部门上线了一个新项目，系统宕机了，客户在访问时发现无法访问，客户 A 不知道如何处理，放弃了访问，客户 B 知道客服系统，告知了运营人员，运营人员自己访问后也发现无法访问，于是通知了测试人员，再由测试人员通知线上项目的负责人，由负责人来进行故障恢复。 整个流程中，能处理故障的人成了最后知道故障的人。 场景二 用户反馈访问某个系统很慢，通知技术人员排查问题，由于系统涉及的组件很多，技术人员没办法立即知道问题出在哪里，于是技术人员只能通过自己把整个数据流走完的方式来排查问题： 1、由入口开始排查问题，先确认网络是否丢包，延时是否过高，发现无异常。 2、于是排查服务所在机器的负载情况，以及服务相关日志 (未必有记录)，也无异常。 3、排查代码发现有做 sql 查询，于是根据 sql 手动到数据库执行，发现 sql 执行很慢。 4、于是排查数据库所在机器的负载情况，发现 cpu 一直处在 100% 状态，是数据库进程造成的。 5、通过查询相关执行 sql 发现有某个 sql 在执行复杂查询导致了 cpu 使用率一直很高，从而影响了其他 sql 查询。 极端情况下，技术人员可能需要把所有相关组件都排查一遍，才能发现问题出在哪里。 ","date":"2020-07-20","objectID":"/devops_series_mon/:2:1","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"场景解决方案 开头提到的两个场景应该是大部分技术人员都会碰到的问题，场景一是故障出现到故障处理的耗时问题，场景二是故障处理到故障恢复的耗时问题。 场景一的解决方式，可以由一个脚本或者一个系统，定时收集客户访问的 url 的返回状态码，如果出现错误的状态码达到一定次数，就发送邮件或者短信给到对应的负载人。 场景二的解决方式，可以由一个系统，定时收集所有组件的相关信息，然后通过聚合和数据展示，来提供一个全局的问题查看功能。 解决上面两种场景的系统就是监控系统。 ","date":"2020-07-20","objectID":"/devops_series_mon/:2:2","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"为什么要监控 监控一个系统有多个原因，一般包含如下几项 分析趋势 数据库多大，增长速度如何？日活用户的增长速度？ 数据对比 增加了 redis 缓存后，访问速度较没增加前如何？这周和上周的访问速度有什么差异？ 告警 有东西故障了，或者即将故障，需要有人处理它。 构建仪表盘 仪表盘应该可以回答有关服务的一些基本问题，通常会包含常见的指标 临时性回溯分析 请求延迟刚刚大幅增加，有没有其他的现象同时发生？ ","date":"2020-07-20","objectID":"/devops_series_mon/:2:3","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"建立监控系统 ","date":"2020-07-20","objectID":"/devops_series_mon/:3:0","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"监控系统基本组件 一个监控系统一般包含下面几个组件： Agent/collector Agent/collector用于定时收集各种需要的指标信息，可以是脚本、程序、埋点。 Server Server用于接收采集回来的指标信息，进行聚合、存储，供后续查询使用。 Dashboard Dashboard用于展示历史指标信息 Alert Alert用于计算告警规则，发送告警的操作 ","date":"2020-07-20","objectID":"/devops_series_mon/:3:1","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"监控系统的工作流程 一个监控系统的工作流程一般如下： 数据采集 安装客户端，可以是脚本、程序、埋点, 定时采集各种需要的数据。 数据接收、存储 Push方式 监控系统提供接口供客户端定时上报数据 Pull方式 客户端提供接口供监控系统定时拉取数据 数据处理 告警 根据一定规则计算采集回来的指标数据，设置阈值，当达到阈值后发送告警。 展示 提供一个仪表板，用来展示采集回来的数据 分析 针对采集回来的数据进行定制化的数据分析 ","date":"2020-07-20","objectID":"/devops_series_mon/:3:2","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"Metric 配置监控时，我们首要面对的是监控数据如何采集的问题。一般我们可以把监控指标分为两类：业务指标和资源指标。 业务指标 业务指标通过衡量有用的输出来指示系统的运行状况。一般包括以下几个 吞吐量 成功率 错误 性能(延迟) 一个Web server的业务指标例子 Subtype Description Value throughput requests per second 312 success 上个周期响应状态码为2xx的百分比 99.1 error 上个周期响应状态码为5xx的百分比 0.1 performance 采集周期内的平均响应时间 0.4 资源指标 资源指标一般包括以下几个： 利用率 饱和度 错误 可用性 一些通用资源的指标例子 Resource Utilization Saturation Errors Availability Disk IO % time that device was busy wait queue length # device errors % time writable Memory % of total memory capacity in use swap usage N/A (not usually observable) N/A Microservice average % time each request-servicing thread was busy # enqueued requests # internal errors such as caught exceptions % time service is reachable Database average % time each connection was busy # enqueued queries # internal errors, e.g. replication errors % time database is reachable Four Golden Signals Four Golden Signals 是 Google 针对大量分布式监控的经验总结，4 个黄金指标可以在服务级别帮助衡量终端用户体验、服务中断、业务影响等层面的问题。主要关注与以下四种类型的指标： 延迟：服务请求所需时间。 记录用户所有请求所需的时间，重点是要区分成功请求的延迟时间和失败请求的延迟时间 流量：监控当前系统的流量，用于衡量服务的容量需求。 流量对于不同类型的系统而言可能代表不同的含义。例如，在 HTTP REST API 中, 流量通常是每秒 HTTP 请求数； 错误：监控当前系统所有发生的错误请求，衡量当前系统错误发生的速率。 对于失败而言有些是显式的 (比如, HTTP 500 错误)，而有些是隐式 (比如，HTTP 响应 200，但实际业务流程依然是失败的)。 对于一些显式的错误如 HTTP 500 可以通过在负载均衡器 (如 Nginx) 上进行捕获，而对于一些系统内部的异常，则可能需要直接从服务中添加钩子统计并进行获取。 饱和度：衡量当前服务的饱和度。 主要强调最能影响服务状态的受限制的资源。 例如，如果系统主要受内存影响，那就主要关注系统的内存状态，如果系统主要受限与磁盘 I/O，那就主要观测磁盘 I/O 的状态。因为通常情况下，当这些资源达到饱和后，服务的性能会明显下降。同时还可以利用饱和度对系统做出预测，比如，“磁盘是否可能在 4 个小时候就满了”。 ","date":"2020-07-20","objectID":"/devops_series_mon/:3:3","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"Alert 报警可以让一个系统发生故障或即将发生故障时主动通知相应的人员，一个紧急报警的处理会占用对应人员的宝贵时间，如果无效信息过多，分析和修复问题课鞥呢会变慢，故障时间也会相应的延长，因此一个高效的报警系统应该能提供足够的信息，并且误报率非常低。 在管理大规模集群的情况下，究竟有多少报警量才是合理的呢？ Google SRE每周只有十条报警，如果超过十条，说明没有把无效报警过滤掉（Google SRE仅负责SLA要求为99.99%的服务）。 那么怎么减少报警量呢？ 这就需要对报警进行优化了。 报警优化 1. 报警值班和报警升级 基于值班表，每天安排两人进行值班处理报警，将值班压力从全团队压缩在两人范围内，从而让团队能够有足够的时间和人力进行优化工作。 同时，为了避免两个值班人员都没有响应报警，可以使用报警升级功能，如果一个报警在5min内值班人员均未响应，或者15min内未处理完毕，或者有严重故障发生，都可以将报警进行升级，通告团队其他成员协助处理。 2. 建立报警等级 Google SRE的实践则是将监控系统的输出分为三类，报警、工单和记录。 SRE的要求是所有的故障级别的报警，都必须是接到报警，有明确的非机械重复的事情要做，且必须马上就得做，才能叫做故障级别的报警。其他要么是工单，要么是记录。 3. 故障自愈 重启作为单机预案，在很多业务线，可以解决至少50%的报警。没有响应，重启试试，请求异常，重启试试，资源占用异常，重启试试，各种问题，重启都屡试不爽。 换言之，针对简单场景具有明确处置方案的报警，自动化是一个比较好的解决方案，能够将人力从大量重复的工作中解放出来。 自动化处理报警的过程中，需要注意以下问题： 自动化处理比例不能超过服务的冗余度（默认串行处理最为稳妥）； 不能对同一个问题在短时间内重复多次地自动化处理（不断重启某个机器上的特定进程）； 在特定情况下可以在全局范围内快速终止自动化处理机制； 尽量避免高危操作（如删除操作、重启服务器等操作）； 每次执行操作都需要确保上一个操作的结果和效果收集分析完毕（如果一个服务重启需要10min）。 4. 持续优化TOP3的报警 2/8定律，80%的报警可能来自20%的指标，对报警数过多的报警进行持续优化，可以减少大量的报警。 5. 基于时间段分而治之 从冗余度角度来分析，如果在流量峰值有20%的冗余度，那么在流量低谷，冗余度至少为50%。 基于冗余度的变换，相应的监控策略的阈值，随机也应该发生一系列的变化。 举例来说，在高峰期，可能一个服务故障20%的实例，就必须介入处理的话，那么在低谷期，可能故障50%的实例，也不需要立即处理，依赖于报警自动化处理功能，逐步修复即可。 6. 报警周期优化，避免瞬报 在监控趋势图中，会看到偶发的一些毛刺或者抖动，这些毛刺和抖动，就是造成瞬报的主要原因。 这些毛刺和抖动，至多定义为异常，而非服务故障，因此应该以非紧急的通知方式进行。 7. 提前预警，防患于未然 对于很多有趋势规律的场景，可以通过提前预警的方式，降低问题的紧迫程度和严重性。 8. 日常巡检 提前预警面向的是有规律的场景，而日常巡检，还可以发现那些没有规律的隐患。 9. 比例为主，绝对值为辅 线上机器的规格不同，如果从绝对值角度进行监控，则无法适配所有的机器规格，势必会产生大量无意义的报警。 10. Code Review 前人埋坑，后人挖坑。在解决存量问题的情况下，不对增量问题进行控制，那报警优化，势必会进入螺旋式缓慢上升的过程，这对于报警优化这类项目来说，无疑是致命的。 通过对新增监控的Code Review，可以让团队成员快速达成一致认知，从而避免监控配置出现千人千面的情况出现。 11. 沉淀标准和最佳实践 仅仅做Code Review还远远不够，一堆人开会，面对一行监控配置，大眼瞪小眼，对不对，为什么不对，怎么做更好？大家没有一个标准，进而会浪费很多时间来进行不断的讨论。 这时候，如果有一个标准，告诉大家什么是好，那么就有了评价标准，很多事情就比较容易做了。 标准本身也是需要迭代和进步的，因此大家并不需要担心说我的标准不够完美。 基于标准，再给出一些最佳的监控时间，那执行起来，就更加容易了。 12. 彻底解决问题不等于自动处理问题 自动化处理问题不等于解决问题，掩耳盗铃也不等于解决问题，什么叫做解决问题，只有是找到问题的根本原因，并消灭之，才能确保彻底解决问题，轻易不会再次发生。 参考 Google SRE 运维解密 datadog monitoring 101 摆脱无效报警？十年运维监控报警优化经验总结 ","date":"2020-07-20","objectID":"/devops_series_mon/:3:4","tags":["devops"],"title":"DevOps系列：监控","uri":"/devops_series_mon/"},{"categories":["DevOps"],"content":"CI/CD","date":"2020-07-15","objectID":"/devops_series_cicd/","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-15","objectID":"/devops_series_cicd/:1:0","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"1. 介绍 CI/CD 是一种通过在应用开发阶段引入自动化来频繁向客户交付应用的方法。CI/CD 的核心概念是持续集成、持续交付和持续部署。作为一个面向开发和运营团队的解决方案，CI/CD 主要针对在集成新代码时所引发的问题（亦称：“集成地狱”）。 具体而言，CI/CD 可让持续自动化和持续监控贯穿于应用的整个生命周期（从集成和测试阶段，到交付和部署）。这些关联的事务通常被统称为“CI/CD 管道”，由开发和运维团队以敏捷方式协同支持。 ","date":"2020-07-15","objectID":"/devops_series_cicd/:2:0","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"1.1 CI 是什么？CI 和 CD 有什么区别？ 缩略词 CI / CD 具有几个不同的含义。CI/CD 中的“CI”始终指持续集成，它属于开发人员的自动化流程。成功的 CI 意味着应用代码的新更改会定期构建、测试并合并到共享存储库中。该解决方案可以解决在一次开发中有太多应用分支，从而导致相互冲突的问题。 CI/CD 中的“CD”指的是持续交付和/或持续部署，这些相关概念有时会交叉使用。两者都事关管道后续阶段的自动化，但它们有时也会单独使用，用于说明自动化程度。 持续交付通常是指开发人员对应用的更改会自动进行错误测试并上传到存储库（如 GitHub 或容器注册表），然后由运维团队将其部署到实时生产环境中。这旨在解决开发和运维团队之间可见性及沟通较差的问题。因此，持续交付的目的就是确保尽可能减少部署新代码时所需的工作量。 持续部署（另一种“CD”）指的是自动将开发人员的更改从存储库发布到生产环境，以供客户使用。它主要为了解决因手动流程降低应用交付速度，从而使运维团队超负荷的问题。持续部署以持续交付的优势为根基，实现了管道后续阶段的自动化。 CI/CD 既可能仅指持续集成和持续交付构成的关联环节，也可以指持续集成、持续交付和持续部署这三项构成的关联环节。更为复杂的是，有时“持续交付”也包含了持续部署流程。 归根结底，我们没必要纠结于这些语义，您只需记得 CI/CD 其实就是一个流程（通常形象地表述为管道），用于实现应用开发中的高度持续自动化和持续监控。因案例而异，该术语的具体含义取决于 CI/CD 管道的自动化程度。许多企业最开始先添加 CI，然后逐步实现交付和部署的自动化（例如作为云原生应用的一部分）。 ","date":"2020-07-15","objectID":"/devops_series_cicd/:2:1","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"1.2 CI 持续集成（Continuous Integration） 现代应用开发的目标是让多位开发人员同时处理同一应用的不同功能。但是，如果企业安排在一天内将所有分支源代码合并在一起（称为“合并日”），最终可能造成工作繁琐、耗时，而且需要手动完成。这是因为当一位独立工作的开发人员对应用进行更改时，有可能会与其他开发人员同时进行的更改发生冲突。如果每个开发人员都自定义自己的本地集成开发环境（IDE），而不是让团队就一个基于云的 IDE 达成一致，那么就会让问题更加雪上加霜。 持续集成（CI）可以帮助开发人员更加频繁地（有时甚至每天）将代码更改合并到共享分支或“主干”中。一旦开发人员对应用所做的更改被合并，系统就会通过自动构建应用并运行不同级别的自动化测试（通常是单元测试和集成测试）来验证这些更改，确保这些更改没有对应用造成破坏。这意味着测试内容涵盖了从类和函数到构成整个应用的不同模块。如果自动化测试发现新代码和现有代码之间存在冲突，CI 可以更加轻松地快速修复这些错误。 进一步了解技术细节 ","date":"2020-07-15","objectID":"/devops_series_cicd/:2:2","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"1.3 CD 持续交付（Continuous Delivery） 完成 CI 中构建及单元测试和集成测试的自动化流程后，持续交付可自动将已验证的代码发布到存储库。为了实现高效的持续交付流程，务必要确保 CI 已内置于开发管道。持续交付的目标是拥有一个可随时部署到生产环境的代码库。 在持续交付中，每个阶段（从代码更改的合并，到生产就绪型构建版本的交付）都涉及测试自动化和代码发布自动化。在流程结束时，运维团队可以快速、轻松地将应用部署到生产环境中。 ","date":"2020-07-15","objectID":"/devops_series_cicd/:2:3","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"1.4 CD 持续部署（Continuous Deployment） 对于一个成熟的 CI/CD 管道来说，最后的阶段是持续部署。作为持续交付——自动将生产就绪型构建版本发布到代码存储库——的延伸，持续部署可以自动将应用发布到生产环境。由于在生产之前的管道阶段没有手动门控，因此持续部署在很大程度上都得依赖精心设计的测试自动化。 实际上，持续部署意味着开发人员对应用的更改在编写后的几分钟内就能生效（假设它通过了自动化测试）。这更加便于持续接收和整合用户反馈。总而言之，所有这些 CI/CD 的关联步骤都有助于降低应用的部署风险，因此更便于以小件的方式（而非一次性）发布对应用的更改。不过，由于还需要编写自动化测试以适应 CI/CD 管道中的各种测试和发布阶段，因此前期投资还是会很大。 ","date":"2020-07-15","objectID":"/devops_series_cicd/:2:4","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"2. 构建CI/CD https://www.infoq.cn/article/wht0wfmdrrbu-dtkh1xp https://gitbook.cn/gitchat/column/5aa795539c3cf94d49162f03/topic/5aaa1abe0bb9e857450e7a9e ","date":"2020-07-15","objectID":"/devops_series_cicd/:3:0","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"CI/CD 与 DevOps 学习笔记 DevOps 是为了应对软件发布频率越来越高与传统的“瀑布型”开发模式之间的矛盾提出的，CI/CD 是 Devops 的基础。CI/CD 将 Dev、QA、Ops 连接在一起，就是所谓的“开发运维一体化”，通过高度自动化的流程保证频繁且可靠的发布。 CI/CD 基本流程 从开发提交代码，到上线，整个过程都是属于 CI/CD 的范畴。 CI 意思是 持续构建，指的是从提交代码到最终生成的可以发布的应用，应用可以是 jar 包，也可以指 tar 包，甚至是 docker 镜像。 CI 的基本流程包括，提交代码、对代码的监控、编译打包、基本测试，发布包。 CD 意思是 持续交付/持续部署，持续部署比持续交付多强调了一点，即deploy的自动化。两者的区别实践起来并不重要，主要流程指将持续构建的产物，快速部署到测试环境进行测试，测试完毕后进行评审后即可自动化发布、部署到现网。 CI 具体分析 CI——Confinuous Integration，持续集成。 集成的意思是，将开发者的代码迅速集成到整个代码项目中，与历史的代码、他人的代码集成。传统的开发模式中，一个项目，分成几部分，大家分别开发，最后发布前，将所有的代码合到一起然后进行迭代测试直到发布。在 CI 流程中，每个人随时将自己的代码合入到主干，并且合入能够很快得到反馈，这种反馈不止是基于修改部分的代码，而是基于整个代码仓库的测试。这种模式下，问题可以被更早的发现，尤其是那些在集成测试中容易出现的问题。 持续的意思，可以理解为，强调的是整个过程是持续不断的。提交代码 -\u003e 监控到代码提交并触发测试（也可能是定时的，比如每天一次）-\u003e反馈结果到开发，整个过程持续贯穿在代码开发的整个流程中。 CI 流程中的测试，一般不同于 CD 流程中的测试。在 CI 流程中，比如在提交代码阶段，一般会有 commit hook，对提交的代码进行基本的静态检查，代码提交之后，一般会有产物的构建流程。在测试中，常常包含的是基本的自动化测试、单元测试以及基本的集成测试。 但是这些也取决于具体的场景的决策，这种决策需要兼顾的是两个方面： 时效性，在 CI 阶段的测试一般来讲应该是可以比较快的反馈到开发者的，否则就会降低开发的效率 问题出现的可能性，应该思考在 CI 阶段比较容易出现、常出现的问题是哪些，这些问题可以尽量放到该阶段，但是一般是一些基础的测试，复杂的测试可以放到 CD 中去做。 CD 具体分析 CD 的输入是 CI 的输出，也叫 CI 的产物（Artifact），它可能是 jar 包、war包、tar包、image 等等，CD 流程从归档地址（Artifact Repository） 获取产物。 CD 的主要过程是部署产出物到测试环境，进行集成的全面的测试，并且最终得到一个通过了所有测试的、可以被评审发布的产物。 在 CD 的测试中，尽管各个厂商叫法不同，但是可以将其基本分为三种环境，分别是测试环境、预发环境、生产环境。团队可以根据自身实际情况，定义三个环境的部署基准。 在 CD 流程中的测试应该是全面覆盖的，包括但不限于单元测试、接口自动化测试、集成自动化测试、UI测试、性能压测以及整个的端到端的测试。 经过了所有的测试的发布包，经过评审发布，就可以部署到现网，如果部署到现网也做到自动化，这个就叫 Continuous Deployment，也就是 持续部署。 持续部署必须拥有回滚的能力。 CI/CD 工具 CI/CD 整体是自动化的，同时由于多个任务并行/串行构成了流水线，Jenkins 提供的就是自动化流水线的能力以及丰富的插件的能力。 Jenkins 基本是事实上的标准，容器化目前可以作为补充来完善或者加速整个流程。但是同时也有一些容器化的工具开始挑战 Jenkins，比如 Drone。 Jenkins 主要在于它强大的生态，几乎可以搞定整个 CI/CD 流程的各个方面。Jenkins 可以安装很多插件，必要时写一个插件也不算太难——比如通过插件可以监控代码仓库的提交。 Jenkins 1.0 中开发者基本就是依靠 shell 脚本来构建一条流水线，在 Jenkins 2.0 中有了 pipeline as code，从而可以将发布的流程也纳入到版本管理中，可以很方便的复制迁移工程。 除了 Jenkins 之外，也可以使用 gitlab 的 CI/CD 流程工具，学会了使用其中一个，另一个也就比较容易上手了，比如知道了如何在 Jenkins 中添加 slave，那么自然就知道 gitlab 中添加 Runner 是干啥的了。gitlab 对代码的托管的集成肯定是更好的，但是 Jenkins 的源码管理插件也已经足够好用了。 Docker 提供了另外一种产物的可能，比如之前发布的包是 jar 包，使用了 docker 之后，可以发布一个 docker 镜像。将产物从打包好了的代码变成处理好了的镜像，就可以解决“测试环境明明运行的好好的，现网却挂了”这种环境导致的问题。 当然，也可以在其它具体的任务场景下使用 docker，比如使用 docker 作为构建机器，好处依旧是配置更加简单，启动停止销毁也变得容易。 另外，kubernates 也可以在 CI/CD 中发挥巨大的作用，比如使用 Jenkins 对接 Kubernates 集群，可以完成 master 挂掉立即重启一个 master的操作，也可以 解决slave 需求峰值低谷差异大造成资源浪费的问题。 但是比较明显的是，容器化能做的远远不止这些，未来的 CI/CD 会跟容器化会联系地更加紧密，几乎是毫无疑问的事情。 总结 CI/CD 可以认为是 DevOps 工作流的基础，它完成了应用的快速且高质量的发布。 持续集成 完成了提交代码到产出物的快速迭代。 持续交付 完成了整个测试流程的快速迭代。 持续部署 自动化了生产环境的部署，并且定义了灰度发布、回滚等能力及策略。 持续集成和持续交付的分界点是 Artiface Repository 中的产出物。 持续交付和持续部署的分界点是评审后的 Release 的产出物。 整个流程是一直在不断 running 的，因此叫做“持续”。 构建CICD工具链 源码管理： git、svn CI 平台：Jenkins、gitlab ci 代码静态分析工具：比如 pylint 单元测试：开发者应该写单元测试 集成测试：集成自动化用例 测试环境：最好可以自动化，支持多版本部署验证 软件发布平台 全覆盖测试工具，UI测试工具、压测工具等 预发环境 自动化部署工具 资料及扩展 阿里巴巴如何基于 Kubernetes 实践 CI/CD Jenkins 用户手册 Getting started with Gitlab CI/CD CICD 方案分析 基于 Jenkins 和 Docker 搭建持续交付流水线 持续集成与交付解决方案 基于 Docker 的 CI/CD 流水线实践 解读阿里 CI/CD、DevOps、分层自动化技术 ","date":"2020-07-15","objectID":"/devops_series_cicd/:4:0","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"2.2 工具 https://jenkins-zh.cn/wechat/articles/2020/01/2020-01-10-the-complete-ci-cd-collection-tutorials/ ","date":"2020-07-15","objectID":"/devops_series_cicd/:4:1","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"3. 结论 ","date":"2020-07-15","objectID":"/devops_series_cicd/:5:0","tags":["devops"],"title":"DevOps系列：CI/CD","uri":"/devops_series_cicd/"},{"categories":["DevOps"],"content":"CMDB","date":"2020-07-10","objectID":"/devops_series_cmdb/","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-10","objectID":"/devops_series_cmdb/:1:0","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"1. 介绍 CMDB是组织使用的ITIL术语，用于组织存储有关硬件和软件资产的信息（通常称为配置项[CI]）。CMDB提供了一种了解组织的关键资产及其关系的方法，例如信息系统，资产的上游来源或依存关系以及资产的下游目标。 用比较通俗的语言解释，CMDB可以存储并自动发现整个IT网络上的各种信息，比如一个IT网络上有多少台服务器、多少存储、设备的品牌、资产编号、维护人员、所属部门、服务器上运营什么操作系统、操作系统的版本、操作系统上有哪些应用、每个应用的版本等等，此外，CMDB还有一个非常重要的功能，即存储不同资源之间的依赖关系，如果网络上某个节点出现问题，通过CMDB，可以判断因此受到影响的业务。 ","date":"2020-07-10","objectID":"/devops_series_cmdb/:2:0","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"2. 云原生时代的CMDB设计 ","date":"2020-07-10","objectID":"/devops_series_cmdb/:3:0","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"2.1 传统时代的CMDB 通常，我们在建设运维的基础管理平台时，通常要做的事情： 1、把服务器、网络、IDC、机柜、存储、配件等这几大维度先定下来； 2、这些硬件的属性确定下来，比如服务器就会有 SN 序列号、IP 地址、厂商、硬件配置（如 CPU、内存、硬盘、网卡、PCIE、BIOS）、维保信息等等；网络设备如交换机也会有厂商、型号、带宽等等； 3、以上信息之间的关联关系，或者叫拓扑关系。比如服务器所在机柜，虚拟机所在的宿主机、机柜所在 IDC 等简单关系，复杂一点就会有核心交换机、汇聚交换机、接入交换机以及机柜和服务器之间的级联关系，这个就相对复杂一些 4、其实应该是 3.5 步，在上面信息的梳理过程中肯定就会遇到一些规划问题，比如，IP 地址段的规划，xx 网段用于 DB，xx 网段用于大数据、xx 网段用于业务应用等等，再比如同步要做的还有 xx 机柜用于做虚拟化宿主机、xx 机柜只放 DB 机器等等。 以上信息梳理清楚，通过 ER 建模工具进行数据建模，再将以上的信息固化到 DB 中，一个资源层面的信息管理平台就基本成型了。但是，信息固化不是目的，也没有价值，只有信息动态流转起来才有价值（跟货币一样）。接下来我们可以做的事情： 1、基于这些信息进行流程规范的建设，比如服务器的上线、下线、维修、装机等流程。同时，流程过程中状态的变更要同步管理起来。 2、拓扑关系的可视化和动态展示，比如交换机与服务器之间的级联关系、状态（正常 or 故障）的展示等，这样可以很直观的关注到资源节点的状态。 至此，从资源维度的信息梳理，以及基于这些信息的平台和流程规范建设也算是基本成型了。这个时候，以服务器简单示例，我们的视角是下面这样的： ","date":"2020-07-10","objectID":"/devops_series_cmdb/:3:1","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"2.2 云时代的CMDB 云和k8s的出现以及DevOps的普及，开始了以应用为中心的CMDB构建 上面说明了 CMDB 的基础信息部分，如果从传统的 SA 运维模式，这些信息已经足够，但是从应用运维的角度，这些就远远不够了。这时我们就需要一个非常非常重要的句柄——应用名，*或者叫应用标示。这时，应用运维里面最最重要的一条联系也就产生了——*“应用名—IP“的关联关系。（注：这里也可以是定义的其它的唯一主机标示，如主机名、容器 ID 等等，因为我们使用的方式是 IP，所以这里就以 IP 示例） 之所以说应用名和应用名-IP 关联关系非常重要，是因为它的影响力不仅仅在运维内部，而是会一直延伸整个技术架构上，后面的文章，我们介绍到的所有的平台和系统建设，都会跟这两个概念有关。 CMDB 是 IP 为标示的资源管理维度，有了应用名之后，我们后面就是以应用为视角的管理维度了。首先看一下应用会涉及到的信息： 1、应用基础信息，如应用责任人、应用的 Git 地址等 2、应用部署涉及的基础软件包，如语言包（Java、C++、GO 等）、Web 容器（Tomcat、JBoss 等）、Web 服务器（Apache、Nginx 等）、基础组件（各种 agent，如日志、监控、系统维护类的 tsar 等） 3、应用部署涉及的目录，如运维脚本目录、日志目录、应用包目录、临时目录等 4、应用运行涉及的各项脚本和命令，如启停脚本、健康监测脚本 5、应用运行时的参数配置，如 Java 的 jvm 参数，特别重要的是 GC 方式、新生代、老生代、永生代的堆内存大小配置等 6、应用运行的端口号 7、应用日志的输出规范 我们梳理完上述信息后就会发现，这些信息跟 CMDB 里面的资源信息是完全两个维度的东西，所以从信息管理维度上讲，资源配置和应用配置分开会更清晰，解耦之后也更容易管理。 **好了，按照上面 CMDB 说的套路，梳理完成后，就是要进行信息的建模和数据的固化，这时就有了我们的——应用配置管理。**再往后，就是基于应用配置管理的流程规范和工具平台的建设，这就涉及到我们经常说的持续集成 \u0026发布 \u0026交付，监控、稳定性平台、成本管理等等。 从应用的视角，我们配置管理，应该是下面这样一个视图（简单示例，不是完整的）： ","date":"2020-07-10","objectID":"/devops_series_cmdb/:3:2","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"3. 构建以应用为中心的CMDB https://cloud.tencent.com/developer/news/675404 ","date":"2020-07-10","objectID":"/devops_series_cmdb/:4:0","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"3. 结论 CMDB 是运维的基石，但是要发挥更大的价值，光有基础是不够的，我们要把更多的精力放到上层的应用和价值服务上，所以我才会讲应用才是运维的核心。我们可以看到，如果仅仅基于 CMDB 的资源信息作自动化，最多只能做出自动化的硬件资源采集、自动化装机、网络-硬件拓扑关系生成等资源层面的工具，这些工具只会在运维层面产生价值，离业务还很远，就更谈不上能给业务带来什么价值了。但是基于应用这一层去做，就可以做很多事情，比如持续集成和发布、持续交付、弹性扩缩容、稳定性平台、成本控制等等，这些事情，带来的价值就会大大不同，这些后续会一个个介绍出来。 ","date":"2020-07-10","objectID":"/devops_series_cmdb/:5:0","tags":["devops"],"title":"DevOps系列：CMDB","uri":"/devops_series_cmdb/"},{"categories":["DevOps"],"content":"概述","date":"2020-07-05","objectID":"/devops_series_intro/","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-05","objectID":"/devops_series_intro/:1:0","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"1. 介绍 DevOps大概起源于08到09年之间，最初的目的是要打破开发与运维之间的壁垒，2010年，The Agile Admin博客发布了《What is DevOps》给出了一个详细的DevOps定义，算是对DevOps有了一个初步的定义。不过，我这里还是引用一下wiki的定义： DevOps（开发 Development 与运维 Operations 的组合词）是一种文化、一场运动或实践，强调在自动化软件交付流程及基础设施变更过程中，软件开发人员与其他信息技术（IT）专业人员彼此之间的协作与沟通。它旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。 ","date":"2020-07-05","objectID":"/devops_series_intro/:2:0","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"2. 优势 传统的瀑布模型会带来很多沟通上的问题和成本，DevOps实际上是要来解决这些问题的。我们分别从工程上和角色上的优势来说一说 ","date":"2020-07-05","objectID":"/devops_series_intro/:3:0","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"2.1 基于DevOps的工程上的优势 DevOps的主要好处是可以更快地交付质量大大提高的软件。 根据行业的不同，可能还会有其他好处。大部分软件工程采用DevOps具有如下优势： 提升了可靠性 更快速的软件更新 减少故障恢复时间 更好的用户体验 更加高效 减少失败 降低风险 更好的质量 更短的开发周期 提升产品交付时间 提升稳定性 节省成本 ","date":"2020-07-05","objectID":"/devops_series_intro/:3:1","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"2.2 基于DevOps的角色上的优势 2.2.1 不同角色的痛苦 在IT角色中，大部分的痛苦都来自于缺乏沟通和无聊的重复工作。 DevOps旨在解决这些问题。 2.2.2 优势 如果采用DevOps后，不同的角色能获得不同的好处： 开发 在没有采用DevOps之前，开发人员可能需要一遍又一遍的完成类似构建和部署的相同的任务。非常消耗时间。 借助DevOps和自动化，可以消除繁琐的重复任务！将这些耗时的项目排除在外，这样就有更多的时间进行开发。 运维 软件开发完成后交由运维人员进行发布维护，但是因为缺少沟通，运维人员不清楚具体的功能和变更，当出现问题时，解决问题将花费更长的时间。也因为这个情况，为了保持环境的稳定性，变更变得小心翼翼。 使用DevOps后，自动化和持续集成允许在不威胁稳定性的情况下交付新功能。这样运维人员报告的计划外的工作和返工时间减少了22%。这主要是因为运维人员与开发人员的交流增加了。 更好的代码、共享的代码库和更稳定的线上环境使工作更加轻松。 产品 当产品和应用需要更长的时间才能投入生产环境时，对于产品经理来说令人难以接受。特别是在软件有错误的时候，时间会更加的长。 而DevOps鼓励协作环境，通过不断的沟通交流，以及小步快跑的方式，软件部署频率提高了46倍，变更准备的时间缩短了440倍！ 系统管理员 当软件有错误，但是反馈不及时以及可见性低时，系统管理员就很难进行工作。 而Devops鼓励沟通，沟通可以带来更好的产品和更好的系统，这样可以让管理更简单，并且自动化可以减少人为错误，从而将故障发生的概率降低3倍。 DevOps还可以提高整个软件开发过程的可见性。当能够检测到错误，找到错误的根源并找到原因时，解决问题就变得容易。 DevOps可使故障恢复速度提高96倍。 测试 当测试人员看不到问题的源头和愿意时，就很令人沮丧。 DevOps可以更快地解决问题。提高可见度和沟通对于解决问题至关重要。工程师可以使用实时数据来解决问题并了解应用程序更改的影响。当出现问题时，解决方案实施越早越好。如果错误太深，则将很难修复。 质量保障 确保产品和系统完好无损是质量保障的工作。但这并不意味着大家会喜欢充满错误的软件和流程。 借助DevOps，团队成员可以共同开发出更好的产品，并且自动化可以减少容易避免的人为错误。这样可以让错误更少。在存在错误的地方，由于持续集成和持续交付以及它们的频繁微小更改，它们更小而且更容易被修复。DevOps用户报告的修复安全问题的时间减少了50％，故障恢复速度提高了96倍。 客服 曾经在服务行业工作过的任何人，无论是在餐馆，零售店还是客户服务部门，都知道与心怀不满的客户打交道的痛苦。当您的系统出现故障和错误时，客户也会不满意。 DevOps减少了错误，这意味着更快乐的客户。客服仍然会收到有投诉的客户打来的电话，但是他们之间的联系可能会越来越少。另外，与他们反复遇到相同的问题相比，他们将更加了解。更具协作性的环境意味着您的工作更加轻松。 用户 产品变更的意义是什么？当然是为了改善用户体验。因为我们简化了流程，这就意味着我们将有更多时间为客户和客户进行更多改进。 DevOps通过改进流程和应用程序使最终用户的体验更加一致。总体而言，使交互更加有趣。 ","date":"2020-07-05","objectID":"/devops_series_intro/:3:2","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"3. 如何实施？ 要让 DevOps 切实有效，您必须首先建立一套开发人员与运营部门通力协作的文化和理念。这对于该策略能否取得成功至关重要。该策略使得两个团队之间能够进行更好的沟通，从而激发创新。在打破了局限性的组织中，您可以建立一个集成环境。在该环境中，您能够反复测试并改进软件代码，然后实施一套连续发布计划以部署经过增强的软件。 您可以快速交付高质量的新产品和服务，因此客户满意度和用户体验将得到提升。通过使用内置了机器学习和算法的工具来执行连续监控和响应，任务（工作流程）可以自动触发，无需人工干预。 通过收集客户反馈和分析，您可以快速将这些信息融入到您的业务规划和未来产品开发中。然后，您可以从头开始再次启动 DevOps 循环。但这一次，您可以借助从客户那里学习并验证的知识来改进协作开发过程，并开始优化。 通过继续遵循 DevOps 方法，公司可以逐步建立一套优化的生态系统，其中包含相互作用的组件、用于优化开发的优秀实践以及用于维持高质量的既定标准。 DevOps的关键在于持续改进并且循环： 持续计划 协作开发 持续测试 持续集成 持续交付 持续反馈 持续监控 持续响应 ","date":"2020-07-05","objectID":"/devops_series_intro/:4:0","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"4. 结论 该篇文章，我们介绍了DevOps的定义，说明了采用DevOps后的优势，以及在大方向上要如何进行DevOps的实施。接来下，我们将从技术层面来说明如何构建DevOps。 参考： https://devops.com/different-organizations-different-devops-outcomes/ https://dzone.com/articles/the-benefits-of-devops-by-role https://www.juniper.net/cn/zh/products-services/what-is/devops/ ","date":"2020-07-05","objectID":"/devops_series_intro/:5:0","tags":["devops"],"title":"DevOps系列：概述","uri":"/devops_series_intro/"},{"categories":["DevOps"],"content":"开篇","date":"2020-07-01","objectID":"/devops_series/","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"系列目录 《DevOps系列：开篇》 《DevOps系列：概述》 《DevOps系列：CMDB》 《DevOps系列：CI/CD》 《DevOps系列：监控》 《DevOps系列：SRE》 ","date":"2020-07-01","objectID":"/devops_series/:1:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"1. 介绍 在Ops领域工作也接近8年了，个人也经历了从人工Ops–\u003e工具Ops–\u003e平台Ops的转变，最近想把自己的一些DevOps相关的学习和经验记录下来，整理成一个系列，算是对自己这么多年的工作经验的一个总结，也想对之后的发展想法做下自己的规划和判断。 ","date":"2020-07-01","objectID":"/devops_series/:2:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"2. 当我们谈论Ops，我们在谈论什么 ","date":"2020-07-01","objectID":"/devops_series/:3:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"2.1 从开发模型说起 早期的软件开发模型一般采用瀑布式开发模型，该模型将软件过程划分成几个阶段，从需求到设计、开发、测试和运维，它的理念是软件开发的规模越来越大，必须以一种工程管理的方式来定义每个阶段，以及相应的交付产物和交付标准，以期通过一种重流程，重管控，按照计划一步步推进整个项目的交付过程。Ops处于软件交付的末端。那么，具体的Ops是什么呢？ ","date":"2020-07-01","objectID":"/devops_series/:3:1","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"2.2 什么是运维(Ops) 运维(Ops)， 通常指IT运维（IT Operations）， 是指通过一系列步骤和方法，管理与维护线上服务（Online Service）或者产品 （Product）的过程。 运维有着非常广泛的定义，在不同的公司不同的阶段代表不同的职责与定位，没有一个统一的标准。尤其是随着互联网的发展，运维的含义也在逐渐互联网化。互联网运维通常属于技术部门，与研发、测试、系统管理同为互联网产品的技术支撑，这种划分在国内和国外以及大小公司之间都会多少有一些不同。运维的重点在于系统运行的各种环境，从机房、网络、存储、物理机、虚拟机这些基础的架构，到数据库、中间件平台、云平台、大数据平台，偏重的也不是编程，而是对这类平台的使用和管理。运维的水平可以成为衡量一个公司（IT公司）技术实力的标准。随着软件行业和规模的不断发展，Ops也在不断的改进。 ","date":"2020-07-01","objectID":"/devops_series/:3:2","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"2.3 Ops的发展历程 2.3.1 人工阶段 在这个阶段，所有运维问题，基本靠人工操作完成。这种情况下，系统规模不大，遇到的问题相对简单，大多集中在硬件、网络和系统层面，所以有一定操作系统或网络维护经验的人就可以搞定。 2.3.2 脚本\u0026工具阶段 一般绝大多数企业都会很快从第一阶段过渡到第二阶段，因为上一阶段的大量重复繁琐的操作，完全可以转化为脚本来实现，而不是每次都去敲一堆类似的命令。 早期的运维主要以各种 shell 为主，所以很多运维如果会 shell 编写一些批处理脚本，就会很有竞争力了。再往后，我们大家所熟知的 Perl、Ruby、Python 等动态语言也被广泛应用于脚本工具的实现，特别是一些逻辑和场景相对复杂的自动化实现。不同的工具也被开发出现，例如ansible、chef、puppet等。 2.3.3 流程\u0026工具阶段 在该阶段，要面临更加复杂化的场景实现，比如做一次业务部署，运维同学可能要安装服务器，做系统配置变更，安装软件包、启停进程，然后再负载均衡上配置服务等等。这时，就需要有一个流程将一个个的脚本功能串联起来，同时还要有一些脚本执行结果校验及判断的过程。 所以，这就对流程和工具平台有了更大的诉求。同时，在一些 IT 化比较早的行业，如电信运营商和金融行业，由于对变更过程的严格控制，这就需要更加科学和规范的管理措施，所以会引入 ITIL 这样 IT 服务管理体系，对整个 IT 系统及其变更进行管控。 2.3.4 运维平台阶段(DevOps) 从该阶段开始，随着业务复杂度和体量的增加，为了完成企业对于效率、稳定和成本的要求，倒逼着整个业务和技术架构发生转变，例如服务化和分布式等技术，而在这样新的技术体系下，运维所面临的场景复杂度也急剧上升，原有的运维技能如操作系统维护、系统配置、脚本编写已经完全满足不了要求。同时，由于软件系统复杂度的提升，也需要运维投入更多的精力去关注业务软件架构和应用服务上。也正是在这种要求下，运维人员不再是运维工作唯一参与的角色，每个在软件交付过程中需要参与的角色都将参与到DevOps中来，用于提升效率。 2.3.5 智能运维阶段(AIOps) 个人理解这个是未来阶段，需要大厂来完成，因为从 AI 的角度，AIOps 有三个方面的充要条件：机器学习算法、计算能力如 GPU、海量数据。那么海量数据这个条件基本是只有大厂才能具备了。 ","date":"2020-07-01","objectID":"/devops_series/:3:3","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"3. DevOps ","date":"2020-07-01","objectID":"/devops_series/:4:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"3.1 从开发模型的转变说起 3.1.1 瀑布式开发模型 随着市场环境和用户需求变化的不断加速，瀑布式开发模式这种按部就班的方式有一个严重的潜在问题。 软件开发活动需要在项目一开始就确定项目目标、范围以及实现方式，而这个时间点往往是我们对用户和市场环境信息了解最少的时候，这样做出来的决策往往带有很大的不确定性，很容易导致项目范围不断变更，计划不断延期，交付上线时间不断推后，最后的结果是，即便我们投入了大量资源，却难以达到预期的效果。 从业界巨头 IBM 的统计数字来看，有 34% 的新 IT 项目延期交付，将近一半的应用系统因为缺陷导致线上回滚，这是一件多么令人沮丧的事情。 3.1.2 敏捷式开发模型 基于这种问题，敏捷的思潮开始盛行。它的核心理念是，既然我们无法充分了解用户的真实需求是怎样的，那么不如将一个大的目标不断拆解，把它变成一个个可交付的小目标，然后通过不断迭代，以小步快跑的方式持续开发。 与此同时，将测试工作从研发末端的一个独立环节注入整个开发活动中，对开发交付的内容进行持续验证，保证每次可交付的都是一个可用的功能集合，并且由于质量内建在研发环节中，交付功能的质量也是有保障的。 说到底，敏捷源于开发实践，敏捷的应用使得开发和测试团队抱团取暖。可是问题又来了，开发和测试团队发现，不管研发的速度变得多快，在软件交付的另一端，始终有一群人在冷冰冰地看着他们，一句“现在没到发布窗口”让多少新开发的功能倒在了上线的门槛上。 毕竟，无论开发了多少天才的功能，如果没有经过运维环节的部署上线，并最终发布给真实用户，那么这些功能其实并没有什么用。 3.1.3 DevOps模型 在传统模式下，度量开发团队效率的途径就是看开发完成了多少需求。于是，开发为了达成绩效目标，当然也是为了满足业务需求，不断地堆砌新功能，却很少有时间认真思考这些功能的可运维性和可测试性，只要需求状态流转到开发完成就万事大吉了。 而对于运维团队而言，他们的考核指标却是系统的稳定性、可用性和安全性。但现代 IT 系统是如此复杂，以至于每一次的上线发布都是一场战役，整个团队如临大敌，上线失败的焦虑始终如影随形。 很多时候，我们并不知道上线之后会发生什么，只能按照部署手册一步步操作，完成之后就听天由命。所以，每逢大促活动，就会有各种“拜服务器教”的照片广为流传。 另一方面，在无数次被开发不靠谱的功能缺陷蹂躏得体无完肤之后，运维团队意识到，变更才是影响他们绩效目标的最大敌人。于是，预先设立的上线窗口就成了运维团队的自留地，不断抬高的上线门槛也使得开发团队的交付变成了不可能完成的任务，最后，“互相伤害”就成了这个故事注定的结局。 因此，DevOps应运而生，也就是说，DevOps 最开始想要打破的就是开发和运维之间的对立和隔阂。DevOps旨在建立一种文化与环境，使构建、测试、软件发布得以快速、频繁以及更加稳定地进行。 虽然DevOps从一开始是想要促进开发和运维的协作，但是慢慢发现，其实在整个软件交付过程中，不仅只有开发和运维，业务也是重要的一环。 比方说，如果业务制定了一个不靠谱的需求，那么无论开发和运维怎样协作，得到的终究是一个不靠谱的结果，以及对人力的浪费。可是业务并不清楚用户的真实情况，于是运维团队慢慢转向运营团队，他们需要持续不断地把线上的真实数据和用户行为及时地反馈给需求团队，来帮助需求团队客观评估需求的价值，并及时作出有利于产品发展的调整，这样一来，业务也被引入到了 DevOps 之中，甚至诞生了 BizDevOps 这样一个专门的词汇。 那么，既然沟通协作放之四海皆准，安全也开始积极地参与进来。安全不再是系统上线发布之后的“定时炸弹”，而是介入到整个软件开发过程中，在每个过程中注入安全反馈机制，来帮助团队在第一时间应对安全风险，那么，对于安全团队来说，DevSecOps 就成了他们眼中的 DevOps。 这样的例子比比皆是，包括职能部门、战略部门等，都纷纷加入其中，使得 DevOps 由最开始的点，扩展为线，再到面，不断发展壮大。每个人都参与其中，这使得 DevOps 成了每一个 IT 从业人员都需要学习和了解的知识和技能体系。 ","date":"2020-07-01","objectID":"/devops_series/:4:1","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["DevOps"],"content":"结论 本篇文章，我们讲述了Ops的相关内容以及发展历程，然后讲到DevOps，我们最终要解决的是软件在企业中的效率、稳定和成本问题。接下来的文章，我们会针对DevOps说一些技术上的实现细节。 参考 [译]当我们谈论Ops时，我们在谈论什么 运维十年回顾：当前很多新技术的本质都是在解决运维问题 DevOps发展历程 ","date":"2020-07-01","objectID":"/devops_series/:5:0","tags":["devops"],"title":"DevOps系列：开篇","uri":"/devops_series/"},{"categories":["Golang"],"content":"并发","date":"2020-04-07","objectID":"/go_series_conc/","tags":["go"],"title":"Go系列：并发","uri":"/go_series_conc/"},{"categories":["Golang"],"content":"系列目录 《Go系列：内存管理》 《Go系列：调度器》 《Go系列：并发》 ","date":"2020-04-07","objectID":"/go_series_conc/:1:0","tags":["go"],"title":"Go系列：并发","uri":"/go_series_conc/"},{"categories":["Golang"],"content":"调度器","date":"2020-04-07","objectID":"/go_series_scheduler/","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"系列目录 《Go系列：内存管理》 《Go系列：调度器》 《Go系列：并发》 ","date":"2020-04-07","objectID":"/go_series_scheduler/:1:0","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"1. 介绍 随着技术的不断发展，CPU也在不断发展，出现了多处理器、多核心、CPU缓存、NUMA架构等概念。为了最大化利用CPU的计算能力，软件也在不断发展，出现了并发和并行等概念。而为了支持并发和并行，就需要调度器，用于处理计算任务在不同CPU上的计算。我们主要从系统调度和语言层面的调度来说明。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:2:0","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2. OS Scheduler 我们的的程序只是一系列机器指令，需要依次执行。为此，操作系统使用了线程的概念，线程的工作就是负责说明并按顺序执行分配给它的指令集。执行将不断进行，直到没有更多指令可以执行。 在操作系统上，我们运行的每个程序都会创建一个进程，并且为每个进程分配一个初始线程。线程具有创建更多线程的能力。所有这些不同的线程彼此独立运行，并且调度决策是在线程级别而不是在进程级别做出的。线程可以同时运行(并发，每个任务运行在同一个的core上)，也可以并行运行(并行，每个任务运行在不同core上同时运行)。线程还维护自己的状态，以允许在本地安全和独立地执行指令。 如果存在可以执行的线程时，OS Scheduler负责确保core不处于空闲状态。它还必须产生一种幻想，即所有可以执行的线程正在同时执行。在创建这种幻想的过程中，Scheduler需要优先运行优先级较高的线程，而不是运行优先级较低的线程。但是，具有较低优先级的线程并无法节省执行时间。Scheduler还需要通过做出快速而明智的决策来最大程度地减少调度延迟。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:0","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.1 执行指令 程序计数器(PC)有时也称为指令指针(IP)，它使线程可以跟踪要执行的下一条指令。在大多数处理器中，PC指向下一条指令，而不是当前指令。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:1","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.2 Thread状态 Waiting，这意味着线程已经停止执行并需要等待某些操作才能继续。这可能是由于诸如等待硬件(磁盘，网络)，操作系统(系统调用)或同步调用(原子，互斥体)之类的原因。这些类型的延迟是导致性能下降的根本原因。 Runnable ，这意味着线程需要获得cpu时间，这样它可以执行其分配的机器指令。如果您有很多需要cpu时间的线程，则线程必须等待更长的时间才能获得cpu时间。而且，随着更多线程争夺cpu时间，任何给定线程获得的cpu时间都将缩短。这种类型的调度延迟也可能是性能下降的原因 Executing，这意味着线程已放置在core上并正在执行其机器指令。与应用程序相关的工作已经完成。这是每个人都想要的状态。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:2","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.3 工作类型 CPU-Bound，这项工作永远不会造成线程可能处于等待状态的情况。这是不断进行计算的工作。计算Pi到第N位的线程将是CPU-Bound的。 IO-Bound，这项工作导致线程进入等待状态。这项工作包括请求通过网络访问资源或对操作系统进行系统调用。需要访问数据库的线程将是IO-Bound。我将包括同步事件(互斥量，原子)等导致线程进入等待状态的事件都归为此类。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:3","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.4 上下文切换 抢占式调度 首先，这意味着在任何给定时间选择要运行的线程时，调度程序都是不可预测的。线程优先级和事件(例如在网络上接收数据)一起使得无法确定调度程序将选择做什么以及何时执行。 其次，这意味着您绝不能基于自己幸运的经历但不能保证每次都发生的某些感知行为来编写代码。让自己思考很容易，因为我已经看到这种情况以1000次相同的方式发生，这是有保证的行为。如果需要在应用程序中确定性，则必须控制线程的同步和编排。 在内核上交换线程的物理行为称为上下文切换。当调度程序从core中拉出一个excuting线程并将其替换为可runnable线程时，就会发生上下文切换。从运行队列中选择的线程将进入excuting状态。被拉出的线程可以移回runnable状态(如果它仍具有运行能力)或waitting状态(如果由于IO-Bound类型的请求而被替换)。 上下文切换被认为是昂贵的，因为在core上和在core外交换线程都需要时间。上下文切换期间的延迟等待时间量取决于不同的因素，但花费约1000到1500纳秒的时间并非没有道理。虑到硬件应该能够合理地(平均)在每核每纳秒执行12条指令，上下文切换可能会花费大约12000至18k的延迟指令。本质上，您的程序在上下文切换期间将失去执行大量指令的能力。 如果您有一个专注于IO-Bound工作的程序，那么上下文切换将是一个优势。一旦一个线程进入等待状态，另一个处于可运行状态的线程就会代替它。这使核心始终可以工作。这是调度的最重要方面之一。如果有工作要做(线程处于可运行状态)，请不要让core闲置。 如果您的程序专注于CPU-Bound工作，那么上下文切换将成为性能噩梦。由于Thead总是有工作要做，因此上下文切换将阻止该工作的进行。这种情况与IO-Bound工作负载形成鲜明对比。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:4","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.5 少即是多 制定调度决策时，scheduler还需要考虑和处理更多的事情。您可以控制在应用程序中使用的线程数。当要考虑的线程更多，并且发生IO-Bound工作时，就会出现更多的混乱和不确定性行为。任务需要更长的时间来计划和执行。 这就是为什么游戏规则是“少即是多”的原因。处于runnable状态的线程越少，意味着获得调度的时间越少，并且每个线程随着时间的流逝会花费更多的时间。更多线程处于runnable状态意味着每个线程随着时间流逝的时间更少。这意味着随着时间的流逝，您完成的工作也更少了。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:5","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.6 寻找平衡 您需要在拥有的core数量与为应用程序获得最佳吞吐量所需的线程数量之间找到平衡。在管理这种平衡时，线程池是一个很好的答案。 如果您的服务正在执行许多不同类型的工作该怎么办？这可能会产生不同且不一致的延迟。也许它还会创建许多需要处理的不同的系统级事件。不可能找到一个在所有不同工作负荷下始终有效的魔术数字。当涉及到使用线程池来调整服务的性能时，找到正确的一致配置会变得非常复杂。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:6","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.7 CPU缓存 从主存储器访问数据具有很高的延迟成本（〜100至〜300个时钟周期），以致处理器和内核具有本地缓存，以使数据保持在需要它的硬件线程附近。从缓存访问数据的成本要低得多（约3至40个时钟周期），具体取决于要访问的缓存。今天，性能的一个方面是关于如何有效地将数据输入处理器以减少这些数据访问延迟。编写改变状态的多线程应用程序需要考虑缓存系统的机制。 使用cache line在处理器和主存储器之间交换数据。缓存行是在主内存和缓存系统之间交换的64字节内存块。每个内核都会获得所需的任何高速缓存行的副本，这意味着硬件使用值语义。这就是为什么多线程应用程序中的内存突变会造成性能方面的噩梦。 当多个并行运行的线程正在访问同一数据值或什至彼此接近的数据值时，它们将在同一高速缓存行上访问数据。在任何内核上运行的任何线程都将获得该同一缓存行的副本。 如果给定核心上的一个线程更改了其缓存行的副本，则必须借助硬件的魔力，将同一缓存行的所有其他副本标记为脏。当线程尝试对脏的缓存行进行读写访问时，需要主存储器访问（〜100至〜300个时钟周期）才能获取缓存行的新副本. 也许在2核处理器上这没什么大不了，但是如果32核处理器并行运行32个线程，所有访问和变异数据都在同一缓存行上，那又如何呢？带有两个分别具有16个内核的物理处理器的系统又如何呢？由于处理器间通信增加了延迟，因此情况将变得更糟。该应用程序将遍历内存，性能将非常糟糕，并且很可能您将不明白为什么。 这称为高速缓存一致性问题，还引入了错误共享之类的问题。当编写将改变共享状态的多线程应用程序时，必须考虑缓存系统. ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:7","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"2.8 调度决策方案 想象一下，我要您根据我给您的高级信息编写操作系统调度程序。考虑一下您必须考虑的一种情况。请记住，这是调度程序在做出调度决策时必须考虑的许多有趣的事情之一。 您启动您的应用程序，并创建了主线程并在核心1上执行该线程。随着该线程开始执行其指令，由于需要数据，因此正在检索缓存行。线程现在决定为某些并发处理创建一个新线程。这是问题。 创建线程并准备就绪后，调度程序应： 上下文切换核心1的主线程？这样做可以提高性能，因为此新线程需要与已缓存的数据相同的机会非常好。但是主线程无法获得其全部时间片。 线程是否等待核心1可用，等待主线程的时间片完成？线程未运行，但是一旦开始，将消除获取数据的延迟。 线程是否正在等待下一个可用core？这意味着将清除，检索和复制所选核心的缓存行，从而导致延迟。但是，线程将启动得更快，并且主线程可以完成其时间片。 玩得开心吗？在做出调度决策时，OS调度程序需要考虑这些有趣的问题。幸运的是，对于每个人来说，我都不是一个。我只能告诉您的是，如果有一个空闲的内核，它将被使用。您希望线程可以在运行时运行。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:3:8","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3. Go Scheduler ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:0","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.1 进程、线程和协程 进程， 线程， 协程， ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:1","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.2 程序开始 Go程序为主机上标识的每个虚拟core分配了逻辑处理器(P)。如果您的处理器每个物理核心具有多个硬件线程(超线程)，则每个硬件线程将作为虚拟core呈现给您的Go程序。 每个P都分配有一个OS线程(M)。“M\"代表machine。该线程仍由操作系统管理，并且操作系统仍负责将线程放置在内核上执行。 每个Go程序还会获得一个初始Goroutine(G)，这是Go程序的“线程”。Goroutine本质上是一个协程，但是它是Go，因此我们将字母\"C\"替换为\"G”，然后得到单词Goroutine。您可以将Goroutines视为应用程序级线程，并且它们在许多方面类似于OS线程。就像OS线程在上下文中打开和关闭core一样，Goroutine在上下文中打开和关闭M。 最后一个难题是运行队列。Go调度程序中有两个不同的运行队列：全局运行队列(GRQ)和本地运行队列(LRQ)。每个P都有一个LRQ，该LRQ管理分配给在P上下文中执行的Goroutine。这些Goroutine轮流在上下文中切换分配给该P的M。GRQ用于尚未分配给P的Goroutine。有一个将Goroutines从GRQ转移到LRQ的过程，我们将在后面讨论。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:2","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.3 协作式调度 Go Scheduler是Go运行时的一部分，并且Go运行时已内置到您的应用程序中。这意味着Go Scheduler在内核上方的用户空间中运行。 Go Scheduler的当前实现不是抢占式调度器，而是协作式调度器。成为协作调度器味着调度器需要在代码的安全点发生的定义明确的用户空间事件，以制定调度决策。 Go协作调度器的出色之处在于它看起来和感觉都是抢先的。您无法预测Go Scheduler将要执行的操作。这是因为该协作调度器的决策权不掌握在开发人员手中，而在于Go运行时。Go Scheduler视为抢占式调度器很重要，并且由于该调度器是不确定的，因此这并不是一件容易的事。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:3","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.4 Goroutine状态 Waiting: 这意味着Goroutine已停止并等待某些东西才能继续。这可能是由于诸如等待操作系统(系统调用)或同步调用(原子和互斥操作)之类的原因。这些类型的延迟是导致性能下降的根本原因。 Runnable: 这意味着Goroutine需要获得在M上的执行时间，因此它可以执行其分配的指令。如果您有很多需要M时间的Goroutine，那么Goroutine必须等待更长的时间才能获得时间。而且，随着更多Goroutine争夺时间，任何给定Goroutine所获得的时间都将缩短。这种类型的调度延迟也可能是性能下降的原因。 Executing: 这意味着Goroutine已放置在M上并正在执行其指令。与应用程序相关的工作已经完成。这就是每个人都想要的。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:4","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.5 上下文切换 Go Scheduler需要定义明确的用户空间事件，这些事件发生在代码中的安全点处，以便从上下文进行切换。函数调用对于Go调度程序的运行状况至关重要。今天(使用Go 1.11或更低版本)，如果运行任何未进行函数调用的紧密循环，则将导致调度程序和垃圾回收中的延迟。在合理的时间内进行函数调用至关重要。 Go程序中发生了四类事件，这些事件使计划程序可以做出计划决策。这并不意味着它将永远在这些事件之一中发生。这意味着调度器会获得机会。 使用关键字go，关键字go是创建Goroutine的方式。一旦创建了新的Goroutine，它将为调度器提供做出调度决策的机会。 垃圾回收，由于GC使用自己的Goroutine集合运行，因此这些Goroutine需要M上的时间才能运行。这导致GC造成很多调度混乱。但是，调度器对于Goroutine所做的事情非常聪明，它将利用该情报做出明智的决策。这个明智的决定是在GC中将要触摸堆的Goroutine与不触摸堆的Goroutine进行上下文切换。当GC运行时，将制定许多计划决策。 系统调用，如果Goroutine进行了导致Goroutine阻塞M的系统调用，则有时调度器能够将Goroutine上下文切换到M之外，并在上下文中将新Goroutine切换到该M上。但是，有时需要一个新的M来继续执行在P中排队的Goroutine。在下一节中将更详细地说明其工作原理。 同步与编排，如果原子，互斥或channel操作调用将导致Goroutine阻塞，则调度器可以进行上下文切换运行新的Goroutine。一旦Goroutine可以再次运行，就可以对其重新排队，并最终在M上进行上下文切换。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:5","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.6 异步系统调用 当您正在运行的OS能够异步处理系统调用时，可以使用称为网络轮询器的东西来更有效地处理系统调用。这是通过在各个操作系统中使用kqueue(MacOS)，epoll(Linux)或iocp(Windows)来完成的。 我们今天使用的许多操作系统都可以异步处理基于网络的系统调用。这是网络轮询器的名称，这是因为它的主要用途是处理网络操作。通过使用网络轮询器进行网络系统调用，调度器可以防止Goroutine在进行这些系统调用时阻止M。这有助于使M保持可用以执行P的LRQ中的其他Goroutine，而无需创建新的M。这有助于减少OS上的调度负载。 例子： 基本调度图，Goroutine-1正在M上执行，并且还有3个Goroutine在LRQ中等待以获取其在M上的时间。网络轮询器闲置无事可做 Goroutine-1希望进行网络系统调用，因此Goroutine-1被移至网络轮询器并处理了异步网络系统调用。将Goroutine-1移至网络轮询器后，M现在可用于执行与LRQ不同的Goroutine。在这种情况下，Goroutine-2在M上进行了上下文切换。 网络轮询器完成了异步网络系统调用，并将Goroutine-1移回了P的LRQ中。一旦Goroutine-1可以在M上上下文切换回去，它负责的Go相关代码就可以再次执行。这里最大的好处是，执行网络系统调用不需要额外的M。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:6","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.7 同步系统调用 当Goroutine想要进行无法异步完成的系统调用时，会发生什么情况？在这种情况下，无法使用网络轮询器，并且进行系统调用的Goroutine将阻止M。不幸的是，但是无法阻止这种情况的发生。无法异步进行的系统调用的一个示例是基于文件的系统调用。如果使用的是CGO，则在其他情况下，调用C函数也会阻塞M。让我们逐一介绍同步系统调用（例如文件I / O）会导致M阻塞的情况。 再次显示了我们的基本调度图，但是这次Goroutine-1将进行一次同步系统调用，该调用将阻塞M1。 调度器可以识别Goroutine-1导致M阻塞。此时，调度器将M1与P分离，而阻塞Goroutine-1仍处于连接状态。然后，调度器会引入一个新的M2来为P服务。这时，可以从LRQ中选择Goroutine-2，并在M2上进行上下文切换。如果由于先前的交换已存在M，则此过渡比必须创建新的M更快。 Goroutine-1进行的阻止系统调用完成。此时，Goroutine-1可以移回LRQ并再次由P服务。如果这种情况需要再次发生，则将M1放在一边以备将来使用。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:7","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"3.8 工作窃取 计划程序的另一个方面是，它是一种可以窃取工作的计划程序。这有助于在某些方面保持调度效率。首先，您想要的最后一件事是M进入等待状态，因为一旦发生这种情况，操作系统将上下文M切换到core。这意味着，即使有一个Goroutine处于可运行状态，P也无法完成任何工作，直到M在上下文中切换回Core为止。窃取工作还有助于在所有P上平衡Goroutine，从而更好地分配工作并更高效地完成工作。 例子： 我们有一个多线程Go程序，其中两个P分别为四个Goroutine和GRQ中的一个Goroutine提供服务。如果P的服务之一迅速地执行其所有Goroutine，会怎样？ P1没有更多的Goroutines可以执行。但是在P2的LRQ和GRQ中都有可运行状态的Goroutine。这是P1需要窃取工作的时刻。窃取工作的规则如下。 runtime.schedule() { // only 1/61 of the time, check the global runnable queue for a G. // if not found, check the local queue. // if not found, // try to steal from other Ps. // if not, check the global runnable queue. // if not found, poll network. } 因此，根据清单2中的这些规则，P1需要在其LRQ中检查P2中的Goroutines，并取其发现结果的一半。 Goroutine的一半来自P2，现在P1可以执行这些Goroutine。 如果P2完成其所有Goroutine的服务并且P1的LRQ中没有剩余，该怎么办？ P2完成了所有工作，现在需要偷一些东西。首先，它将查看P1的LRQ，但找不到任何Goroutine。接下来，将查看GRQ。在那里它将找到Goroutine-9。 P2从GRQ窃取Goroutine-9，并开始执行工作。所有这些偷窃工作的最大好处是，它可以让M保持忙碌而不会闲着。内部，这种窃取工作被认为是在旋转M。这种旋转还有其他好处，JBD在她的工作窃取博客文章中很好地解释了这一点。 ","date":"2020-04-07","objectID":"/go_series_scheduler/:4:8","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"4. 结论 这里讲了OS Scheduler和Go Scheduler的相关的实现原理。 参考 OS Scheduler Go Scheduler ","date":"2020-04-07","objectID":"/go_series_scheduler/:5:0","tags":["go"],"title":"Go系列：调度器","uri":"/go_series_scheduler/"},{"categories":["Golang"],"content":"内存管理","date":"2020-04-01","objectID":"/go_series_mem/","tags":["go"],"title":"Go系列：内存管理","uri":"/go_series_mem/"},{"categories":["Golang"],"content":"系列目录 《Go系列：内存管理》 《Go系列：并发》 ","date":"2020-04-01","objectID":"/go_series_mem/:1:0","tags":["go"],"title":"Go系列：内存管理","uri":"/go_series_mem/"},{"categories":["Nginx"],"content":"Nginx匹配机制总结","date":"2020-02-06","objectID":"/nginx_match/","tags":["nginx","linux\"","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Nginx"],"content":"背景 Nginx是一个当前主流的HTTP服务器和反向代理服务器，很多做WEB相关的同学基本都会用到，很多云厂商的七层负载均衡器也基本都是基于nginx实现的，个人在工作过程也算是经常接触，这篇文章主要想总结一下nginx的匹配机制，主要分为两块，一块是server的匹配，一块是location的匹配。 ","date":"2020-02-06","objectID":"/nginx_match/:1:0","tags":["nginx","linux\"","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Nginx"],"content":"Server匹配机制 配置过nginx的都知道，在一个http模块中是可以配置多个server模块的，并且多个server模块是可以配置相同的监听端口的，下面是一个简单的server配置例子： server { listen 80; server_name example.org www.example.org; ... } server { listen 80; server_name example.net www.example.net; ... } server { listen 80; server_name example.com www.example.com; ... } 当我们对nginx发起http请求后，nginx会拿到http请求中对应的 \"Host\" 头部跟server模块中的server_name进行匹配，根据匹配的server结果进入具体的server模块处理http请求。那么，它具体的匹配机制是怎样的呢？ 首先，我们先简单了解下nginx内部server的相关结构， 其中listen和server_name在配置文件中的写法有： listen(可带default_server标识) ip:port ip(监听80端口) port(监听所有地址) server_name www.example.com(完整域名) *.example.com(带通配符开头的域名) www.example.*(带通配符结尾的域名) ~^(www.)?(.+)$(正则写法的域名) 代码中的具体结构： /************************************************************************************* 伪结构体示例 (port) --\u003e address(ip:port) --\u003e server(example.com) --\u003e server(example.net) 一个server模块的唯一标识是由address(listen配置)和server(server_name配置)组成 *************************************************************************************/ /* address 结构体，具有相同的ip:port */ struct ngx_http_addr_conf_s { /* default_server 存储的是listen配置里带default_server标识的server， 若没有就为顺序中的第一个server */ ngx_http_core_srv_conf_t *default_server; ngx_http_virtual_names_t *virtual_names; unsigned ssl:1; unsigned http2:1; unsigned proxy_protocol:1; }; /* virtual_name结构体，存储hash_combined和正则写法的server_name */ typedef struct { ngx_hash_combined_t names; ngx_uint_t nregex; ngx_http_server_name_t *regex; } ngx_http_virtual_names_t; /* hash_combined结构体，存储完成域名、通配符开头、通配符结尾的server_name */ typedef struct { ngx_hash_t hash; ngx_hash_wildcard_t *wc_head; ngx_hash_wildcard_t *wc_tail; } ngx_hash_combined_t; 通过结构体，我们来说明下server的匹配规则： host是否匹配virtual_names中的names中的完整域名(hash)，若是则返回 host是否匹配virtual_name中的names中的通配符开头的域名(wc_head)，若是则返回 host是否匹配virtual_name中的names中的通配符结尾的域名(wc_tail)，若是则返回 host是否匹配virtual_name中的正则写法的域名(regex)，若是则返回 返回default_server 具体示例如下： #精确匹配，第一优先级 server { listen 80; server_name www.test.com; } #通配符开头匹配，第二优先级， server { listen 80; server_name *.test.com; } #通配符结尾匹配，第三优先级 server { listen 80; server_name www.test.*; } #正则匹配，第三优先级 server { listen 80; server_name ~^(www.)?(.+)$; } #default，没找到对应host，则以此优先 server { listen 80 defalut_server; server_name _; } #若没有加defalut_server，则第一个server为defalut_server server { listen 80; server_name _; } ","date":"2020-02-06","objectID":"/nginx_match/:2:0","tags":["nginx","linux\"","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Nginx"],"content":"Location匹配机制 一个server模块可以配置多个location，nginx根据URI来进行匹配， lication的写法有以下几种： = /uri 精确匹配 ^~ /uri 非正则前缀匹配 ~ 或者 ~* /uri 正则匹配 /uri 前缀匹配 整个location匹配机制如下： 针对所有前缀字符串测试URI(包括精确匹配、非正则前缀匹配、前缀匹配中的字符串) uri等于精确匹配中的字符串，停止搜索 最长(最相似)前缀字符串如果为非正则前缀匹配(带^~)，则停止正则搜索 保存最长(最相似)的前缀字符串 按顺序进行uri和正则匹配测试，有一个匹配成功后就停止搜索 如果都没有，就使用最长(最相似)的前缀匹配 额外说明： 最长(最相似)前缀字符串的测试阶段，非正则前缀匹配匹配、前缀匹配的优先级是一致的，谁的长度长，谁优先。优先前缀匹配的前提必须是前缀字符串非正则前缀匹配的长度大于前缀匹配的长度，这个很多网站都是直接写成了非正则前缀匹配是第二优先级，没有说明前提条件。 具体示例如下： #精确匹配，第一优先级 location = /test { } #前缀匹配，最低优先级，长度优先 location /test/aa { } #非正则前缀匹配，最长前缀下为第二优先级(特殊条件下) location ^~ /test { } #正则匹配，第三优先级,顺序优先 # ~ : 区分大小写 # ~* : 不区分大小写 location ~* ^/test { } ","date":"2020-02-06","objectID":"/nginx_match/:3:0","tags":["nginx","linux\"","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Nginx"],"content":"参考 https://nginx.org/en/docs/http/request_processing.html https://nginx.org/en/docs/http/ngx_http_core_module.html#location https://docs.nginx.com/nginx/admin-guide/web-server/web-server/ https://www.codedump.info/post/20190212-nginx-http-config/ ","date":"2020-02-06","objectID":"/nginx_match/:4:0","tags":["nginx","linux\"","application"],"title":"Nginx匹配机制总结","uri":"/nginx_match/"},{"categories":["Linux"],"content":"谈谈文件描述符","date":"2019-12-29","objectID":"/file_descriptor/","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"概念 wiki解释，文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。 一个文件描述符是一个数字，唯一标识一个在计算机的操作系统打开的文件。它描述了数据资源，以及如何访问该资源。 当程序要求打开文件（或其他数据资源，例如网络套接字）时，内核： 授予访问权限。 在全局文件表中创建一个条目。 向软件提供该条目的位置。 该描述符是唯一的非负整数。系统上每个打开的文件至少存在一个文件描述符。 ","date":"2019-12-29","objectID":"/file_descriptor/:1:0","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"细节 对于内核，所有打开的文件均由文件描述符引用。文件描述符是一个非负数。当我们打开现有文件或创建新文件时，内核将文件描述符返回到进程。当我们想读取或写入文件时，我们用文件描述符标识文件。 每个Linux进程（也许是守护程序除外）都应该具有三个标准的POSIX文件描述符： POSIX常数名称 文件描述符 描述 STDIN_FILENO 0 标准输入 STDOUT_FILENO 1 标准输出 STDERR_FILENO 2 标准误差 有三个“系统文件表”：有一个文件描述符表，它将文件描述符（小整数）映射到打开的文件表中的条目。打开文件表中的每个条目（除其他事项外）还包含文件偏移量和指向内存中inode表的指针。在打开的文件表中，每个open（）调用都有一个文件表条目，如果文件描述符是dup（）ed或fork（）ed，则共享该条目。 我们使用来自维基百科的示例来显示这些表的工作方式。这是一张照片： 单个进程的文件描述符，文件表和索引节点表。请注意，多个文件描述符可以引用相同的文件表条目（例如，由于dup系统调用），并且多个文件表条目可以依次引用同一个索引节点（如果已多次打开；则该表之所以仍然简化，是因为它通过文件名来表示索引节点，即使索引节点可以具有多个名称也是如此。文件描述符3没有引用文件表中的任何内容，表明它已关闭。 理解具体情况，需要了解由内核维护的 3 个数据结构： 进程级 文件描述符表 ( file descriptor table ) 系统级 打开文件表 ( open file table ) 文件系统 i-node表 ( i-node table ) 这 3 个数据结构之间的关系如图所示： ","date":"2019-12-29","objectID":"/file_descriptor/:2:0","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"文件描述符表 内核为每个进程维护一个 文件描述符表 ，该表每一条目都记录了单个文件描述符的相关信息，包括： 控制标志 ( flags )，目前内核仅定义了一个，即 close-on-exec 打开文件描述体指针 ","date":"2019-12-29","objectID":"/file_descriptor/:2:1","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"打开文件表 内核对所有打开的文件维护一个系统级别的 打开文件描述表 ( open file description table )，简称 打开文件表 。 表中条目称为 打开文件描述体 ( open file description )，存储了与一个打开文件相关的全部信息，包括： 文件偏移量 ( file offset )，调用 read() 和 write() 更新，调用 lseek() 直接修改 访问模式 ，由 open() 调用设置，例如：只读、只写或读写等 i-node 对象指针 ","date":"2019-12-29","objectID":"/file_descriptor/:2:2","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"i-node 表 每个文件系统会为存储于其上的所有文件(包括目录)维护一个 i-node 表，单个 i-node 包含以下信息： 文件类型 ( file type )，可以是常规文件、目录、套接字或 FIFO 访问权限 文件锁列表 ( file locks ) 文件大小 等等 i-node 存储在磁盘设备上，内核在内存中维护了一个副本，这里的 i-node 表为后者。 副本除了原有信息，还包括： 引用计数 (从打开文件描述体)、所在 设备号 以及一些临时属性，例如文件锁。 ","date":"2019-12-29","objectID":"/file_descriptor/:2:3","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"参数优化 ","date":"2019-12-29","objectID":"/file_descriptor/:3:0","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"1. 系统最大的文件描述符数量 系统文件最大值取决于内存大小，在kernel初始化时定义 代码: /* * One file with associated inode and dcache is very roughly 1K. Per default * do not use more than 10% of our memory for files. */ void __init files_maxfiles_init(void) { unsigned long n; unsigned long nr_pages = totalram_pages(); unsigned long memreserve = (nr_pages - nr_free_pages()) * 3/2; memreserve = min(memreserve, nr_pages - 1); n = ((nr_pages - memreserve) * (PAGE_SIZE / 1024)) / 10; files_stat.max_files = max_t(unsigned long, n, NR_FILE); } 由代码可知，file-max的值不超过内存的10% #获取total ram pages 和 PAGE_SIZE大小 $ getconf -a | grep \"PAGE\" PAGESIZE 4096 PAGE_SIZE 4096 _AVPHYS_PAGES 565489 _PHYS_PAGES 1011579 #查看系统最大打开文件描述符数 $ cat /proc/sys/fs/file-max 399894 #查看当前系统使用的打开文件描述符数 $ cat /proc/sys/fs/file-nr 928 0 399894 | | |_ Max no. of file descriptors allowed on the system | | | |__ Total free allocated file descriptors | |__ Total allocated file descriptors #设置系统最大文件描述符 #临时性 $ echo 1000000 \u003e /proc/sys/fs/file-max #永久性 #在/etc/sysctl.conf中设置 fs.file-max = 1000000 $ sysctl -p ","date":"2019-12-29","objectID":"/file_descriptor/:3:1","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"2. 进程最大描述符 # 查看某个进程的使用 $ ls -l /proc/2374/fd | wc -l # 进程最大打开文件描述符数 #soft limit $ ulimit -n 65535 #hard limit $ ulimit -Hn 65535 #soft limit不能大于hard limit #设置 #临时性 $ ulimit -Sn 1600000 #永久性 $ vim /etc/security/limits.conf root soft nofile 65535 root hard nofile 65535 #设置nofile的hard limit还有一点要注意的就是hard limit不能大于/proc/sys/fs/nr_open ","date":"2019-12-29","objectID":"/file_descriptor/:3:2","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"3. 总结 1. 所有进程打开的文件描述符数不能超过/proc/sys/fs/file-max 2. 单个进程打开的文件描述符数不能超过user limit中nofile的soft limit 3. nofile的soft limit不能超过其hard limit 4. nofile的hard limit不能超过/proc/sys/fs/nr_open ","date":"2019-12-29","objectID":"/file_descriptor/:3:3","tags":["linux"],"title":"谈谈文件描述符","uri":"/file_descriptor/"},{"categories":["Linux"],"content":"Linux PAM模块","date":"2019-09-05","objectID":"/linux_pam/","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"概念 Linux-PAM（Pluggable Authentication Modules for Linux）是一套共享库,使本地系统管理员可以随意选择程序的认证方式。换句话说，不用(重新编写)重新编译一个包含PAM功能的应用程序，就可以改变它使用的认证机制，这种方式下，就算升级本地认证机制,也不用修改程序。 ","date":"2019-09-05","objectID":"/linux_pam/:1:0","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"工作机制 当应用程序希望与PAM交互以处理事件时，他们必须包括libpam，该libpam允许通过库提供的API进行通信。 当PAM看到必须处理的新事件时，它将查看/etc/pam.d中的相关配置文件，并确定在某些阶段必须使用哪些模块。 ","date":"2019-09-05","objectID":"/linux_pam/:2:0","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"/etc/pam.d配置文件介绍 配置文件语法 type control module-path module-arguments 配置文件分为四列 第一列代表模块类型 第二列代表控制标记 第三列代表模块路径 第四列代表模块参数 ","date":"2019-09-05","objectID":"/linux_pam/:3:0","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"类型 类型 是规则对应的管理组。它用于指定后续模块要与哪个管理组关联。 目前有四种类型: account 此模块类型执行基于非身份验证的帐户管理。 通常用于限制/允许对服务的访问，例如是否允许登录,是否达到最大用户数,或是root用户是否允许在这个终端登录等。 auth 此模块为用户验证提供两方面服务。让应用程序提示用户输入密码或者其他标记，确认用户合法性；通过他的凭证许可权限，设定组成员关系或者其他优先权。 password 此模块用于控制用户更改密码的全过程。 session 此模块处理为用户提供服务之前/后需要做的些事情。包括：开启/关闭交换数据的信息，监视目录等，设置用户会话环境等。也就是说这是在系统正式进行服务提供之前的最后一道关口。 如果在类型前加一个短横线 -，就表示如果找不到这个模块，导致无法被加载时，这一事件不会被记录在日志中。这个功能适用于那些认证时非必需的、安装时可能没被安装进系统的模块。 ","date":"2019-09-05","objectID":"/linux_pam/:3:1","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"控制标记 流程栈（stack） 它是认证时执行步骤和规则的堆叠。在某个服务的配置文件中，它体现在了配置文件中的自上而下的执行顺序中。栈是可以被引用的，即在一个栈（或者流程）中嵌入另一个栈。 控制标记 规定如何处理PAM模块鉴别认证的结果，简而言之就是鉴别认证成功或者失败之后会发生什么事，如何进行控制。一般有两种形式，一种是比较常见的“关键字”方式，另一种则是用方括号（[]）包含的“value =action”方式。 关键字方式: required 如果本条目没有被满足，那最终本次认证一定失败，但认证过程不因此打断。整个栈运行完毕之后才会返回“认证失败”信号。 requisite 如果本条目没有被满足，那本次认证一定失败，而且整个栈立即中止并返回错误信号。 sufficient 如果本条目的条件被满足，且本条目之前没有任何required条目失败，则立即返回“认证成功”信号；如果对本条目的验证失败，不对结果造成影响。 optional 该条目仅在整个栈中只有这一个条目时才有决定性作用，否则无论该条验证成功与否都和最终结果无关。 include 将其他配置文件中的流程栈包含在当前的位置，就好像将其他配置文件中的内容复制粘贴到这里一样。 substack 运行其他配置文件中的流程，并将整个运行结果作为该行的结果进行输出。该模式和 include 的不同点在于认证结果的作用域：如果某个流程栈 include 了一个带 requisite 的栈，这个 requisite 失败将直接导致认证失败，同时退出栈；而某个流程栈 substack 了同样的栈时，requisite 的失败只会导致这个子栈返回失败信号，母栈并不会在此退出。 value = action方式: 另外还有一种比较复杂的格式为value = action的语法来设置控制标志，标志之间会以空格分开。格式如下： [value1 = action1 value2 = action2 ……] 其中value可以是下列Linux PAM库的返回值： success、open_err、symbol_err、service_err、 system_err、buf_err、perm_denied、auth_err、cred_insufficient、authinfo_unavail、user_unknown、maxtries、new_authtok_reqd、acct_expired、 session_err、cred_unavail、cred_expired、cred_err、no_module_data、conv_err、 authtok_err、authtok_recover_err、authtok_lock_busy、authtok_disable_aging、 try_again、ignore、abort、authtok_expired、module_unknown、bad_item和default。其中，default代表其他所有没有明确说明的返回值。 流程栈中很可能有多个验证规则，每条验证的返回值可能不尽相同，那么到底哪一个验证规则能作为最终的结果呢？这就需要 actionN 的值来决定了。actionN 的值有以下几种： ignore 在一个栈中有多个认证条目的情况下，如果标记 ignore 的返回值被命中，那么这条返回值不会对最终的认证结果产生影响。 bad 标记 bad 的返回值被命中时，最终的认证结果注定会失败。此外，如果这条 bad 的返回值是整个栈的第一个失败项，那么整个栈的返回值一定是这个返回值，后面的认证无论结果怎样都改变不了现状了。 die 标记 die 的返回值被命中时，马上退出栈并宣告失败。整个返回值为这个 die 的返回值。 ok 在一个栈的运行过程中，如果 ok 前面没有返回值，或者前面的返回值为 PAM_SUCCESS，那么这个标记了 ok 的返回值将覆盖前面的返回值。但如果前面执行过的验证中有最终将导致失败的返回值，那 ok 标记的值将不会起作用。 done 在前面没有 bad 值被命中的情况下，done 值被命中之后将马上被返回，并退出整个栈。 N（无符号整数） 功效和 ok 类似，并且会跳过接下来的 N 个验证步骤。如果 N = 0 则和 ok 完全相同。 reset 清空之前生效的返回值，并且从下面的验证起重新开始。 关键字的控制方式也可以用value = action方式来表示 #required [success=ok new_authtok_reqd=ok ignore=ignore default=bad] #requisite [success=ok new_authtok_reqd=ok ignore=ignore default=die] #sufficient [success=done new_authtok_reqd=done default=ignore] #optional [success=ok new_authtok_reqd=ok default=ignore] ","date":"2019-09-05","objectID":"/linux_pam/:3:2","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"模块路径 模块路径 是应用程序要使用的PAM的绝对路径，或者是默认模块位置的相对路径名，一般为/lib/security /或/lib64/security/，取决于系统架构。 ","date":"2019-09-05","objectID":"/linux_pam/:3:3","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"模块参数 模块参数 将只和特定模块相关，因此某个模块的文档中一定包含其参数的信息。如果需要在单个参数中使用空格，可以将整个参数用方括号（[]）包裹起来。 ","date":"2019-09-05","objectID":"/linux_pam/:3:4","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Linux"],"content":"一个例子 以/etc/pam.d/sshd为例 加载/etc/pam.d/password-auth配置文件 大部分模块的配置文件可在/etc/security中找到，并进行配置 我们比较常进行配置的最大文件数和最大进程数就是在limit.conf中配置，在sshd中会加载到 ","date":"2019-09-05","objectID":"/linux_pam/:4:0","tags":["linux","security"],"title":"Linux PAM模块","uri":"/linux_pam/"},{"categories":["Security"],"content":"理解SSL/TLS协议","date":"2017-01-08","objectID":"/tls/","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"背景 早期我们在访问web时使用HTTP协议，该协议在传输数据时使用明文传输，明文传输带来了以下风险： 信息窃听风险，第三方可以获取通信内容 信息篡改风险，第三方可以篡改通信内容 身份冒充风险，第三方可以冒充他人身份参与通信 为了解决明文传输所带来的风险，网景公司在1994年设计了SSL用于Web的安全传输协议，这是SSL的起源。IETF将SSL进行标准化，1999年公布了第一版TLS标准文件。随后又公布了 RFC 5246（2008年8月）与 RFC 6176 （2011年3月）。该协议在web中被广泛应用。 ","date":"2017-01-08","objectID":"/tls/:1:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"SSL/TLS协议 TLS（Transport Layer Security，传输层安全协议），及其前身SSL（Secure Sockets Layer，安全套接层）是一种安全协议，目的是为互联网通信，提供安全及数据完整性保障。 TLS协议使用以下三种机制为信息通信提供安全传输： 隐秘性，所有通信都通过加密后进行传播 身份认证，通过证书进行认证 可靠性，通过校验数据完整性维护一个可靠的安全连接 ","date":"2017-01-08","objectID":"/tls/:2:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"以TLS1.2为例说明TLS协议 TLS协议由TLS Record Protocol和TLS Handshake Protocol两层协议组成 ","date":"2017-01-08","objectID":"/tls/:3:0","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"TLS Record Protocol 该协议提供了连接安全的两个基本特性： 连接私有 对称密码用于数据加密，这种对称加密是为每条连接唯一生成的并基于另一个人协商的秘密协议 连接可靠 消息传输包括一条消息 使用密钥MAC进行完整性检查，安全哈希函数（例如， SHA-1等）用于MAC计算。 ","date":"2017-01-08","objectID":"/tls/:3:1","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"TLS Handshake Protocol 该协议提供了连接安全的三个基本特性： 可以使用非对称身份验证对等方的身份，或者 公钥，密码学等 共享密钥的协商是安全的 谈判可靠 一个TLS握手协议一般涉及以下步骤： 交换hello信息用于算法协商，交换随机值，并检查会话是否恢复 交换必要的密码信息以允许客户端和服务端同意使用premaster secret 交换证书和密码信息以允许客户端和服务端进行身份验证 通过随机值和premaster secret生成master secret 向record layer提供安全参数 允许客户端和服务器验证其对等方具有计算出的相同安全参数，并且握手发生在没有被攻击者篡改的情况下 TLS握手的完整消息流 ClientHello 客户端提供了以下内容: 支持的协议版本 客户端随机数据(后续用于握手) 可选的session id 加密套件列表 压缩方法列表 扩展列表 ServerHello 服务端提供了以下内容： 选择后的协议版本 选择后的加密套件 选择后的压缩方法 服务端随机数据(后续用于握手) session id 扩展列表 ServerCertificate 服务端提供了证书，证书包含以下内容： 服务端的hostname 服务端所使用的公钥 来自受信任的第三方的证明，证明此hostname的所有者拥有此公钥的私钥 ServerKeyExchange(可选) 服务端仅在证书包含的信息不足以使客户端进行premaster secret交换时发送该消息 CertificateRequest(可选) 当服务端需要客户端证书时发送，需要加密套件支持 ServerHelloDone 服务端表明已经完成了一半的handshake ClientCertificate(可选) 当服务端有需要验证客户端证书时发送，如果加密套件不支持，则消息不包含证书 ClientKeyExchange 生成一个48byte的premaster secret，并通过服务端证书包含的公钥进行加密发送给服务端 CertificateVerify(可选) 该消息只在客户端证书具有签名能力时发送 ClientChangeCipherSpec(message) 一种协议，数据只有一字节，用于告知Server端已经切换到之前协商好的加密套件的状态，准备使用之前协商好的加密套件加密数据并进行传输了。 ClientFinished 客户端和服务端现在都拥有3个数值 ClientHello.random ServerHello.random premaster secret master secret由上面三个数值计算而成 master_secret = PRF(pre_master_secret,\"master secret\",ClientHello.random + ServerHello.random)[0..47]; 使用master secret加密finished消息发送给服务端 ServerChangeCipherSpec(message) 同上 ServerFinished 同上 根据之前的握手信息，如果客户端和服务端都能对Finish信息进行正常加解密且消息正确的被验证，则说明握手通道已经建立成功。 接下来，双方所有的通信数据都通过Master Secret进行加密后传输。　 ","date":"2017-01-08","objectID":"/tls/:3:2","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Security"],"content":"参考： WIKI/Transport_Layer_Security RFC 5246 图示TLS连接 ","date":"2017-01-08","objectID":"/tls/:3:3","tags":["security"],"title":"理解SSL/TLS协议","uri":"/tls/"},{"categories":["Network"],"content":"谈谈HTTP","date":"2016-05-29","objectID":"/http/","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"写在前面 如今网络已经无处不在，人们通过网络获取浏览各种信息，其中，大部分都是通过浏览器访问各种网页来获取我们想要的信息，那么浏览器与网页(服务端)究竟是如何通信的呢？这就得从HTTP协议说起了，浏览器获取网页信息都是基于HTTP协议来处理的。 ","date":"2016-05-29","objectID":"/http/:0:1","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"概念 HTTP（HyperText Transfer Protocol，超文本传输协议）是互联网上应用最为广泛的一种网络协议。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。通过HTTP或者HTTPS协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。其具有如下特点： 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快 PS：尽管TCP/IP协议是互联网上最流行的应用，HTTP协议中，并没有规定必须使用它或它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP假定其下层协议提供可靠的传输。因此，任何能够提供这种保证的协议都可以被其使用。因此也就是其在TCP/IP协议族使用TCP作为其传输层。 ","date":"2016-05-29","objectID":"/http/:0:2","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"工作流程 HTTP协议的通信过程永远是客户端发起请求(request)，服务器回送响应(respone)，如下图所示： 一个完整的HTTP操作称为一个事务，其流程可分为四步： 建立连接(TCP三次握手) 客户端发送一个请求报文给服务器 服务器响应对应信息 客户端接收信息，然后断开连接 ","date":"2016-05-29","objectID":"/http/:0:3","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"请求和响应详解 请求报文 请求行：由请求方法、URL和HTTP版本组成 eg：GET /index.html HTTP/1.1 请求方法 GET：请求获取URI所标识的资源 HEAD：请求获取URI所标识的资源，但不传回资源的文本部分 POST：向指定URI资源提交数据，请求服务器进行处理 PUT：向指定URI资源上传其最新内容 DELETE：请求服务器删除URI所标识的资源 TRACE：回显服务器收到的请求，主要用于测试或诊断 OPTIONS：请求URI资源所支持的HTTP请求方法 CONNECT：HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接 URL 请求的资源路径 协议版本 现在大部分为HTTP/1.0 和 HTTP/1.1 请求头部 eg：host:www.google.com host为必选，其他都为可选参数 空行 消息体 请求所带的文本 响应报文 状态行：由协议版本、状态码和描述信息组成 eg：HTTP/1.1 200 OK 协议版本 状态码：用于告诉客户端，服务器是否产生预期的响应 1XX：提示信息，表示请求已被成功接收，继续处理 2XX：成功，表示请求已被成功接收，理解 3XX：重定向，要完成请求必须进行更进一步的处理 4XX：客户端错误，请求有语法错误或请求无法实现 5XX：服务器端错误，服务器未能实现合法的请求 描述信息 响应头部 空行 消息体 一个例子 访问codecc.xyz首页 Request，首行为请求行，其余为请求头部 Respone，首行为响应状态行，空行前为响应头部，其余为响应数据 ","date":"2016-05-29","objectID":"/http/:0:4","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol ","date":"2016-05-29","objectID":"/http/:0:5","tags":["network"],"title":"谈谈HTTP","uri":"/http/"},{"categories":["Linux"],"content":"理解系统启动过程","date":"2016-05-21","objectID":"/system_start/","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"前言 Linux是一种自由和开放源代码的类UNIX操作系统。该操作系统的内核由林纳斯·托瓦兹在1991年10月5日首次发布。在加上用户空间的应用程序之后，成为Linux操作系统。Linux是自由软件和开放源代码软件发展中最著名的例子。 接触Linux的时间也不算短了，一直都是直接使用Linux操作系统进行一些工作，很少去了解系统从开机到能使用的整个过程，感觉有需要好好理解下整个系统的启动过程，故写这篇博客加深一下理解。 ","date":"2016-05-21","objectID":"/system_start/:0:1","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"启动过程 先通过一张图来简单了解下整个系统启动的流程，整个过程基本可以分为POST–\u003eBIOS–\u003eMBR(GRUB)–\u003eKernel–\u003eInit–\u003eRunlevel。下面会详细说明每个过程的作用。 BIOS BIOS(Basic Input/Output System)，基本输入输出系统，该系统存储于主板的ROM芯片上，计算机在开机时，会最先读取该系统，然后会有一个加电自检过程，这个过程其实就是检查CPU和内存，计算机最基本的组成单元(控制器、运算器和存储器)，还会检查其他硬件，若没有异常就开始加载BIOS程序到内存当中。详细的BIOS功能，这边就不说了，BIOS主要的一个功能就是存储了磁盘的启动顺序，BIOS会按照启动顺序去查找第一个磁盘头的MBR信息，并加载和执行MBR中的Bootloader程序，若第一个磁盘不存在MBR，则会继续查找第二个磁盘(PS：启动顺序可以在BIOS的界面中进行设置)，一旦BootLoader程序被检测并加载内存中，BIOS就将控制权交接给了BootLoader程序。 MBR MBR(Master Boot Record)，主引导记录，MBR存储于磁盘的头部，大小为512bytes，其中，446bytes用于存储BootLoader程序，64bytes用于存储分区表信息，最后2bytes用于MBR的有效性检查。 GRUB GRUB(Grand Unified Bootloader)，多系统启动程序，其执行过程可分为三个步骤： Stage1：这个其实就是MBR，它的主要工作就是查找并加载第二段Bootloader程序(stage2)，但系统在没启动时，MBR根本找不到文件系统，也就找不到stage2所存放的位置，因此，就有了stage1_5 Stage1_5：该步骤就是为了识别文件系统 Stage2：GRUB程序会根据/boot/grub/grub.conf文件查找Kernel的信息，然后开始加载Kernel程序，当Kernel程序被检测并在加载到内存中，GRUB就将控制权交接给了Kernel程序。 PS：实际上这个步骤/boot还没被挂载，GRUB直接识别grub所在磁盘的文件系统，所以实际上应该是/grub/grub.conf文件，该配置文件的信息如下： grub.conf: #boot=/dev/sda default=0 #设定默认启动的title的编号，从0开始 timeout=5 #等待用户选择的超时时间 splashimage=(hd0,0)/boot/grub/splash.xpm.gz #GRUB的背景图片 hiddenmenu #隐藏菜单 title CentOS (2.6.18-194.el5PAE) #内核标题 root (hd0,0) #内核文件所在的设备 kernel /vmlinuz-2.6.18-194.el5PAE ro root=LABEL=/ #内核文件路径以及传递给内核的参数 initrd /initrd-2.6.18-194.el5PAE.img #ramdisk文件路径 ``` Kernel Kernel，内核，Kernel是Linux系统最主要的程序，实际上，Kernel的文件很小，只保留了最基本的模块，并以压缩的文件形式存储在硬盘中，当GRUB将Kernel读进内存，内存开始解压缩内核文件。讲内核启动，应该先讲下initrd这个文件， initrd(Initial RAM Disk)，它在stage2这个步骤就被拷贝到了内存中，这个文件是在安装系统时产生的，是一个临时的根文件系统(rootfs)。因为Kernel为了精简，只保留了最基本的模块，因此，Kernel上并没有各种硬件的驱动程序，也就无法识rootfs所在的设备，故产生了initrd这个文件，该文件装载了必要的驱动模块，当Kernel启动时，可以从initrd文件中装载驱动模块，直到挂载真正的rootfs，然后将initrd从内存中移除。 Kernel会以只读方式挂载根文件系统，当根文件系统被挂载后，开始装载第一个进程(用户空间的进程)，执行/sbin/init，之后就将控制权交接给了init程序。 Init init，初始化，顾名思义，该程序就是进行OS初始化操作，实际上是根据/etc/inittab(定义了系统默认运行级别)设定的动作进行脚本的执行，第一个被执行的脚本为/etc/rc.d/rc.sysinit，这个是真正的OS初始化脚本，简单讲下这个脚本的任务(可以去看看实际脚本，看看都做了什么)： 激活udev和selinux; 根据/etc/sysctl.conf文件，来设定内核参数; 设定系统时钟; 装载硬盘映射; 启用交换分区; 设置主机名; 根文件系统检测，并以读写方式重新挂载根文件系统; 激活RAID和LVM设备; 启用磁盘配额; 根据/etc/fstab，检查并挂载其他文件系统; 清理过期的锁和PID文件 执行完后，根据配置的启动级别，执行对应目录底下的脚本，最后执行/etc/rc.d/rc.local这个脚本，至此，系统启动完成。 Runlevel runlevel，运行级别，不同的级别会启动的服务不一样，init会根据定义的级别去执行相应目录下的脚本，Linux的启动级别分为以下几种： 0：关机模式 1：单一用户模式(直接以管理员身份进入) 2：多用户模式（无网络） 3：多用户模式（命令行） 4：保留 5：多用户模式（图形界面） 6：重启 在不同的运行级别下，/etc/rc.d/rc这个脚本会分别执行不同目录下的脚本： Runlevel 0 – /etc/rc.d/rc0.d/ Runlevel 1 – /etc/rc.d/rc1.d/ Runlevel 2 – /etc/rc.d/rc2.d/ Runlevel 3 – /etc/rc.d/rc3.d/ Runlevel 4 – /etc/rc.d/rc4.d/ Runlevel 5 – /etc/rc.d/rc5.d/ Runlevel 6 – /etc/rc.d/rc6.d/ 这些目录下的脚本只有K*和S*开头的文件，K开头的文件为开机需要执行关闭的服务，S开头的文件为开机需要执行开启的服务。 ","date":"2016-05-21","objectID":"/system_start/:0:2","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Linux"],"content":"参考 http://www.thegeekstuff.com/2011/02/linux-boot-process/ [http://www.ibm.com/developerworks/library/l-linuxboot/]( ","date":"2016-05-21","objectID":"/system_start/:0:3","tags":["linux"],"title":"理解系统启动过程","uri":"/system_start/"},{"categories":["Network"],"content":"谈谈DNS","date":"2016-05-21","objectID":"/dns/","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"写在前面 目前，我们大部分的网络通信都是基于TCP/IP协议的，而TCP/IP又基于IP地址作为唯一标识进行通信，随着需要记忆的IP地址数量的增多，肯定会超出我们的记忆能力范围，但如果使用一种利于人们的记忆的方式，如域名，例如\"www.google.com”，我们便可以轻松的记忆这种方式的标识，而不是繁杂的数字。而DNS(域名系统)就是为了可以使用这种方式提供服务的。 ","date":"2016-05-21","objectID":"/dns/:0:1","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"概念 DNS(Domain Name System)，域名系统，它是因特网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。 DNS Domain Namespace，DNS域命名空间，是一种分层树状结构，其格式如下:“www.google.com”,以点”.“为分隔。结构如图所示： 根域：绝对域名(FQDN)，以点”.“结尾的域名 顶级域：用来指示某个国家/地区或组织使用的名称的类型名称，例如.com 二级域：个人或组织在因特网上使用的注册名称，例如google.com 子域：已注册的二级域名派生的域名，一般就是网站名，例如www.google.com 主机名：标识网络上的特定计算机，例如h1.www.google.com DNS资源记录：(即映射关系，通常由域名管理员进行配置)，常见类型如下： SOA：起始授权机构 NS：名称服务器 MX：邮件服务器 A：IP地址(最常用，映射IP地址) CNAME：别名(较常用，映射到其他域名) ","date":"2016-05-21","objectID":"/dns/:0:2","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"DNS工作原理 当我们请求一个域名时，会通过DNS服务器将域名解析成IP访问最终的主机，那么，DNS是如何查询到域名所对应的IP并返回给我们的呢？请工作机制如图所示： 当我们请求一个域名时，直到获取到IP地址，整个过程是如何工作的？以请求www.codecc.xyz为例： 首先，我们的主机会去查找本地的hosts文件和本地DNS解析器缓存，如果hosts文件和本地DNS缓存存在www.codecc.xyz和IP的映射关系，则完成域名解析，请求该IP地址，否则进入第二步。 当hosts和本地DNS解析器缓存都没有对应的网址映射关系，则会根据机器(/etc/reslove.conf)配置的本地DNS服务器进行查询，此服务器收到查询时，如果要查询的域名在本地配置区域资源或者缓存中存在映射关系，则跳到步骤9，将解析结果直接返回给客户机。 PS：一二步骤为递归查询，其余步骤为迭代查询 若本地DNS服务器不存在该域名的映射关系，就把请求发送至13台根DNS服务器。 根DNS服务器会判断这个域名(.xyz)由谁来授权管理，并返回一个负责该顶级域的DNS服务器的一个IP给本地DNS服务器。 本地DNS服务器收到该IP后，会再将查询请求发送至(.xyz)所在的DNS服务器。 如果(.xyz)的DNS服务器无法解析该域名，就会去判断这个二级域名(codecc.xyz)的管理者，返回一个负责该二级域的DNS服务器的IP给本地DNS服务器。 本地DNS服务器收到该IP后，会再次将查询请求发送至(codecc.xyz)所在的DNS服务器。 (codecc.xyz)的DNS服务器会存有www.codecc.xzy的映射关系，将解析后的IP返回给本地DNS服务器 本地DNS服务器根据查询到的解析IP发送给客户机，至此，DNS解析完成。 ","date":"2016-05-21","objectID":"/dns/:0:3","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"常用DNS查询命令 windows： nslookup 域名 Linux： nslookup 域名 dig 域名 ","date":"2016-05-21","objectID":"/dns/:0:4","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Domain_Name_System https://technet.microsoft.com/en-us/library/cc772774(v=ws.10).aspx 《TCP/IP详解卷1：协议》 ","date":"2016-05-21","objectID":"/dns/:0:5","tags":["network"],"title":"谈谈DNS","uri":"/dns/"},{"categories":["Security"],"content":"WEB安全之CSP","date":"2016-05-20","objectID":"/webcsp/","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"概念 内容安全策略(Content-Security-Policy，CSP)：是一种web应用技术用于帮助缓解大部分类型的内容注入攻击，包括XSS攻击和数据注入等，这些攻击可实现数据窃取、网站破坏和作为恶意软件分发版本等行为。该策略可让网站管理员指定客户端允许加载的各类可信任资源。 ","date":"2016-05-20","objectID":"/webcsp/:0:1","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"浏览器支持 统计来源：caniuse.com/contentsecuritypolicy \u0026 Mozilla ","date":"2016-05-20","objectID":"/webcsp/:0:2","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"指令参考 Content-Security-Policy 响应头的值可配置一个或多个，多个指令以分号;隔开。 指令 示例 描述 default-src ‘self’ cdn.example.com 默认配置，若其他指令没有配置，都以此配置的规则为准 script-src ‘self’ js.example.com 定义允许加载的JavaScript来源 style-src ‘self’ css.example.com 定义允许加载的样式表来源 img-src ‘self’ img.example.com 定义允许加载的图片来源 connect-src ‘self’ 适用于XMLHttpRequest(AJAX),WebSocket或EventSource，当为不允许的来源，浏览器返回一个400的状态码。 font-src font.example.com 定义允许加载的字体来源 object-src ‘self’ 定义允许加载的插件来源.eg,\u003cobject\u003e,\u003cembed\u003e或\u003capplet\u003e media-src media.example.com 定义允许加载的audio和video.eg,HTML5,\u003caudio\u003e,\u003cvideo\u003e元素 frame-src ‘self’ 定义允许加载的框架来源 sandbox allow-forms allow-scripts 授权一个沙箱用来请求具有iframe sanbox等类似属性的资源,该沙箱默认为同源策略,禁止弹出窗口,执行插件和脚本.若要允许其他,可增加配置:allow-forms,allow-same-origin,allow-scripts,allow-top-navigation report-uri /some-report-uri 该配置让浏览器发送一个失败报告到指定的路径，也可以增加-Report-only到HTTP头,让浏览器只发送报告(不做阻止动作) ","date":"2016-05-20","objectID":"/webcsp/:0:3","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"来源配置参考 所有的指令都要在配置后面添加来源列表，多个来源列表可用空格隔开，*和none只能存在一个。 指令 示例 描述 * img-src * 无限制，允许所有 ‘none’ object-src ‘none’ 禁止加载任何路径的资源 ‘self’ script-src ‘self’ 允许加载同源的资源 data: img-src ‘self’ data: 允许通过数据模式加载资源 domain.ccc.com img-src img.ccc.com 允许加载匹配域名的资源 *.ccc.com img-src *.ccc.com 允许加载匹配域名的资源 https://img.ccc.com img-src https://img.ccc.com 允许加载匹配https方式的域名资源 https: img-src https: 允许加载所有匹配https方式的资源 ‘unsafe-inline’ script-src ‘unsafe-inline’ 允许使用内联元素,类似,Style attribute,onclick,scripttag bodies ‘unsafe-eval’ script-src ‘unsafe-eval’ 允许不安全的动态编码，例如eval() ","date":"2016-05-20","objectID":"/webcsp/:0:4","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"例子 只允许加载同源的所有资源 default-src 'self'; 支持*号匹配 default-src 'self' https://*.ccc.com:*; 只允许加载同源的脚本 script-src 'self'; 只允许加载同源的和www.ccc.com的脚本 script-src 'self' www.ccc.com; ","date":"2016-05-20","objectID":"/webcsp/:0:5","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"常见配置 该策略允许加载同源的图片、脚本、AJAX和CSS资源，并阻止加载其他任何资源，对于大多数网站是一个不错的配置。 default-src 'none'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; 被禁止时的报错信息： 谷歌浏览器可通过谷歌开发工具查看该报错，通常是按F12 Refused to load the script ‘script-uri’ because it violates the following Content Security Policy directive: “your CSP directive”. Firefox 可通过 Web Developer Tools 查看报错 Content Security Policy: A violation occurred for a report-only CSP policy (“An attempt to execute inline scripts has been blocked”). The behavior was allowed, and a CSP report was sent. ","date":"2016-05-20","objectID":"/webcsp/:0:6","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Security"],"content":"参考 http://content-security-policy.com/ https://developer.mozilla.org/en-US/docs/Web/Security/CSP http://www.w3.org/TR/CSP2/ ","date":"2016-05-20","objectID":"/webcsp/:0:7","tags":["security","web"],"title":"WEB安全之CSP","uri":"/webcsp/"},{"categories":["Network"],"content":"初识网络通信","date":"2016-05-18","objectID":"/network_comm/","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"写在前面 在计算机刚出现的时候，只能在本机进行一些运算处理，想将一台计算机中的数据转移到另一台计算机中，需要通过外部存储介质来传输，例如磁带、软盘。而网络技术的出现，使得计算机间可以通过一些传输介质(网线、光纤等)，实现快速的数据传输和信息交互。如今，网络已无处不在，那么，计算机之间究竟是如何通信的呢？下面会通过一些基础的网络知识来简单理解计算机之间的通信过程。 ","date":"2016-05-18","objectID":"/network_comm/:0:1","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"网络通信模型 网络通信模型是一种概念模型和框架，旨在使各种计算机在世界范围内互连为网络。其中有OSI七层模型和TCP/IP四层模型，现在大部分网络通信都是以TCP/IP四层模型为基础的。 它们的对应层次如下图： OSI有七层：从上到下依次为应用层、表示层、会话层、传输层、网络层、数据链路层、物理层 TCP/IP有四层：从上到下依次为应用层、传输层、互连层(网络层)、网络接口层(链路层)。 因为目前大部分TCP/IP模型，所以就以TCP/IP为例，我们来理解下数据间的通信，下图是两台计算机通信的数据的传输过程： ","date":"2016-05-18","objectID":"/network_comm/:0:2","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"数据封装 在详细了解TCP/IP每一层各自的作用前，先要理解数据封装的概念，数据在通过网络接口传送出去前，会经过层层封装，每层都会在前面的基础上添加自己的信息，在传输到对方计算机后，又会被层层进行解封装后得到最后的数据。其过程如下图所示： ","date":"2016-05-18","objectID":"/network_comm/:0:3","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"TCP/IP参考模型 TCP/IP参考模型是一个抽象的分层模型，这个模型中，所有的TCP/IP系列网络协议都被归类到4个抽象的\"层\"中。每一抽象层创建在低一层提供的服务上，并且为高一层提供服务。 完成一些特定的任务需要众多的协议协同工作，这些协议分布在参考模型的不同层中的，因此有时称它们为一个协议栈。 应用层(Application Layer) 该层包括所有和应用程序协同工作，利用基础网络交换应用程序专用的数据的协议。 应用层是大多数普通与网络相关的程序为了通过网络与其他程序通信所使用的层。这个层的处理过程是应用特有的；数据从网络相关的程序以这种应用内部使用的格式进行传送，然后被编码成标准协议的格式。 常见的应用层协议有HTTP、FTP、DNS、SNMP(基于UDP) 传输层(Transport Layer) 主要为两台主机上的应用程序提供端到端的通信，包括TCP协议（传输控制协议）和UDP（用户数据报协议）。 端口号由此层提供，且在一台计算机中具有唯一性。 UDP为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。 TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等,由于运输层提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。 因为TCP是一种面向连接的协议，所以两个在使用TCP的应用在彼此交换数据前必须先建立一个TCP连接，也就是有名的TCP三次握手，如下图所示： 建立连接协议过程：（TCP三次握手协议） 客户端发送一个SYN段指明客户打算连接的服务器的端口，以及初始序号（ISN）。 服务器发回包含服务器的初始序号的SYN报文段作为应答。同时，将确认序号设置为客户的ISN加1以对客户的SYN报文段进行确认。一个SYN占用一个序号。 客户将确认序号设置为服务器的ISN加1以对服务器的SYN报文段进行确认。 网络层(Internet Layer) 处理分组在网络中的活动。网络层协议包括IP协议（网际协议），ICPM协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议），其中的IP协议身是TCP/IP协议簇中最为核心的协议。IP提供的是不可靠、无连接的数据包传送服务。 IP地址 讲到IP协议就应该讲讲IP地址，IP地址是分配给网络上使用IP协议的设备的数字标签，有IPv4和IPv6两大类，我们目前使用的大部分还是IPv4的地址，以下简称IP地址，IP地址由32位二进制数组成，为便于使用，常以XXX.XXX.XXX.XXX形式表示。 IP地址由两个字段组成：网络号(net-id)和主机号(host-id)，为方便IP地址管理，IP地址被分为五类，如下图： 其中A、B、C类地址为单播（unicast）地址；D类地址为组播（multicast）地址；E类地址为保留地址，以备将来的特殊用途。目前大量使用中的IP地址属于A、B、C三类地址。 A类地址范围：0.0.0.0～127.255.255.255 B类地址范围：128.0.0.0～191.255.255.255 C类地址范围：192.0.0.0～223.255.255.255 私网地址范围：10.0.0.0～10.255.255.255 ，172.16.0.0～172.31.255.255 ，192.168.0.0～192.168.255.255，私网地址只能在本地局域网中使用，不在公网中使用。 子网和掩码 传统的IP地址分配方式，对IP地址的浪费非常严重。为了充分利用已有的IP地址，人们提出了掩码（mask）和子网（subnet）的概念。 掩码是一个与IP地址对应的32位数字，这些数字中一些为1，另外一些为0。原则上这些1和0可以任意组合，不过一般在设计掩码时，网络号码和子网号码的比特值为1，主机号码的比特值为0。掩码可以把IP地址分为两个部分：子网地址和主机地址。IP地址与掩码中为1的位对应的部分为子网地址，其他的位对应的部分则是主机地址。当不进行子网划分时，子网掩码即为默认值，此时子网掩码中“1”的长度就是网络号码的长度。即A类地址对应的掩码默认值为255.0.0.0；B类地址的掩码默认值为255.255.0.0；C类地址掩码的默认值为255.255.255.0。 路由 概念：若目的主机与源主机在同一共享网络内，IP数据报直接送达目的主机，否则，主机把数据报发往默认的路由器上，由路由器进行数据报转发。 链路层(Link Layer) 通常包括设备驱动程序和网络接口卡。处理与传输媒介的物理接口细节。 主要协议有：ARP协议和RARP协议 MAC地址 ：数据链路层具有自己的寻址机制(48bit地址)，当一台主机把以太网数据帧发送到位于同一局域网上得另一台主机时，是根据48bit的以太网地址来确定目的接口的。 而ARP和RARP协议是为IP地址和MAC地址提供映射的： ","date":"2016-05-18","objectID":"/network_comm/:0:4","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"使用 我们在判断两台主机应用之间的网络是否正常，通常是判断到对方IP和端口是否能通。 常用网络判断命令： Windows ping $IP：最常用的判断网络是否可达的命令。 tracert $IP：跟踪路由，即打印出本机到到目的IP，所经过路由。 telnet $IP $port：可以测试某个IP和应用端口是否能通。 netstat：查看本机监听和建立连接的端口。 Linux ping $IP：最常用的判断网络是否可达的命令 traceroute $IP：跟踪路由，即打印出本机到到目的IP，所经过路由。 或者使用mtr -ni 0.1 $IP，可以实现以上两个共同的效果 nc -vz $IP $PORT：测试到目的IP的应用端口是否能通。 netstat -tupln：可以查看本机目前监听的端口 ","date":"2016-05-18","objectID":"/network_comm/:0:5","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":["Network"],"content":"参考 https://en.wikipedia.org/wiki/Internet_protocol_suite 《TCP/IP详解卷1:协议》 ","date":"2016-05-18","objectID":"/network_comm/:0:6","tags":["network"],"title":"初识网络通信","uri":"/network_comm/"},{"categories":null,"content":"About CC Software Developer Networking Engineer ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"About Mess","uri":"/about/"},{"categories":null,"content":"Working Experience CF (2019-current) DevOps Engineer CNC (2015-2018) Operations Engineer(SA) ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"About Mess","uri":"/about/"},{"categories":null,"content":"Focus \u0026 Interests Linux Networking Cloud Native Golang, Shell DevOps ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"About Mess","uri":"/about/"}]